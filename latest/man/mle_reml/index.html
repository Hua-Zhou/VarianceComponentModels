<!DOCTYPE html>
<!--[if lt IE 7 ]><html class="no-js ie6"><![endif]-->
<!--[if IE 7 ]><html class="no-js ie7"><![endif]-->
<!--[if IE 8 ]><html class="no-js ie8"><![endif]-->
<!--[if IE 9 ]><html class="no-js ie9"><![endif]-->
<!--[if (gt IE 9)|!(IE)]><!--> <html class="no-js"> <!--<![endif]-->
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,maximum-scale=1">
    
      
        <title>MLE/REML - VarianceComponentModels.jl</title>
      
      
      
      
        <meta name="author" content="Hua Zhou">
      
    
    <meta property="og:url" content="None">
    <meta property="og:title" content="VarianceComponentModels.jl">
    <meta property="og:image" content="None/../../">
    <meta name="apple-mobile-web-app-title" content="VarianceComponentModels.jl">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    
    
    <link rel="shortcut icon" type="image/x-icon" href="../../assets/images/favicon-e565ddfa3b.ico">
    <link rel="icon" type="image/x-icon" href="../../assets/images/favicon-e565ddfa3b.ico">
    <style>
      @font-face {
      	font-family: 'Icon';
      	src: url('../../assets/fonts/icon.eot?52m981');
      	src: url('../../assets/fonts/icon.eot?#iefix52m981')
               format('embedded-opentype'),
      		   url('../../assets/fonts/icon.woff?52m981')
               format('woff'),
      		   url('../../assets/fonts/icon.ttf?52m981')
               format('truetype'),
      		   url('../../assets/fonts/icon.svg?52m981#icon')
               format('svg');
      	font-weight: normal;
      	font-style: normal;
      }
    </style>
    <link rel="stylesheet" href="../../assets/stylesheets/application-a422ff04cc.css">
    
      <link rel="stylesheet" href="../../assets/stylesheets/palettes-05ab2406df.css">
    
    
      
      
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,700|Ubuntu+Mono">
      <style>
        body, input {
          font-family: 'Ubuntu', Helvetica, Arial, sans-serif;
        }
        pre, code {
          font-family: 'Ubuntu Mono', 'Courier New', 'Courier', monospace;
        }
      </style>
    
    
      <link rel="stylesheet" href="../../assets/Documenter.css">
    
    <script src="../../assets/javascripts/modernizr-4ab42b99fd.js"></script>
    
  </head>
  
  
  
  <body class="palette-primary-indigo palette-accent-blue">
    
      
      
    
    <div class="backdrop">
      <div class="backdrop-paper"></div>
    </div>
    <input class="toggle" type="checkbox" id="toggle-drawer">
    <input class="toggle" type="checkbox" id="toggle-search">
    <label class="toggle-button overlay" for="toggle-drawer"></label>
    <header class="header">
      <nav aria-label="Header">
  <div class="bar default">
    <div class="button button-menu" role="button" aria-label="Menu">
      <label class="toggle-button icon icon-menu" for="toggle-drawer">
        <span></span>
      </label>
    </div>
    <div class="stretch">
      <div class="title">
        
          <span class="path">
            
              
                Manual <i class="icon icon-link"></i>
              
            
          </span>
        
        MLE/REML
      </div>
    </div>
    
    
    <div class="button button-search" role="button" aria-label="Search">
      <label class="toggle-button icon icon-search" title="Search" for="toggle-search"></label>
    </div>
  </div>
  <div class="bar search">
    <div class="button button-close" role="button" aria-label="Close">
      <label class="toggle-button icon icon-back" for="toggle-search"></label>
    </div>
    <div class="stretch">
      <div class="field">
        <input class="query" type="text" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck>
      </div>
    </div>
    <div class="button button-reset" role="button" aria-label="Search">
      <button class="toggle-button icon icon-close" id="reset-search"></button>
    </div>
  </div>
</nav>
    </header>
    <main class="main">
      
      <div class="drawer">
        <nav aria-label="Navigation">
  
  <a href="https://github.com/OpenMendel/VarianceComponentModels.jl" class="project">
    <div class="banner">
      
      <div class="name">
        <strong>
          VarianceComponentModels.jl
          <span class="version">
            
          </span>
        </strong>
        
          <br>
          OpenMendel/VarianceComponentModels.jl
        
      </div>
    </div>
  </a>
  <div class="scrollable">
    <div class="wrapper">
      
        <ul class="repo">
          <li class="repo-download">
            
            <a href="https://github.com/OpenMendel/VarianceComponentModels.jl/archive/master.zip" target="_blank" title="Download" data-action="download">
              <i class="icon icon-download"></i> Download
            </a>
          </li>
          <li class="repo-stars">
            <a href="https://github.com/OpenMendel/VarianceComponentModels.jl/stargazers" target="_blank" title="Stargazers" data-action="star">
              <i class="icon icon-star"></i> Stars
              <span class="count">&ndash;</span>
            </a>
          </li>
        </ul>
        <hr>
      
      <div class="toc">
        <ul>
          
            
  <li>
    <a class="" title="Home" href="../..">
      Home
    </a>
    
  </li>

          
            
  <li>
    <span class="section">Manual</span>
    <ul>
      
        
  <li>
    <a class="current" title="MLE/REML" href="./">
      MLE/REML
    </a>
    
      
        
      
      
        <ul>
          
            <li class="anchor">
              <a title="Demo data" href="#demo-data">
                Demo data
              </a>
            </li>
          
            <li class="anchor">
              <a title="Maximum likelihood estimation (MLE)" href="#maximum-likelihood-estimation-mle">
                Maximum likelihood estimation (MLE)
              </a>
            </li>
          
            <li class="anchor">
              <a title="Restricted maximum likelihood estimation (REML)" href="#restricted-maximum-likelihood-estimation-reml">
                Restricted maximum likelihood estimation (REML)
              </a>
            </li>
          
            <li class="anchor">
              <a title="Optimization algorithms" href="#optimization-algorithms">
                Optimization algorithms
              </a>
            </li>
          
            <li class="anchor">
              <a title="Starting point" href="#starting-point">
                Starting point
              </a>
            </li>
          
            <li class="anchor">
              <a title="Constrained estimation of B" href="#constrained-estimation-of-b">
                Constrained estimation of B
              </a>
            </li>
          
        </ul>
      
    
  </li>

      
        
  <li>
    <a class="" title="Heritability" href="../heritability/">
      Heritability
    </a>
    
  </li>

      
    </ul>
  </li>

          
            
  <li>
    <a class="" title="API" href="../api/">
      API
    </a>
    
  </li>

          
        </ul>
        
      </div>
    </div>
  </div>
</nav>
      </div>
      <article class="article">
        <div class="wrapper">
          
          <p><a id='MLE-and-REML-1'></a></p>
<h1 id="mle-and-reml">MLE and REML</h1>
<p><a id='Demo-data-1'></a></p>
<h2 id="demo-data">Demo data</h2>
<p>For demonstration, we generate a random data set.</p>
<div class="codehilite"><pre><span></span><span class="c"># generate data from a d-variate response variane component model</span>
<span class="n">srand</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">1000</span>   <span class="c"># no. observations</span>
<span class="n">d</span> <span class="o">=</span> <span class="mi">2</span>      <span class="c"># dimension of responses</span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">2</span>      <span class="c"># no. variance components</span>
<span class="n">p</span> <span class="o">=</span> <span class="mi">2</span>      <span class="c"># no. covariates</span>
<span class="c"># n-by-p design matrix</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
<span class="c"># p-by-d mean component regression coefficient</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">ones</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>  
<span class="c"># a tuple of m covariance matrices</span>
<span class="n">V</span> <span class="o">=</span> <span class="nb">ntuple</span><span class="p">(</span><span class="n">x</span> <span class="o">-&gt;</span> <span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">),</span> <span class="n">m</span><span class="p">)</span> 
<span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="p">:</span><span class="n">m</span><span class="o">-</span><span class="mi">1</span>
  <span class="n">Vi</span> <span class="o">=</span> <span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
  <span class="n">copy!</span><span class="p">(</span><span class="n">V</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">Vi</span> <span class="o">*</span> <span class="n">Vi</span><span class="o">&#39;</span><span class="p">)</span>
<span class="k">end</span>
<span class="n">copy!</span><span class="p">(</span><span class="n">V</span><span class="p">[</span><span class="n">m</span><span class="p">],</span> <span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">))</span> <span class="c"># last covarianec matrix is idendity</span>
<span class="c"># a tuple of m d-by-d variance component parameters</span>
<span class="n">Σ</span> <span class="o">=</span> <span class="nb">ntuple</span><span class="p">(</span><span class="n">x</span> <span class="o">-&gt;</span> <span class="n">zeros</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">d</span><span class="p">),</span> <span class="n">m</span><span class="p">)</span> 
<span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="p">:</span><span class="n">m</span>
  <span class="n">Σi</span> <span class="o">=</span> <span class="n">randn</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
  <span class="n">copy!</span><span class="p">(</span><span class="n">Σ</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">Σi</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">Σi</span><span class="p">)</span>
<span class="k">end</span>
<span class="c"># form overall nd-by-nd covariance matrix Ω</span>
<span class="n">Ω</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">d</span><span class="p">,</span> <span class="n">n</span> <span class="o">*</span> <span class="n">d</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="p">:</span><span class="n">m</span>
  <span class="n">Ω</span> <span class="o">+=</span> <span class="n">kron</span><span class="p">(</span><span class="n">Σ</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">V</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="k">end</span>
<span class="n">Ωchol</span> <span class="o">=</span> <span class="n">cholfact</span><span class="p">(</span><span class="n">Ω</span><span class="p">)</span>
<span class="c"># n-by-d responses</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">X</span> <span class="o">*</span> <span class="n">B</span> <span class="o">+</span> <span class="n">reshape</span><span class="p">(</span><span class="n">Ωchol</span><span class="p">[:</span><span class="n">L</span><span class="p">]</span> <span class="o">*</span> <span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="o">*</span><span class="n">d</span><span class="p">),</span> <span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">);</span>
</pre></div>


<p><a id='Maximum-likelihood-estimation-(MLE)-1'></a></p>
<h2 id="maximum-likelihood-estimation-mle">Maximum likelihood estimation (MLE)</h2>
<p>To find the MLE of parameters $(B,\Sigma_1,\ldots,\Sigma_m)$, we take 3 steps:  </p>
<p><strong>Step 1 (Construct data)</strong>. Construct an instance of <code>VarianceComponentVariate</code>, which consists fields  </p>
<ul>
<li><code>Y</code>: $n$-by-$d$ responses  </li>
<li><code>X</code>: $n$-by-$p$ covariate matrix  </li>
<li><code>V=(V[1],...,V[m])</code>: a tuple of $n$-by-$n$ covariance matrices. The last covariance matrix must be positive definite and usually is the identity matrix. </li>
</ul>
<div class="codehilite"><pre><span></span><span class="k">using</span> <span class="n">VarianceComponentModels</span>
<span class="n">vcdata</span> <span class="o">=</span> <span class="n">VarianceComponentVariate</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">V</span><span class="p">)</span>
<span class="n">fieldnames</span><span class="p">(</span><span class="n">vcdata</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>3-element Array{Symbol,1}:
 :Y
 :X
 :V
</pre></div>


<p>In the absence of covariates $X$, we can simply initialize by <code>vcdata = VarianceComponentVariate(Y, V)</code>.</p>
<p><strong>Step 2 (Construct a model)</strong>. Construct an instance of <code>VarianceComponentModel</code>, which consists of fields  </p>
<ul>
<li><code>B</code>: $n$-by-$p$ mean regression coefficients  </li>
<li><code>Σ=(Σ[1],...,Σ[m])</code>: variane component parameters respectively. </li>
</ul>
<p>When constructed from a <code>VarianceComponentVariate</code> instance, the mean parameters $B$ are initialized to be zero and the tuple of variance component parameters $\Sigma$ to be <code>(eye(d),...,eye(d))</code>.</p>
<div class="codehilite"><pre><span></span><span class="n">vcmodel</span> <span class="o">=</span> <span class="n">VarianceComponentModel</span><span class="p">(</span><span class="n">vcdata</span><span class="p">)</span>
<span class="n">fieldnames</span><span class="p">(</span><span class="n">vcmodel</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>7-element Array{Symbol,1}:
 :B    
 :Σ    
 :A    
 :sense
 :b    
 :lb   
 :ub
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">vcmodel</span>
</pre></div>


<div class="codehilite"><pre><span></span>VarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(2x2 Array{Float64,2}:
 0.0  0.0
 0.0  0.0,(
2x2 Array{Float64,2}:
 1.0  0.0
 0.0  1.0,

2x2 Array{Float64,2}:
 1.0  0.0
 0.0  1.0),0x4 Array{Float64,2},Char[],Float64[],-Inf,Inf)
</pre></div>


<p>The remaining fields <code>A</code>, <code>sense</code>, <code>b</code>, <code>lb</code>, <code>ub</code> specify (optional) constraints on the mean parameters <code>B</code>:</p>
<p>$A * \text{vec}(B) \,\, =(\text{or } \ge \text{or } \le) \,\, b$</p>
<p>$lb \le \text{vec}(B) \le ub$</p>
<p><code>A</code> is an constraint matrix with $pd$ columns, <code>sense</code> is a vector of charaters taking values <code>'&lt;'</code>, <code>'='</code> or <code>'&gt;'</code>, and <code>lb</code> and <code>ub</code> are the lower and upper bounds for <code>vec(B)</code>. By default, <code>A</code>, <code>sense</code>, <code>b</code> are empty, <code>lb</code> is <code>-Inf</code>, and <code>ub</code> is <code>Inf</code>. If any constraits are non-trivial, final estimates of <code>B</code> are enforced to satisfy them.</p>
<p>When a better initial guess is available, we can initialize by calling <code>vcmodel=VarianceComponentModel(B0, Σ0)</code> directly.</p>
<p><strong>Step 3 (Fit model)</strong>. Call optmization routine <code>fit_mle!</code>. The keywork <code>algo</code> dictates the optimization algorithm: <code>:MM</code> (minorization-maximization algorithm) or <code>:FS</code> (Fisher scoring algorithm).</p>
<div class="codehilite"><pre><span></span><span class="n">vcmodel_mle</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">vcmodel</span><span class="p">)</span>
<span class="p">@</span><span class="n">time</span> <span class="n">logl</span><span class="p">,</span> <span class="n">vcmodel_mle</span><span class="p">,</span> <span class="n">Σse</span><span class="p">,</span> <span class="n">Σcov</span><span class="p">,</span> <span class="n">Bse</span><span class="p">,</span> <span class="n">Bcov</span> <span class="o">=</span> <span class="n">fit_mle!</span><span class="p">(</span><span class="n">vcmodel_mle</span><span class="p">,</span> <span class="n">vcdata</span><span class="p">;</span> <span class="n">algo</span> <span class="o">=</span> <span class="p">:</span><span class="n">MM</span><span class="p">);</span>
</pre></div>


<div class="codehilite"><pre><span></span>     MM Algorithm
  Iter      Objective  
--------  -------------
       0  -6.253551e+03
       1  -3.881454e+03
       2  -3.853179e+03
       3  -3.846525e+03
       4  -3.844906e+03
       5  -3.844506e+03
       6  -3.844406e+03
       7  -3.844381e+03
       8  -3.844375e+03
       9  -3.844374e+03
      10  -3.844373e+03

  0.369037 seconds (13.81 k allocations: 23.961 MB, 1.31% gc time)
</pre></div>


<p>The output of <code>fit_mle!</code> contains  </p>
<ul>
<li>final log-likelihood  </li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">logl</span>
</pre></div>


<div class="codehilite"><pre><span></span>-3844.373181418088
</pre></div>


<ul>
<li>fitted model</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">fieldnames</span><span class="p">(</span><span class="n">vcmodel_mle</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>7-element Array{Symbol,1}:
 :B    
 :Σ    
 :A    
 :sense
 :b    
 :lb   
 :ub
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">vcmodel_mle</span>
</pre></div>


<div class="codehilite"><pre><span></span>VarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(2x2 Array{Float64,2}:
 1.092     1.04727
 0.955346  1.01632,(
2x2 Array{Float64,2}:
  0.380637  -0.305465
 -0.305465   4.51938 ,

2x2 Array{Float64,2}:
 1.84009   0.265569
 0.265569  2.17275 ),0x4 Array{Float64,2},Char[],Float64[],-Inf,Inf)
</pre></div>


<ul>
<li>standard errors of the estimated varianec component parameters</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">Σse</span>
</pre></div>


<div class="codehilite"><pre><span></span>(
2x2 Array{Float64,2}:
 0.0765136  0.263047
 0.263047   0.904332,

2x2 Array{Float64,2}:
 0.0844292  0.0917441
 0.0917441  0.0996927)
</pre></div>


<ul>
<li>covariance matrix of the variance component parameters estimates</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">Σcov</span>
</pre></div>


<div class="codehilite"><pre><span></span>8x8 Array{Float64,2}:
  0.00585433  -0.00467019  -0.00467019  …  -1.07903e-6   -1.557e-7   
 -0.00467019   0.0691937    0.00372555     -1.557e-7     -1.27444e-6 
 -0.00467019   0.00372555   0.0691937      -8.83212e-6   -1.27444e-6 
  0.00372555  -0.055198    -0.055198       -1.27444e-6   -1.04316e-5 
 -7.4779e-6   -1.07903e-6  -1.07903e-6      0.00102878    0.000148477
 -1.07903e-6  -8.83212e-6  -1.557e-7    …   0.000148477   0.00121477 
 -1.07903e-6  -1.557e-7    -8.83212e-6      0.00841698    0.00121477 
 -1.557e-7    -1.27444e-6  -1.27444e-6      0.00121477    0.00993864
</pre></div>


<ul>
<li>standard errors of the estimated mean parameters</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">Bse</span>
</pre></div>


<div class="codehilite"><pre><span></span>2x2 Array{Float64,2}:
 0.042556   0.0483538
 0.0430622  0.0495727
</pre></div>


<ul>
<li>covariance matrix of the mean parameter estimates</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">Bcov</span>
</pre></div>


<div class="codehilite"><pre><span></span>4x4 Array{Float64,2}:
  0.00181101   -1.98163e-5    0.000243689  -2.44708e-6 
 -1.98163e-5    0.00185435   -2.44708e-6    0.000243907
  0.000243689  -2.44708e-6    0.00233809   -2.80614e-5 
 -2.44708e-6    0.000243907  -2.80614e-5    0.00245745
</pre></div>


<p><a id='Restricted-maximum-likelihood-estimation-(REML)-1'></a></p>
<h2 id="restricted-maximum-likelihood-estimation-reml">Restricted maximum likelihood estimation (REML)</h2>
<p><a href="https://en.wikipedia.org/wiki/Restricted_maximum_likelihood">REML (restricted maximum likelihood estimation)</a> is a popular alternative to the MLE. To find the REML of a variane component model, we replace the above step 3 by  </p>
<p><strong>Step 3</strong>. Call optmization routine <code>fit_reml!</code>.</p>
<div class="codehilite"><pre><span></span><span class="n">vcmodel_reml</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">vcmodel</span><span class="p">)</span>
<span class="p">@</span><span class="n">time</span> <span class="n">logl</span><span class="p">,</span> <span class="n">vcmodel_reml</span><span class="p">,</span> <span class="n">Σse</span><span class="p">,</span> <span class="n">Σcov</span><span class="p">,</span> <span class="n">Bse</span><span class="p">,</span> <span class="n">Bcov</span> <span class="o">=</span> <span class="n">fit_reml!</span><span class="p">(</span><span class="n">vcmodel_reml</span><span class="p">,</span> <span class="n">vcdata</span><span class="p">;</span> <span class="n">algo</span> <span class="o">=</span> <span class="p">:</span><span class="n">MM</span><span class="p">);</span>
</pre></div>


<div class="codehilite"><pre><span></span>     MM Algorithm
  Iter      Objective  
--------  -------------
       0  -4.215053e+03
       1  -3.925799e+03
       2  -3.865114e+03
       3  -3.851105e+03
       4  -3.847732e+03
       5  -3.846903e+03
       6  -3.846698e+03
       7  -3.846647e+03
       8  -3.846634e+03
       9  -3.846631e+03
      10  -3.846630e+03

  0.677764 seconds (16.35 k allocations: 62.680 MB, 1.06% gc time)
</pre></div>


<p>The output of <code>fit_reml!</code> contains</p>
<ul>
<li>the final log-likelihood at REML estimate</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">logl</span>
</pre></div>


<div class="codehilite"><pre><span></span>-3844.377717902519
</pre></div>


<ul>
<li>REML estimates</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">fieldnames</span><span class="p">(</span><span class="n">vcmodel_reml</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>7-element Array{Symbol,1}:
 :B    
 :Σ    
 :A    
 :sense
 :b    
 :lb   
 :ub
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">vcmodel_reml</span>
</pre></div>


<div class="codehilite"><pre><span></span>VarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(2x2 Array{Float64,2}:
 1.092     1.04727
 0.955345  1.01632,(
2x2 Array{Float64,2}:
  0.380594  -0.305485
 -0.305485   4.51994 ,

2x2 Array{Float64,2}:
 1.84285   0.261963
 0.261963  2.17842 ),0x4 Array{Float64,2},Char[],Float64[],-Inf,Inf)
</pre></div>


<ul>
<li>standard errors of the estimated varianec component parameters</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">Σse</span>
</pre></div>


<div class="codehilite"><pre><span></span>(
2x2 Array{Float64,2}:
 0.0765055  0.26305 
 0.26305    0.904446,

2x2 Array{Float64,2}:
 0.0845559  0.0919325
 0.0919325  0.0999526)
</pre></div>


<ul>
<li>covariance matrix of the variance component parameters estimates</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">Σcov</span>
</pre></div>


<div class="codehilite"><pre><span></span>8x8 Array{Float64,2}:
  0.0058531   -0.00467005  -0.00467005  …  -1.06597e-6   -1.51499e-7 
 -0.00467005   0.0691951    0.00372613     -1.51499e-7   -1.26041e-6 
 -0.00467005   0.00372613   0.0691951      -8.86843e-6   -1.26041e-6 
  0.00372613  -0.0552092   -0.0552092      -1.26041e-6   -1.0486e-5  
 -7.50035e-6  -1.06597e-6  -1.06597e-6      0.00101633    0.000144472
 -1.06597e-6  -8.86843e-6  -1.51499e-7  …   0.000144472   0.0012014  
 -1.06597e-6  -1.51499e-7  -8.86843e-6      0.00845158    0.0012014  
 -1.51499e-7  -1.26041e-6  -1.26041e-6      0.0012014     0.00999052
</pre></div>


<ul>
<li>standard errors of the estimated mean parameters</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">Bse</span>
</pre></div>


<div class="codehilite"><pre><span></span>2x2 Array{Float64,2}:
 0.0425878  0.0484189
 0.0430944  0.04964
</pre></div>


<ul>
<li>covariance matrix of the mean parameter estimates</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">Bcov</span>
</pre></div>


<div class="codehilite"><pre><span></span>4x4 Array{Float64,2}:
  0.00181372   -1.9846e-5    0.000240116  -2.40768e-6
 -1.9846e-5     0.00185713  -2.40768e-6    0.00024024
  0.000240116  -2.40768e-6   0.00234439   -2.81393e-5
 -2.40768e-6    0.00024024  -2.81393e-5    0.00246413
</pre></div>


<p><a id='Optimization-algorithms-1'></a></p>
<h2 id="optimization-algorithms">Optimization algorithms</h2>
<p>Finding the MLE or REML of variance component models is a non-trivial nonlinear optimization problem. The main complications are the non-convexity of objective function and the positive semi-definiteness constraint of variane component parameters $\Sigma_1,\ldots,\Sigma_m$. In specific applications, users should try different algorithms with different starting points in order to find a better solution. Here are some tips for efficient computation. </p>
<p>In general the optimization algorithm needs to invert the $nd$ by $nd$ overall covariance matrix $\Omega = \Sigma_1 \otimes V_1 + \cdots + \Sigma_m \otimes V_m$ in each iteration. Inverting a matrix is an expensive operation with $O(n^3 d^3)$ floating operations. When there are only <strong>two</strong> varianec components ($m=2$), this tedious task can be avoided by taking one (generalized) eigendecomposion of $(V_1, V_2)$ and rotating data $(Y, X)$ by the eigen-vectors. </p>
<div class="codehilite"><pre><span></span><span class="n">vcdatarot</span> <span class="o">=</span> <span class="n">TwoVarCompVariateRotate</span><span class="p">(</span><span class="n">vcdata</span><span class="p">)</span>
<span class="n">fieldnames</span><span class="p">(</span><span class="n">vcdatarot</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>4-element Array{Symbol,1}:
 :Yrot    
 :Xrot    
 :eigval  
 :logdetV2
</pre></div>


<p>Two optimization algorithms are implemented: <a href="https://books.google.com/books?id=QYqeYTftPNwC&amp;lpg=PP1&amp;pg=PA142#v=onepage&amp;q&amp;f=false">Fisher scoring</a> (<code>mle_fs!</code>) and the <a href="http://arxiv.org/abs/1509.07426">minorization-maximization (MM) algorithm</a> (<code>mle_mm!</code>). Both take the rotated data as input. These two functions give finer control of the optimization algorithms. Generally speaking, MM algorithm is more stable while Fisher scoring (if it converges) yields more accurate answer.</p>
<div class="codehilite"><pre><span></span><span class="n">vcmodel_mm</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">vcmodel</span><span class="p">)</span>
<span class="p">@</span><span class="n">time</span> <span class="n">mle_mm!</span><span class="p">(</span><span class="n">vcmodel_mm</span><span class="p">,</span> <span class="n">vcdatarot</span><span class="p">;</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">funtol</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="n">true</span><span class="p">);</span>
</pre></div>


<div class="codehilite"><pre><span></span>     MM Algorithm
  Iter      Objective  
--------  -------------
       0  -6.253551e+03
       1  -3.881454e+03
       2  -3.853179e+03
       3  -3.846525e+03
       4  -3.844906e+03
       5  -3.844506e+03
       6  -3.844406e+03
       7  -3.844381e+03
       8  -3.844375e+03
       9  -3.844374e+03
      10  -3.844373e+03

  0.021236 seconds (9.75 k allocations: 619.875 KB)
</pre></div>


<div class="codehilite"><pre><span></span><span class="c"># MM estimates</span>
<span class="n">vcmodel_mm</span><span class="o">.</span><span class="n">B</span>
</pre></div>


<div class="codehilite"><pre><span></span>2x2 Array{Float64,2}:
 1.092     1.04727
 0.955346  1.01632
</pre></div>


<div class="codehilite"><pre><span></span><span class="c"># MM estimates</span>
<span class="n">vcmodel_mm</span><span class="o">.</span><span class="n">Σ</span>
</pre></div>


<div class="codehilite"><pre><span></span>(
2x2 Array{Float64,2}:
  0.380637  -0.305465
 -0.305465   4.51938 ,

2x2 Array{Float64,2}:
 1.84009   0.265569
 0.265569  2.17275 )
</pre></div>


<p>Fisher scoring (<code>mle_fs!</code>) uses either <a href="https://github.com/JuliaOpt/Ipopt.jl">Ipopt.jl</a> (keyword <code>solver=:Ipopt</code>) or <a href="https://github.com/JuliaOpt/KNITRO.jl">KNITRO.jl</a> (keyword <code>solver=:Knitro</code>) as the backend solver. Ipopt is open source and installation of <a href="https://github.com/JuliaOpt/Ipopt.jl">Ipopt.jl</a> package alone is sufficient. Knitro is a commercial software and users need to follow instructions at <a href="https://github.com/JuliaOpt/KNITRO.jl">KNITRO.jl</a> for proper functioning.</p>
<div class="codehilite"><pre><span></span><span class="c"># Fisher scoring using Ipopt</span>
<span class="n">vcmodel_ipopt</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">vcmodel</span><span class="p">)</span>
<span class="p">@</span><span class="n">time</span> <span class="n">mle_fs!</span><span class="p">(</span><span class="n">vcmodel_ipopt</span><span class="p">,</span> <span class="n">vcdatarot</span><span class="p">;</span> <span class="n">solver</span><span class="o">=</span><span class="p">:</span><span class="n">Ipopt</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">true</span><span class="p">);</span>
</pre></div>


<div class="codehilite"><pre><span></span>This is Ipopt version 3.12.4, running with linear solver mumps.
NOTE: Other linear solvers might be more efficient (see Ipopt documentation).

Number of nonzeros in equality constraint Jacobian...:        0
Number of nonzeros in inequality constraint Jacobian.:        0
Number of nonzeros in Lagrangian Hessian.............:       21

Total number of variables............................:        6
                     variables with only lower bounds:        0
                variables with lower and upper bounds:        0
                     variables with only upper bounds:        0
Total number of equality constraints.................:        0
Total number of inequality constraints...............:        0
        inequality constraints with only lower bounds:        0
   inequality constraints with lower and upper bounds:        0
        inequality constraints with only upper bounds:        0

iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
   0  4.2109423e+03 0.00e+00 1.00e+02   0.0 0.00e+00    -  0.00e+00 0.00e+00   0 
   5  3.8445586e+03 0.00e+00 7.87e-01 -11.0 4.94e-02    -  1.00e+00 1.00e+00f  1 MaxS
  10  3.8443870e+03 0.00e+00 2.25e-01 -11.0 1.38e-02    -  1.00e+00 1.00e+00f  1 MaxS
  15  3.8443742e+03 0.00e+00 6.23e-02 -11.0 3.78e-03    -  1.00e+00 1.00e+00f  1 MaxS
  20  3.8443733e+03 0.00e+00 1.70e-02 -11.0 1.03e-03    -  1.00e+00 1.00e+00f  1 MaxS
  25  3.8443732e+03 0.00e+00 4.61e-03 -11.0 2.79e-04    -  1.00e+00 1.00e+00f  1 MaxS
  30  3.8443732e+03 0.00e+00 1.25e-03 -11.0 7.56e-05    -  1.00e+00 1.00e+00f  1 MaxS
  35  3.8443732e+03 0.00e+00 3.39e-04 -11.0 2.05e-05    -  1.00e+00 1.00e+00f  1 MaxS
  40  3.8443732e+03 0.00e+00 9.19e-05 -11.0 5.55e-06    -  1.00e+00 1.00e+00f  1 MaxS
  45  3.8443732e+03 0.00e+00 2.49e-05 -11.0 1.51e-06    -  1.00e+00 1.00e+00f  1 MaxS
iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
  50  3.8443732e+03 0.00e+00 6.76e-06 -11.0 4.08e-07    -  1.00e+00 1.00e+00f  1 MaxSA
  55  3.8443732e+03 0.00e+00 1.83e-06 -11.0 1.11e-07    -  1.00e+00 1.00e+00f  1 MaxSA
  60  3.8443732e+03 0.00e+00 4.97e-07 -11.0 3.00e-08    -  1.00e+00 1.00e+00h  1 MaxSA

Number of Iterations....: 63

                                   (scaled)                 (unscaled)
Objective...............:   3.4496886481727671e+02    3.8443731733053760e+03
Dual infeasibility......:   2.2693632135739328e-07    2.5290047736252332e-06
Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00
Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00
Overall NLP error.......:   2.2693632135739328e-07    2.5290047736252332e-06


Number of objective function evaluations             = 64
Number of objective gradient evaluations             = 64
Number of equality constraint evaluations            = 0
Number of inequality constraint evaluations          = 0
Number of equality constraint Jacobian evaluations   = 0
Number of inequality constraint Jacobian evaluations = 0
Number of Lagrangian Hessian evaluations             = 63
Total CPU secs in IPOPT (w/o function evaluations)   =      0.019
Total CPU secs in NLP function evaluations           =      0.263

EXIT: Solved To Acceptable Level.
  0.314060 seconds (110.60 k allocations: 6.978 MB)
</pre></div>


<div class="codehilite"><pre><span></span><span class="c"># Ipopt estimates</span>
<span class="n">vcmodel_ipopt</span><span class="o">.</span><span class="n">B</span>
</pre></div>


<div class="codehilite"><pre><span></span>2x2 Array{Float64,2}:
 1.092     1.04727
 0.955346  1.01632
</pre></div>


<div class="codehilite"><pre><span></span><span class="c"># Ipopt estimates</span>
<span class="n">vcmodel_ipopt</span><span class="o">.</span><span class="n">Σ</span>
</pre></div>


<div class="codehilite"><pre><span></span>(
2x2 Array{Float64,2}:
  0.380552  -0.305594
 -0.305594   4.52106 ,

2x2 Array{Float64,2}:
 1.84008   0.265385
 0.265385  2.17287 )
</pre></div>


<div class="codehilite"><pre><span></span><span class="c"># Fisher scoring using Knitro</span>
<span class="n">vcmodel_knitro</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">vcmodel</span><span class="p">)</span>
<span class="p">@</span><span class="n">time</span> <span class="n">mle_fs!</span><span class="p">(</span><span class="n">vcmodel_knitro</span><span class="p">,</span> <span class="n">vcdatarot</span><span class="p">;</span> <span class="n">solver</span><span class="o">=</span><span class="p">:</span><span class="n">Knitro</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">true</span><span class="p">);</span>
</pre></div>


<div class="codehilite"><pre><span></span>Knitro 10.1.0 STUDENT LICENSE (problem size limit = 300)

=======================================
            Student License
       (NOT FOR COMMERCIAL USE)
         Artelys Knitro 10.1.0
=======================================

Knitro presolve eliminated 0 variables and 0 constraints.

The problem is identified as unconstrained.
Knitro changing algorithm from AUTO to 1.
Knitro changing bar_initpt from AUTO to 3.
Knitro changing bar_murule from AUTO to 4.
Knitro changing bar_penaltycons from AUTO to 1.
Knitro changing bar_penaltyrule from AUTO to 2.
Knitro changing bar_switchrule from AUTO to 1.
Knitro changing linsolver from AUTO to 2.

Problem Characteristics                    ( Presolved)
-----------------------
Objective goal:  Maximize
Number of variables:                     6 (         6)
    bounded below:                       0 (         0)
    bounded above:                       0 (         0)
    bounded below and above:             0 (         0)
    fixed:                               0 (         0)
    free:                                6 (         6)
Number of constraints:                   0 (         0)
    linear equalities:                   0 (         0)
    nonlinear equalities:                0 (         0)
    linear inequalities:                 0 (         0)
    nonlinear inequalities:              0 (         0)
    range:                               0 (         0)
Number of nonzeros in Jacobian:          0 (         0)
Number of nonzeros in Hessian:          21 (        21)

  Iter      Objective      FeasError   OptError    ||Step||    CGits 
--------  --------------  ----------  ----------  ----------  -------
       0   -4.210942e+03   0.000e+00
      10   -3.844387e+03   0.000e+00   2.254e-01   1.390e-02        0
      20   -3.844373e+03   0.000e+00   1.698e-02   1.034e-03        0
      30   -3.844373e+03   0.000e+00   1.250e-03   7.606e-05        0
      40   -3.844373e+03   0.000e+00   9.191e-05   5.591e-06        0

EXIT: Locally optimal solution found.

Final Statistics
----------------
Final objective value               =  -3.84437317330763e+03
Final feasibility error (abs / rel) =   0.00e+00 / 0.00e+00
Final optimality error  (abs / rel) =   9.19e-05 / 9.19e-07
# of iterations                     =         40 
# of CG iterations                  =          0 
# of function evaluations           =         42
# of gradient evaluations           =         42
# of Hessian evaluations            =         40
Total program time (secs)           =       0.18812 (     0.188 CPU time)
Time spent in evaluations (secs)    =       0.18277

===============================================================================

  0.191113 seconds (73.31 k allocations: 4.642 MB)


### Could not find a valid license.
    Your machine ID is 1f-aa-f6-5b-46.
    Please contact licensing@artelys.com or your local distributor to obtain a license.
    If you already have a license, please execute `get_machine_ID -v` and send the output to support.
</pre></div>


<div class="codehilite"><pre><span></span><span class="c"># Knitro estimates</span>
<span class="n">vcmodel_knitro</span><span class="o">.</span><span class="n">B</span>
</pre></div>


<div class="codehilite"><pre><span></span>2x2 Array{Float64,2}:
 1.092     1.04727
 0.955346  1.01632
</pre></div>


<div class="codehilite"><pre><span></span><span class="c"># Knitro estimates</span>
<span class="n">vcmodel_knitro</span><span class="o">.</span><span class="n">Σ</span>
</pre></div>


<div class="codehilite"><pre><span></span>(
2x2 Array{Float64,2}:
  0.380552  -0.305582
 -0.305582   4.52106 ,

2x2 Array{Float64,2}:
 1.84008   0.265385
 0.265385  2.17287 )
</pre></div>


<p><a id='Starting-point-1'></a></p>
<h2 id="starting-point">Starting point</h2>
<p>Here are a few strategies for successful optimization. </p>
<ul>
<li>For $d&gt;1$ (multivariate response), initialize $B, \Sigma$ from univariate estimates.  </li>
<li>Use REML estimate as starting point for MLE.  </li>
<li>When there are only $m=2$ variance components, pre-compute <code>TwoVarCompVariateRotate</code> and use it for optimization.</li>
</ul>
<p><a id='Constrained-estimation-of-B-1'></a></p>
<h2 id="constrained-estimation-of-b">Constrained estimation of <code>B</code></h2>
<p>Many applications invoke constraints on the mean parameters <code>B</code>. For demonstration, we enforce <code>B[1,1]=B[1,2]</code> and all entries of <code>B</code> are within [0, 2].</p>
<div class="codehilite"><pre><span></span><span class="c"># set up constraints on B</span>
<span class="n">vcmodel_constr</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">vcmodel</span><span class="p">)</span>
<span class="n">vcmodel_constr</span><span class="o">.</span><span class="n">A</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span> <span class="mf">0.0</span> <span class="o">-</span><span class="mf">1.0</span> <span class="mf">0.0</span><span class="p">]</span>
<span class="n">vcmodel_constr</span><span class="o">.</span><span class="n">sense</span> <span class="o">=</span> <span class="sc">&#39;=&#39;</span>
<span class="n">vcmodel_constr</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="n">vcmodel_constr</span><span class="o">.</span><span class="n">lb</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="n">vcmodel_constr</span><span class="o">.</span><span class="n">ub</span> <span class="o">=</span> <span class="mf">2.0</span>
<span class="n">vcmodel_constr</span>
</pre></div>


<div class="codehilite"><pre><span></span>VarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(2x2 Array{Float64,2}:
 0.0  0.0
 0.0  0.0,(
2x2 Array{Float64,2}:
 1.0  0.0
 0.0  1.0,

2x2 Array{Float64,2}:
 1.0  0.0
 0.0  1.0),1x4 Array{Float64,2}:
 1.0  0.0  -1.0  0.0,&#39;=&#39;,0.0,0.0,2.0)
</pre></div>


<p>We first try the MM algorithm.</p>
<div class="codehilite"><pre><span></span><span class="c"># MM algorithm for constrained estimation of B</span>
<span class="p">@</span><span class="n">time</span> <span class="n">mle_mm!</span><span class="p">(</span><span class="n">vcmodel_constr</span><span class="p">,</span> <span class="n">vcdatarot</span><span class="p">;</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">funtol</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="n">true</span><span class="p">);</span>
</pre></div>


<div class="codehilite"><pre><span></span>     MM Algorithm
  Iter      Objective  
--------  -------------
       0  -6.253551e+03
       1  -3.881820e+03
       2  -3.853477e+03
       3  -3.846807e+03
       4  -3.845184e+03
       5  -3.844783e+03
       6  -3.844683e+03
       7  -3.844658e+03
       8  -3.844652e+03
       9  -3.844650e+03
      10  -3.844650e+03

  0.095903 seconds (34.73 k allocations: 1.715 MB)
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">fieldnames</span><span class="p">(</span><span class="n">vcmodel_constr</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>7-element Array{Symbol,1}:
 :B    
 :Σ    
 :A    
 :sense
 :b    
 :lb   
 :ub
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">vcmodel_constr</span><span class="o">.</span><span class="n">B</span>
</pre></div>


<div class="codehilite"><pre><span></span>2x2 Array{Float64,2}:
 1.07177   1.07177
 0.955683  1.01591
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">vcmodel_constr</span><span class="o">.</span><span class="n">Σ</span>
</pre></div>


<div class="codehilite"><pre><span></span>(
2x2 Array{Float64,2}:
  0.380624  -0.305498
 -0.305498   4.51948 ,

2x2 Array{Float64,2}:
 1.84051   0.265065
 0.265065  2.17336 )
</pre></div>


<p>Now let's try Fisher scoring.</p>
<div class="codehilite"><pre><span></span><span class="c"># Fisher scoring using Ipopt for constrained estimation of B</span>
<span class="n">vcmodel_constr</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">vcmodel</span><span class="p">)</span>
<span class="n">vcmodel_constr</span><span class="o">.</span><span class="n">A</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span> <span class="mf">0.0</span> <span class="o">-</span><span class="mf">1.0</span> <span class="mf">0.0</span><span class="p">]</span>
<span class="n">vcmodel_constr</span><span class="o">.</span><span class="n">sense</span> <span class="o">=</span> <span class="sc">&#39;=&#39;</span>
<span class="n">vcmodel_constr</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="n">vcmodel_constr</span><span class="o">.</span><span class="n">lb</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="n">vcmodel_constr</span><span class="o">.</span><span class="n">ub</span> <span class="o">=</span> <span class="mf">2.0</span>
<span class="n">vcmodel_constr</span>
<span class="p">@</span><span class="n">time</span> <span class="n">mle_fs!</span><span class="p">(</span><span class="n">vcmodel_constr</span><span class="p">,</span> <span class="n">vcdatarot</span><span class="p">;</span> <span class="n">solver</span><span class="o">=</span><span class="p">:</span><span class="n">Ipopt</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">true</span><span class="p">);</span>
</pre></div>


<div class="codehilite"><pre><span></span>This is Ipopt version 3.12.4, running with linear solver mumps.
NOTE: Other linear solvers might be more efficient (see Ipopt documentation).

Number of nonzeros in equality constraint Jacobian...:        0
Number of nonzeros in inequality constraint Jacobian.:        0
Number of nonzeros in Lagrangian Hessian.............:       21

Total number of variables............................:        6
                     variables with only lower bounds:        0
                variables with lower and upper bounds:        0
                     variables with only upper bounds:        0
Total number of equality constraints.................:        0
Total number of inequality constraints...............:        0
        inequality constraints with only lower bounds:        0
   inequality constraints with lower and upper bounds:        0
        inequality constraints with only upper bounds:        0

iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
   0  4.2114270e+03 0.00e+00 1.00e+02   0.0 0.00e+00    -  0.00e+00 0.00e+00   0 
   5  3.8448353e+03 0.00e+00 7.87e-01 -11.0 4.94e-02    -  1.00e+00 1.00e+00f  1 MaxS
  10  3.8446636e+03 0.00e+00 2.25e-01 -11.0 1.38e-02    -  1.00e+00 1.00e+00f  1 MaxS
  15  3.8446509e+03 0.00e+00 6.23e-02 -11.0 3.78e-03    -  1.00e+00 1.00e+00f  1 MaxS
  20  3.8446499e+03 0.00e+00 1.70e-02 -11.0 1.03e-03    -  1.00e+00 1.00e+00f  1 MaxS
  25  3.8446498e+03 0.00e+00 4.61e-03 -11.0 2.79e-04    -  1.00e+00 1.00e+00f  1 MaxS
  30  3.8446498e+03 0.00e+00 1.25e-03 -11.0 7.56e-05    -  1.00e+00 1.00e+00f  1 MaxS
  35  3.8446498e+03 0.00e+00 3.39e-04 -11.0 2.05e-05    -  1.00e+00 1.00e+00f  1 MaxS
  40  3.8446498e+03 0.00e+00 9.19e-05 -11.0 5.56e-06    -  1.00e+00 1.00e+00f  1 MaxS
  45  3.8446498e+03 0.00e+00 2.49e-05 -11.0 1.51e-06    -  1.00e+00 1.00e+00f  1 MaxS
iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
  50  3.8446498e+03 0.00e+00 6.76e-06 -11.0 4.08e-07    -  1.00e+00 1.00e+00f  1 MaxSA
  55  3.8446498e+03 0.00e+00 1.83e-06 -11.0 1.11e-07    -  1.00e+00 1.00e+00f  1 MaxSA
  60  3.8446498e+03 0.00e+00 4.97e-07 -11.0 3.00e-08    -  1.00e+00 1.00e+00f  1 MaxSA

Number of Iterations....: 63

                                   (scaled)                 (unscaled)
Objective...............:   3.4484507551948582e+02    3.8446498170293421e+03
Dual infeasibility......:   2.2694405419276139e-07    2.5301808793809917e-06
Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00
Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00
Overall NLP error.......:   2.2694405419276139e-07    2.5301808793809917e-06


Number of objective function evaluations             = 64
Number of objective gradient evaluations             = 64
Number of equality constraint evaluations            = 0
Number of inequality constraint evaluations          = 0
Number of equality constraint Jacobian evaluations   = 0
Number of inequality constraint Jacobian evaluations = 0
Number of Lagrangian Hessian evaluations             = 63
Total CPU secs in IPOPT (w/o function evaluations)   =      0.021
Total CPU secs in NLP function evaluations           =      0.650

EXIT: Solved To Acceptable Level.
  0.748622 seconds (160.13 k allocations: 8.986 MB, 17.15% gc time)
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">vcmodel_constr</span><span class="o">.</span><span class="n">B</span>
</pre></div>


<div class="codehilite"><pre><span></span>2x2 Array{Float64,2}:
 1.07177   1.07177
 0.955683  1.01591
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">vcmodel_constr</span><span class="o">.</span><span class="n">Σ</span>
</pre></div>


<div class="codehilite"><pre><span></span>(
2x2 Array{Float64,2}:
  0.380539  -0.305626
 -0.305626   4.52116 ,

2x2 Array{Float64,2}:
 1.8405    0.264881
 0.264881  2.17348 )
</pre></div>
          <aside class="copyright" role="note">
            
            Documentation built with
            <a href="http://www.mkdocs.org" target="_blank">MkDocs</a>
            using the
            <a href="http://squidfunk.github.io/mkdocs-material/" target="_blank">
              Material
            </a>
            theme.
          </aside>
          
            <footer class="footer">
              
  <nav class="pagination" aria-label="Footer">
    <div class="previous">
      
        <a href="../.." title="Home">
          <span class="direction">
            Previous
          </span>
          <div class="page">
            <div class="button button-previous" role="button" aria-label="Previous">
              <i class="icon icon-back"></i>
            </div>
            <div class="stretch">
              <div class="title">
                Home
              </div>
            </div>
          </div>
        </a>
      
    </div>
    <div class="next">
      
        <a href="../heritability/" title="Heritability">
          <span class="direction">
            Next
          </span>
          <div class="page">
            <div class="stretch">
              <div class="title">
                Heritability
              </div>
            </div>
            <div class="button button-next" role="button" aria-label="Next">
              <i class="icon icon-forward"></i>
            </div>
          </div>
        </a>
      
    </div>
  </nav>

            </footer>
          
        </div>
      </article>
      <div class="results" role="status" aria-live="polite">
        <div class="scrollable">
          <div class="wrapper">
            <div class="meta"></div>
            <div class="list"></div>
          </div>
        </div>
      </div>
    </main>
    <script>
      var base_url = '../..';
      var repo_id  = 'OpenMendel/VarianceComponentModels.jl';
    </script>
    <script src="../../assets/javascripts/application-997097ee0c.js"></script>
    
      <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    
      <script src="../../assets/mathjaxhelper.js"></script>
    
    
  </body>
</html>