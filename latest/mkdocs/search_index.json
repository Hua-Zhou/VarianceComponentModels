{
    "docs": [
        {
            "location": "/", 
            "text": "VarianceComponentModels.jl\n\n\nUtilities for fitting and testing variance component models\n\n\nVarianceComponentModels.jl implements computation routines for fitting and testing variance component model of form\n\n\n$\\text{vec}(Y) \\sim \\text{Nomral}(X B, \\Sigma_1 \\otimes V_1 + \\cdots + \\Sigma_m \\otimes V_m),$\n\n\nwhere $\\otimes$ is the \nKronecker product\n.\n\n\nIn this model, \ndata\n is represented by  \n\n\n\n\nY\n: \nn x d\n response matrix  \n\n\nX\n: \nn x p\n covariate matrix  \n\n\nV=(V1,...,Vm)\n: a tuple \nm\n \nn x n\n covariance matrices  \n\n\n\n\nand \nparameters\n are  \n\n\n\n\nB\n: \np x d\n mean parameter matrix  \n\n\n\u03a3=(\u03a31,...,\u03a3m)\n: a tuple of \nm\n \nd x d\n variance components  \n\n\n\n\n\n\nPackage Features\n\n\n\n\nMaximum likelihood estimation (MLE) and restricted maximum likelihood estimation (REML) of mean parameters \nB\n and variance component parameters \n\u03a3\n   \n\n\nAllow constrains in the mean parameters \nB\n  \n\n\nChoice of optimization algorithms: \nFisher scoring\n and \nminorization-maximization algorithm\n  \n\n\nHeritability Analysis\n in genetics  \n\n\n\n\n\n\nInstallation\n\n\nUse the Julia package manager to install VarianceComponentModels.jl.\n\n\nPkg\n.\nclone\n(\ngit@github.com:OpenMendel/VarianceComponentModels.jl.git\n)\n\n\n\n\n\n\nThis package supports Julia \n0.4\n.\n\n\n\n\nManual Outline\n\n\n\n\nMLE and REML\n\n\nDemo data\n\n\nMaximum likelihood estimation (MLE)\n\n\nRestricted maximum likelihood estimation (REML)\n\n\nOptimization algorithms\n\n\nStarting point\n\n\nConstrained estimation of \nB\n\n\n\n\n\n\nHeritability Analysis\n\n\nRead in binary SNP data\n\n\nSummary statistics of SNP data\n\n\nEmpirical kinship matrix\n\n\nPhenotypes\n\n\nPre-processing data for heritability analysis\n\n\nSave intermediate results\n\n\nHeritability of single traits\n\n\nPairwise traits\n\n\n3-trait analysis\n\n\nSave analysis results", 
            "title": "Home"
        }, 
        {
            "location": "/#variancecomponentmodelsjl", 
            "text": "Utilities for fitting and testing variance component models  VarianceComponentModels.jl implements computation routines for fitting and testing variance component model of form  $\\text{vec}(Y) \\sim \\text{Nomral}(X B, \\Sigma_1 \\otimes V_1 + \\cdots + \\Sigma_m \\otimes V_m),$  where $\\otimes$ is the  Kronecker product .  In this model,  data  is represented by     Y :  n x d  response matrix    X :  n x p  covariate matrix    V=(V1,...,Vm) : a tuple  m   n x n  covariance matrices     and  parameters  are     B :  p x d  mean parameter matrix    \u03a3=(\u03a31,...,\u03a3m) : a tuple of  m   d x d  variance components", 
            "title": "VarianceComponentModels.jl"
        }, 
        {
            "location": "/#package-features", 
            "text": "Maximum likelihood estimation (MLE) and restricted maximum likelihood estimation (REML) of mean parameters  B  and variance component parameters  \u03a3      Allow constrains in the mean parameters  B     Choice of optimization algorithms:  Fisher scoring  and  minorization-maximization algorithm     Heritability Analysis  in genetics", 
            "title": "Package Features"
        }, 
        {
            "location": "/#installation", 
            "text": "Use the Julia package manager to install VarianceComponentModels.jl.  Pkg . clone ( git@github.com:OpenMendel/VarianceComponentModels.jl.git )   This package supports Julia  0.4 .", 
            "title": "Installation"
        }, 
        {
            "location": "/#manual-outline", 
            "text": "MLE and REML  Demo data  Maximum likelihood estimation (MLE)  Restricted maximum likelihood estimation (REML)  Optimization algorithms  Starting point  Constrained estimation of  B    Heritability Analysis  Read in binary SNP data  Summary statistics of SNP data  Empirical kinship matrix  Phenotypes  Pre-processing data for heritability analysis  Save intermediate results  Heritability of single traits  Pairwise traits  3-trait analysis  Save analysis results", 
            "title": "Manual Outline"
        }, 
        {
            "location": "/man/mle_reml/", 
            "text": "MLE and REML\n\n\n\n\nDemo data\n\n\nFor demonstration, we generate a random data set.\n\n\n# generate data from a d-variate response variane component model\n\n\nsrand\n(\n123\n)\n\n\nn\n \n=\n \n1000\n   \n# no. observations\n\n\nd\n \n=\n \n2\n      \n# dimension of responses\n\n\nm\n \n=\n \n2\n      \n# no. variance components\n\n\np\n \n=\n \n2\n      \n# no. covariates\n\n\n# n-by-p design matrix\n\n\nX\n \n=\n \nrandn\n(\nn\n,\n \np\n)\n\n\n# p-by-d mean component regression coefficient\n\n\nB\n \n=\n \nones\n(\np\n,\n \nd\n)\n  \n\n# a tuple of m covariance matrices\n\n\nV\n \n=\n \nntuple\n(\nx\n \n-\n \nzeros\n(\nn\n,\n \nn\n),\n \nm\n)\n \n\nfor\n \ni\n \n=\n \n1\n:\nm\n-\n1\n\n  \nVi\n \n=\n \nrandn\n(\nn\n,\n \n50\n)\n\n  \ncopy!\n(\nV\n[\ni\n],\n \nVi\n \n*\n \nVi\n)\n\n\nend\n\n\ncopy!\n(\nV\n[\nm\n],\n \neye\n(\nn\n))\n \n# last covarianec matrix is idendity\n\n\n# a tuple of m d-by-d variance component parameters\n\n\n\u03a3\n \n=\n \nntuple\n(\nx\n \n-\n \nzeros\n(\nd\n,\n \nd\n),\n \nm\n)\n \n\nfor\n \ni\n \nin\n \n1\n:\nm\n\n  \n\u03a3i\n \n=\n \nrandn\n(\nd\n,\n \nd\n)\n\n  \ncopy!\n(\n\u03a3\n[\ni\n],\n \n\u03a3i\n \n*\n \n\u03a3i\n)\n\n\nend\n\n\n# form overall nd-by-nd covariance matrix \u03a9\n\n\n\u03a9\n \n=\n \nzeros\n(\nn\n \n*\n \nd\n,\n \nn\n \n*\n \nd\n)\n\n\nfor\n \ni\n \n=\n \n1\n:\nm\n\n  \n\u03a9\n \n+=\n \nkron\n(\n\u03a3\n[\ni\n],\n \nV\n[\ni\n])\n\n\nend\n\n\n\u03a9chol\n \n=\n \ncholfact\n(\n\u03a9\n)\n\n\n# n-by-d responses\n\n\nY\n \n=\n \nX\n \n*\n \nB\n \n+\n \nreshape\n(\n\u03a9chol\n[:\nL\n]\n \n*\n \nrandn\n(\nn\n*\nd\n),\n \nn\n,\n \nd\n);\n\n\n\n\n\n\n\n\nMaximum likelihood estimation (MLE)\n\n\nTo find the MLE of parameters $(B,\\Sigma_1,\\ldots,\\Sigma_m)$, we take 3 steps:  \n\n\nStep 1 (Construct data)\n. Construct an instance of \nVarianceComponentVariate\n, which consists fields  \n\n\n\n\nY\n: $n$-by-$d$ responses  \n\n\nX\n: $n$-by-$p$ covariate matrix  \n\n\nV=(V[1],...,V[m])\n: a tuple of $n$-by-$n$ covariance matrices. The last covariance matrix must be positive definite and usually is the identity matrix. \n\n\n\n\nusing\n \nVarianceComponentModels\n\n\nvcdata\n \n=\n \nVarianceComponentVariate\n(\nY\n,\n \nX\n,\n \nV\n)\n\n\nfieldnames\n(\nvcdata\n)\n\n\n\n\n\n\n3-element Array{Symbol,1}:\n :Y\n :X\n :V\n\n\n\n\n\nIn the absence of covariates $X$, we can simply initialize by \nvcdata = VarianceComponentVariate(Y, V)\n.\n\n\nStep 2 (Construct a model)\n. Construct an instance of \nVarianceComponentModel\n, which consists of fields  \n\n\n\n\nB\n: $n$-by-$p$ mean regression coefficients  \n\n\n\u03a3=(\u03a3[1],...,\u03a3[m])\n: variane component parameters respectively. \n\n\n\n\nWhen constructed from a \nVarianceComponentVariate\n instance, the mean parameters $B$ are initialized to be zero and the tuple of variance component parameters $\\Sigma$ to be \n(eye(d),...,eye(d))\n.\n\n\nvcmodel\n \n=\n \nVarianceComponentModel\n(\nvcdata\n)\n\n\nfieldnames\n(\nvcmodel\n)\n\n\n\n\n\n\n7-element Array{Symbol,1}:\n :B    \n :\u03a3    \n :A    \n :sense\n :b    \n :lb   \n :ub\n\n\n\n\n\nvcmodel\n\n\n\n\n\n\nVarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(2x2 Array{Float64,2}:\n 0.0  0.0\n 0.0  0.0,(\n2x2 Array{Float64,2}:\n 1.0  0.0\n 0.0  1.0,\n\n2x2 Array{Float64,2}:\n 1.0  0.0\n 0.0  1.0),0x4 Array{Float64,2},Char[],Float64[],-Inf,Inf)\n\n\n\n\n\nThe remaining fields \nA\n, \nsense\n, \nb\n, \nlb\n, \nub\n specify (optional) constraints on the mean parameters \nB\n:\n\n\n$A * \\text{vec}(B) \\,\\, =(\\text{or } \\ge \\text{or } \\le) \\,\\, b$\n\n\n$lb \\le \\text{vec}(B) \\le ub$\n\n\nA\n is an constraint matrix with $pd$ columns, \nsense\n is a vector of charaters taking values \n'\n'\n, \n'='\n or \n'\n'\n, and \nlb\n and \nub\n are the lower and upper bounds for \nvec(B)\n. By default, \nA\n, \nsense\n, \nb\n are empty, \nlb\n is \n-Inf\n, and \nub\n is \nInf\n. If any constraits are non-trivial, final estimates of \nB\n are enforced to satisfy them.\n\n\nWhen a better initial guess is available, we can initialize by calling \nvcmodel=VarianceComponentModel(B0, \u03a30)\n directly.\n\n\nStep 3 (Fit model)\n. Call optmization routine \nfit_mle!\n. The keywork \nalgo\n dictates the optimization algorithm: \n:MM\n (minorization-maximization algorithm) or \n:FS\n (Fisher scoring algorithm).\n\n\nvcmodel_mle\n \n=\n \ndeepcopy\n(\nvcmodel\n)\n\n\n@\ntime\n \nlogl\n,\n \nvcmodel_mle\n,\n \n\u03a3se\n,\n \n\u03a3cov\n,\n \nBse\n,\n \nBcov\n \n=\n \nfit_mle!\n(\nvcmodel_mle\n,\n \nvcdata\n;\n \nalgo\n \n=\n \n:\nMM\n);\n\n\n\n\n\n\n     MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0  -6.253551e+03\n       1  -3.881454e+03\n       2  -3.853179e+03\n       3  -3.846525e+03\n       4  -3.844906e+03\n       5  -3.844506e+03\n       6  -3.844406e+03\n       7  -3.844381e+03\n       8  -3.844375e+03\n       9  -3.844374e+03\n      10  -3.844373e+03\n\n  0.369037 seconds (13.81 k allocations: 23.961 MB, 1.31% gc time)\n\n\n\n\n\nThe output of \nfit_mle!\n contains  \n\n\n\n\nfinal log-likelihood  \n\n\n\n\nlogl\n\n\n\n\n\n\n-3844.373181418088\n\n\n\n\n\n\n\nfitted model\n\n\n\n\nfieldnames\n(\nvcmodel_mle\n)\n\n\n\n\n\n\n7-element Array{Symbol,1}:\n :B    \n :\u03a3    \n :A    \n :sense\n :b    \n :lb   \n :ub\n\n\n\n\n\nvcmodel_mle\n\n\n\n\n\n\nVarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(2x2 Array{Float64,2}:\n 1.092     1.04727\n 0.955346  1.01632,(\n2x2 Array{Float64,2}:\n  0.380637  -0.305465\n -0.305465   4.51938 ,\n\n2x2 Array{Float64,2}:\n 1.84009   0.265569\n 0.265569  2.17275 ),0x4 Array{Float64,2},Char[],Float64[],-Inf,Inf)\n\n\n\n\n\n\n\nstandard errors of the estimated varianec component parameters\n\n\n\n\n\u03a3se\n\n\n\n\n\n\n(\n2x2 Array{Float64,2}:\n 0.0765136  0.263047\n 0.263047   0.904332,\n\n2x2 Array{Float64,2}:\n 0.0844292  0.0917441\n 0.0917441  0.0996927)\n\n\n\n\n\n\n\ncovariance matrix of the variance component parameters estimates\n\n\n\n\n\u03a3cov\n\n\n\n\n\n\n8x8 Array{Float64,2}:\n  0.00585433  -0.00467019  -0.00467019  \u2026  -1.07903e-6   -1.557e-7   \n -0.00467019   0.0691937    0.00372555     -1.557e-7     -1.27444e-6 \n -0.00467019   0.00372555   0.0691937      -8.83212e-6   -1.27444e-6 \n  0.00372555  -0.055198    -0.055198       -1.27444e-6   -1.04316e-5 \n -7.4779e-6   -1.07903e-6  -1.07903e-6      0.00102878    0.000148477\n -1.07903e-6  -8.83212e-6  -1.557e-7    \u2026   0.000148477   0.00121477 \n -1.07903e-6  -1.557e-7    -8.83212e-6      0.00841698    0.00121477 \n -1.557e-7    -1.27444e-6  -1.27444e-6      0.00121477    0.00993864\n\n\n\n\n\n\n\nstandard errors of the estimated mean parameters\n\n\n\n\nBse\n\n\n\n\n\n\n2x2 Array{Float64,2}:\n 0.042556   0.0483538\n 0.0430622  0.0495727\n\n\n\n\n\n\n\ncovariance matrix of the mean parameter estimates\n\n\n\n\nBcov\n\n\n\n\n\n\n4x4 Array{Float64,2}:\n  0.00181101   -1.98163e-5    0.000243689  -2.44708e-6 \n -1.98163e-5    0.00185435   -2.44708e-6    0.000243907\n  0.000243689  -2.44708e-6    0.00233809   -2.80614e-5 \n -2.44708e-6    0.000243907  -2.80614e-5    0.00245745\n\n\n\n\n\n\n\nRestricted maximum likelihood estimation (REML)\n\n\nREML (restricted maximum likelihood estimation)\n is a popular alternative to the MLE. To find the REML of a variane component model, we replace the above step 3 by  \n\n\nStep 3\n. Call optmization routine \nfit_reml!\n.\n\n\nvcmodel_reml\n \n=\n \ndeepcopy\n(\nvcmodel\n)\n\n\n@\ntime\n \nlogl\n,\n \nvcmodel_reml\n,\n \n\u03a3se\n,\n \n\u03a3cov\n,\n \nBse\n,\n \nBcov\n \n=\n \nfit_reml!\n(\nvcmodel_reml\n,\n \nvcdata\n;\n \nalgo\n \n=\n \n:\nMM\n);\n\n\n\n\n\n\n     MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0  -4.215053e+03\n       1  -3.925799e+03\n       2  -3.865114e+03\n       3  -3.851105e+03\n       4  -3.847732e+03\n       5  -3.846903e+03\n       6  -3.846698e+03\n       7  -3.846647e+03\n       8  -3.846634e+03\n       9  -3.846631e+03\n      10  -3.846630e+03\n\n  0.677764 seconds (16.35 k allocations: 62.680 MB, 1.06% gc time)\n\n\n\n\n\nThe output of \nfit_reml!\n contains\n\n\n\n\nthe final log-likelihood at REML estimate\n\n\n\n\nlogl\n\n\n\n\n\n\n-3844.377717902519\n\n\n\n\n\n\n\nREML estimates\n\n\n\n\nfieldnames\n(\nvcmodel_reml\n)\n\n\n\n\n\n\n7-element Array{Symbol,1}:\n :B    \n :\u03a3    \n :A    \n :sense\n :b    \n :lb   \n :ub\n\n\n\n\n\nvcmodel_reml\n\n\n\n\n\n\nVarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(2x2 Array{Float64,2}:\n 1.092     1.04727\n 0.955345  1.01632,(\n2x2 Array{Float64,2}:\n  0.380594  -0.305485\n -0.305485   4.51994 ,\n\n2x2 Array{Float64,2}:\n 1.84285   0.261963\n 0.261963  2.17842 ),0x4 Array{Float64,2},Char[],Float64[],-Inf,Inf)\n\n\n\n\n\n\n\nstandard errors of the estimated varianec component parameters\n\n\n\n\n\u03a3se\n\n\n\n\n\n\n(\n2x2 Array{Float64,2}:\n 0.0765055  0.26305 \n 0.26305    0.904446,\n\n2x2 Array{Float64,2}:\n 0.0845559  0.0919325\n 0.0919325  0.0999526)\n\n\n\n\n\n\n\ncovariance matrix of the variance component parameters estimates\n\n\n\n\n\u03a3cov\n\n\n\n\n\n\n8x8 Array{Float64,2}:\n  0.0058531   -0.00467005  -0.00467005  \u2026  -1.06597e-6   -1.51499e-7 \n -0.00467005   0.0691951    0.00372613     -1.51499e-7   -1.26041e-6 \n -0.00467005   0.00372613   0.0691951      -8.86843e-6   -1.26041e-6 \n  0.00372613  -0.0552092   -0.0552092      -1.26041e-6   -1.0486e-5  \n -7.50035e-6  -1.06597e-6  -1.06597e-6      0.00101633    0.000144472\n -1.06597e-6  -8.86843e-6  -1.51499e-7  \u2026   0.000144472   0.0012014  \n -1.06597e-6  -1.51499e-7  -8.86843e-6      0.00845158    0.0012014  \n -1.51499e-7  -1.26041e-6  -1.26041e-6      0.0012014     0.00999052\n\n\n\n\n\n\n\nstandard errors of the estimated mean parameters\n\n\n\n\nBse\n\n\n\n\n\n\n2x2 Array{Float64,2}:\n 0.0425878  0.0484189\n 0.0430944  0.04964\n\n\n\n\n\n\n\ncovariance matrix of the mean parameter estimates\n\n\n\n\nBcov\n\n\n\n\n\n\n4x4 Array{Float64,2}:\n  0.00181372   -1.9846e-5    0.000240116  -2.40768e-6\n -1.9846e-5     0.00185713  -2.40768e-6    0.00024024\n  0.000240116  -2.40768e-6   0.00234439   -2.81393e-5\n -2.40768e-6    0.00024024  -2.81393e-5    0.00246413\n\n\n\n\n\n\n\nOptimization algorithms\n\n\nFinding the MLE or REML of variance component models is a non-trivial nonlinear optimization problem. The main complications are the non-convexity of objective function and the positive semi-definiteness constraint of variane component parameters $\\Sigma_1,\\ldots,\\Sigma_m$. In specific applications, users should try different algorithms with different starting points in order to find a better solution. Here are some tips for efficient computation. \n\n\nIn general the optimization algorithm needs to invert the $nd$ by $nd$ overall covariance matrix $\\Omega = \\Sigma_1 \\otimes V_1 + \\cdots + \\Sigma_m \\otimes V_m$ in each iteration. Inverting a matrix is an expensive operation with $O(n^3 d^3)$ floating operations. When there are only \ntwo\n varianec components ($m=2$), this tedious task can be avoided by taking one (generalized) eigendecomposion of $(V_1, V_2)$ and rotating data $(Y, X)$ by the eigen-vectors. \n\n\nvcdatarot\n \n=\n \nTwoVarCompVariateRotate\n(\nvcdata\n)\n\n\nfieldnames\n(\nvcdatarot\n)\n\n\n\n\n\n\n4-element Array{Symbol,1}:\n :Yrot    \n :Xrot    \n :eigval  \n :logdetV2\n\n\n\n\n\nTwo optimization algorithms are implemented: \nFisher scoring\n (\nmle_fs!\n) and the \nminorization-maximization (MM) algorithm\n (\nmle_mm!\n). Both take the rotated data as input. These two functions give finer control of the optimization algorithms. Generally speaking, MM algorithm is more stable while Fisher scoring (if it converges) yields more accurate answer.\n\n\nvcmodel_mm\n \n=\n \ndeepcopy\n(\nvcmodel\n)\n\n\n@\ntime\n \nmle_mm!\n(\nvcmodel_mm\n,\n \nvcdatarot\n;\n \nmaxiter\n=\n10000\n,\n \nfuntol\n=\n1e-8\n,\n \nverbose\n \n=\n \ntrue\n);\n\n\n\n\n\n\n     MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0  -6.253551e+03\n       1  -3.881454e+03\n       2  -3.853179e+03\n       3  -3.846525e+03\n       4  -3.844906e+03\n       5  -3.844506e+03\n       6  -3.844406e+03\n       7  -3.844381e+03\n       8  -3.844375e+03\n       9  -3.844374e+03\n      10  -3.844373e+03\n\n  0.021236 seconds (9.75 k allocations: 619.875 KB)\n\n\n\n\n\n# MM estimates\n\n\nvcmodel_mm\n.\nB\n\n\n\n\n\n\n2x2 Array{Float64,2}:\n 1.092     1.04727\n 0.955346  1.01632\n\n\n\n\n\n# MM estimates\n\n\nvcmodel_mm\n.\n\u03a3\n\n\n\n\n\n\n(\n2x2 Array{Float64,2}:\n  0.380637  -0.305465\n -0.305465   4.51938 ,\n\n2x2 Array{Float64,2}:\n 1.84009   0.265569\n 0.265569  2.17275 )\n\n\n\n\n\nFisher scoring (\nmle_fs!\n) uses either \nIpopt.jl\n (keyword \nsolver=:Ipopt\n) or \nKNITRO.jl\n (keyword \nsolver=:Knitro\n) as the backend solver. Ipopt is open source and installation of \nIpopt.jl\n package alone is sufficient. Knitro is a commercial software and users need to follow instructions at \nKNITRO.jl\n for proper functioning.\n\n\n# Fisher scoring using Ipopt\n\n\nvcmodel_ipopt\n \n=\n \ndeepcopy\n(\nvcmodel\n)\n\n\n@\ntime\n \nmle_fs!\n(\nvcmodel_ipopt\n,\n \nvcdatarot\n;\n \nsolver\n=\n:\nIpopt\n,\n \nmaxiter\n=\n1000\n,\n \nverbose\n=\ntrue\n);\n\n\n\n\n\n\nThis is Ipopt version 3.12.4, running with linear solver mumps.\nNOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n\nNumber of nonzeros in equality constraint Jacobian...:        0\nNumber of nonzeros in inequality constraint Jacobian.:        0\nNumber of nonzeros in Lagrangian Hessian.............:       21\n\nTotal number of variables............................:        6\n                     variables with only lower bounds:        0\n                variables with lower and upper bounds:        0\n                     variables with only upper bounds:        0\nTotal number of equality constraints.................:        0\nTotal number of inequality constraints...............:        0\n        inequality constraints with only lower bounds:        0\n   inequality constraints with lower and upper bounds:        0\n        inequality constraints with only upper bounds:        0\n\niter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n   0  4.2109423e+03 0.00e+00 1.00e+02   0.0 0.00e+00    -  0.00e+00 0.00e+00   0 \n   5  3.8445586e+03 0.00e+00 7.87e-01 -11.0 4.94e-02    -  1.00e+00 1.00e+00f  1 MaxS\n  10  3.8443870e+03 0.00e+00 2.25e-01 -11.0 1.38e-02    -  1.00e+00 1.00e+00f  1 MaxS\n  15  3.8443742e+03 0.00e+00 6.23e-02 -11.0 3.78e-03    -  1.00e+00 1.00e+00f  1 MaxS\n  20  3.8443733e+03 0.00e+00 1.70e-02 -11.0 1.03e-03    -  1.00e+00 1.00e+00f  1 MaxS\n  25  3.8443732e+03 0.00e+00 4.61e-03 -11.0 2.79e-04    -  1.00e+00 1.00e+00f  1 MaxS\n  30  3.8443732e+03 0.00e+00 1.25e-03 -11.0 7.56e-05    -  1.00e+00 1.00e+00f  1 MaxS\n  35  3.8443732e+03 0.00e+00 3.39e-04 -11.0 2.05e-05    -  1.00e+00 1.00e+00f  1 MaxS\n  40  3.8443732e+03 0.00e+00 9.19e-05 -11.0 5.55e-06    -  1.00e+00 1.00e+00f  1 MaxS\n  45  3.8443732e+03 0.00e+00 2.49e-05 -11.0 1.51e-06    -  1.00e+00 1.00e+00f  1 MaxS\niter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n  50  3.8443732e+03 0.00e+00 6.76e-06 -11.0 4.08e-07    -  1.00e+00 1.00e+00f  1 MaxSA\n  55  3.8443732e+03 0.00e+00 1.83e-06 -11.0 1.11e-07    -  1.00e+00 1.00e+00f  1 MaxSA\n  60  3.8443732e+03 0.00e+00 4.97e-07 -11.0 3.00e-08    -  1.00e+00 1.00e+00h  1 MaxSA\n\nNumber of Iterations....: 63\n\n                                   (scaled)                 (unscaled)\nObjective...............:   3.4496886481727671e+02    3.8443731733053760e+03\nDual infeasibility......:   2.2693632135739328e-07    2.5290047736252332e-06\nConstraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\nComplementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00\nOverall NLP error.......:   2.2693632135739328e-07    2.5290047736252332e-06\n\n\nNumber of objective function evaluations             = 64\nNumber of objective gradient evaluations             = 64\nNumber of equality constraint evaluations            = 0\nNumber of inequality constraint evaluations          = 0\nNumber of equality constraint Jacobian evaluations   = 0\nNumber of inequality constraint Jacobian evaluations = 0\nNumber of Lagrangian Hessian evaluations             = 63\nTotal CPU secs in IPOPT (w/o function evaluations)   =      0.019\nTotal CPU secs in NLP function evaluations           =      0.263\n\nEXIT: Solved To Acceptable Level.\n  0.314060 seconds (110.60 k allocations: 6.978 MB)\n\n\n\n\n\n# Ipopt estimates\n\n\nvcmodel_ipopt\n.\nB\n\n\n\n\n\n\n2x2 Array{Float64,2}:\n 1.092     1.04727\n 0.955346  1.01632\n\n\n\n\n\n# Ipopt estimates\n\n\nvcmodel_ipopt\n.\n\u03a3\n\n\n\n\n\n\n(\n2x2 Array{Float64,2}:\n  0.380552  -0.305594\n -0.305594   4.52106 ,\n\n2x2 Array{Float64,2}:\n 1.84008   0.265385\n 0.265385  2.17287 )\n\n\n\n\n\n# Fisher scoring using Knitro\n\n\nvcmodel_knitro\n \n=\n \ndeepcopy\n(\nvcmodel\n)\n\n\n@\ntime\n \nmle_fs!\n(\nvcmodel_knitro\n,\n \nvcdatarot\n;\n \nsolver\n=\n:\nKnitro\n,\n \nmaxiter\n=\n1000\n,\n \nverbose\n=\ntrue\n);\n\n\n\n\n\n\nKnitro 10.1.0 STUDENT LICENSE (problem size limit = 300)\n\n=======================================\n            Student License\n       (NOT FOR COMMERCIAL USE)\n         Artelys Knitro 10.1.0\n=======================================\n\nKnitro presolve eliminated 0 variables and 0 constraints.\n\nThe problem is identified as unconstrained.\nKnitro changing algorithm from AUTO to 1.\nKnitro changing bar_initpt from AUTO to 3.\nKnitro changing bar_murule from AUTO to 4.\nKnitro changing bar_penaltycons from AUTO to 1.\nKnitro changing bar_penaltyrule from AUTO to 2.\nKnitro changing bar_switchrule from AUTO to 1.\nKnitro changing linsolver from AUTO to 2.\n\nProblem Characteristics                    ( Presolved)\n-----------------------\nObjective goal:  Maximize\nNumber of variables:                     6 (         6)\n    bounded below:                       0 (         0)\n    bounded above:                       0 (         0)\n    bounded below and above:             0 (         0)\n    fixed:                               0 (         0)\n    free:                                6 (         6)\nNumber of constraints:                   0 (         0)\n    linear equalities:                   0 (         0)\n    nonlinear equalities:                0 (         0)\n    linear inequalities:                 0 (         0)\n    nonlinear inequalities:              0 (         0)\n    range:                               0 (         0)\nNumber of nonzeros in Jacobian:          0 (         0)\nNumber of nonzeros in Hessian:          21 (        21)\n\n  Iter      Objective      FeasError   OptError    ||Step||    CGits \n--------  --------------  ----------  ----------  ----------  -------\n       0   -4.210942e+03   0.000e+00\n      10   -3.844387e+03   0.000e+00   2.254e-01   1.390e-02        0\n      20   -3.844373e+03   0.000e+00   1.698e-02   1.034e-03        0\n      30   -3.844373e+03   0.000e+00   1.250e-03   7.606e-05        0\n      40   -3.844373e+03   0.000e+00   9.191e-05   5.591e-06        0\n\nEXIT: Locally optimal solution found.\n\nFinal Statistics\n----------------\nFinal objective value               =  -3.84437317330763e+03\nFinal feasibility error (abs / rel) =   0.00e+00 / 0.00e+00\nFinal optimality error  (abs / rel) =   9.19e-05 / 9.19e-07\n# of iterations                     =         40 \n# of CG iterations                  =          0 \n# of function evaluations           =         42\n# of gradient evaluations           =         42\n# of Hessian evaluations            =         40\nTotal program time (secs)           =       0.18812 (     0.188 CPU time)\nTime spent in evaluations (secs)    =       0.18277\n\n===============================================================================\n\n  0.191113 seconds (73.31 k allocations: 4.642 MB)\n\n\n### Could not find a valid license.\n    Your machine ID is 1f-aa-f6-5b-46.\n    Please contact licensing@artelys.com or your local distributor to obtain a license.\n    If you already have a license, please execute `get_machine_ID -v` and send the output to support.\n\n\n\n\n\n# Knitro estimates\n\n\nvcmodel_knitro\n.\nB\n\n\n\n\n\n\n2x2 Array{Float64,2}:\n 1.092     1.04727\n 0.955346  1.01632\n\n\n\n\n\n# Knitro estimates\n\n\nvcmodel_knitro\n.\n\u03a3\n\n\n\n\n\n\n(\n2x2 Array{Float64,2}:\n  0.380552  -0.305582\n -0.305582   4.52106 ,\n\n2x2 Array{Float64,2}:\n 1.84008   0.265385\n 0.265385  2.17287 )\n\n\n\n\n\n\n\nStarting point\n\n\nHere are a few strategies for successful optimization. \n\n\n\n\nFor $d\n1$ (multivariate response), initialize $B, \\Sigma$ from univariate estimates.  \n\n\nUse REML estimate as starting point for MLE.  \n\n\nWhen there are only $m=2$ variance components, pre-compute \nTwoVarCompVariateRotate\n and use it for optimization.\n\n\n\n\n\n\nConstrained estimation of \nB\n\n\nMany applications invoke constraints on the mean parameters \nB\n. For demonstration, we enforce \nB[1,1]=B[1,2]\n and all entries of \nB\n are within [0, 2].\n\n\n# set up constraints on B\n\n\nvcmodel_constr\n \n=\n \ndeepcopy\n(\nvcmodel\n)\n\n\nvcmodel_constr\n.\nA\n \n=\n \n[\n1.0\n \n0.0\n \n-\n1.0\n \n0.0\n]\n\n\nvcmodel_constr\n.\nsense\n \n=\n \n=\n\n\nvcmodel_constr\n.\nb\n \n=\n \n0.0\n\n\nvcmodel_constr\n.\nlb\n \n=\n \n0.0\n\n\nvcmodel_constr\n.\nub\n \n=\n \n2.0\n\n\nvcmodel_constr\n\n\n\n\n\n\nVarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(2x2 Array{Float64,2}:\n 0.0  0.0\n 0.0  0.0,(\n2x2 Array{Float64,2}:\n 1.0  0.0\n 0.0  1.0,\n\n2x2 Array{Float64,2}:\n 1.0  0.0\n 0.0  1.0),1x4 Array{Float64,2}:\n 1.0  0.0  -1.0  0.0,\n=\n,0.0,0.0,2.0)\n\n\n\n\n\nWe first try the MM algorithm.\n\n\n# MM algorithm for constrained estimation of B\n\n\n@\ntime\n \nmle_mm!\n(\nvcmodel_constr\n,\n \nvcdatarot\n;\n \nmaxiter\n=\n10000\n,\n \nfuntol\n=\n1e-8\n,\n \nverbose\n \n=\n \ntrue\n);\n\n\n\n\n\n\n     MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0  -6.253551e+03\n       1  -3.881820e+03\n       2  -3.853477e+03\n       3  -3.846807e+03\n       4  -3.845184e+03\n       5  -3.844783e+03\n       6  -3.844683e+03\n       7  -3.844658e+03\n       8  -3.844652e+03\n       9  -3.844650e+03\n      10  -3.844650e+03\n\n  0.095903 seconds (34.73 k allocations: 1.715 MB)\n\n\n\n\n\nfieldnames\n(\nvcmodel_constr\n)\n\n\n\n\n\n\n7-element Array{Symbol,1}:\n :B    \n :\u03a3    \n :A    \n :sense\n :b    \n :lb   \n :ub\n\n\n\n\n\nvcmodel_constr\n.\nB\n\n\n\n\n\n\n2x2 Array{Float64,2}:\n 1.07177   1.07177\n 0.955683  1.01591\n\n\n\n\n\nvcmodel_constr\n.\n\u03a3\n\n\n\n\n\n\n(\n2x2 Array{Float64,2}:\n  0.380624  -0.305498\n -0.305498   4.51948 ,\n\n2x2 Array{Float64,2}:\n 1.84051   0.265065\n 0.265065  2.17336 )\n\n\n\n\n\nNow let's try Fisher scoring.\n\n\n# Fisher scoring using Ipopt for constrained estimation of B\n\n\nvcmodel_constr\n \n=\n \ndeepcopy\n(\nvcmodel\n)\n\n\nvcmodel_constr\n.\nA\n \n=\n \n[\n1.0\n \n0.0\n \n-\n1.0\n \n0.0\n]\n\n\nvcmodel_constr\n.\nsense\n \n=\n \n=\n\n\nvcmodel_constr\n.\nb\n \n=\n \n0.0\n\n\nvcmodel_constr\n.\nlb\n \n=\n \n0.0\n\n\nvcmodel_constr\n.\nub\n \n=\n \n2.0\n\n\nvcmodel_constr\n\n\n@\ntime\n \nmle_fs!\n(\nvcmodel_constr\n,\n \nvcdatarot\n;\n \nsolver\n=\n:\nIpopt\n,\n \nmaxiter\n=\n1000\n,\n \nverbose\n=\ntrue\n);\n\n\n\n\n\n\nThis is Ipopt version 3.12.4, running with linear solver mumps.\nNOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n\nNumber of nonzeros in equality constraint Jacobian...:        0\nNumber of nonzeros in inequality constraint Jacobian.:        0\nNumber of nonzeros in Lagrangian Hessian.............:       21\n\nTotal number of variables............................:        6\n                     variables with only lower bounds:        0\n                variables with lower and upper bounds:        0\n                     variables with only upper bounds:        0\nTotal number of equality constraints.................:        0\nTotal number of inequality constraints...............:        0\n        inequality constraints with only lower bounds:        0\n   inequality constraints with lower and upper bounds:        0\n        inequality constraints with only upper bounds:        0\n\niter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n   0  4.2114270e+03 0.00e+00 1.00e+02   0.0 0.00e+00    -  0.00e+00 0.00e+00   0 \n   5  3.8448353e+03 0.00e+00 7.87e-01 -11.0 4.94e-02    -  1.00e+00 1.00e+00f  1 MaxS\n  10  3.8446636e+03 0.00e+00 2.25e-01 -11.0 1.38e-02    -  1.00e+00 1.00e+00f  1 MaxS\n  15  3.8446509e+03 0.00e+00 6.23e-02 -11.0 3.78e-03    -  1.00e+00 1.00e+00f  1 MaxS\n  20  3.8446499e+03 0.00e+00 1.70e-02 -11.0 1.03e-03    -  1.00e+00 1.00e+00f  1 MaxS\n  25  3.8446498e+03 0.00e+00 4.61e-03 -11.0 2.79e-04    -  1.00e+00 1.00e+00f  1 MaxS\n  30  3.8446498e+03 0.00e+00 1.25e-03 -11.0 7.56e-05    -  1.00e+00 1.00e+00f  1 MaxS\n  35  3.8446498e+03 0.00e+00 3.39e-04 -11.0 2.05e-05    -  1.00e+00 1.00e+00f  1 MaxS\n  40  3.8446498e+03 0.00e+00 9.19e-05 -11.0 5.56e-06    -  1.00e+00 1.00e+00f  1 MaxS\n  45  3.8446498e+03 0.00e+00 2.49e-05 -11.0 1.51e-06    -  1.00e+00 1.00e+00f  1 MaxS\niter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n  50  3.8446498e+03 0.00e+00 6.76e-06 -11.0 4.08e-07    -  1.00e+00 1.00e+00f  1 MaxSA\n  55  3.8446498e+03 0.00e+00 1.83e-06 -11.0 1.11e-07    -  1.00e+00 1.00e+00f  1 MaxSA\n  60  3.8446498e+03 0.00e+00 4.97e-07 -11.0 3.00e-08    -  1.00e+00 1.00e+00f  1 MaxSA\n\nNumber of Iterations....: 63\n\n                                   (scaled)                 (unscaled)\nObjective...............:   3.4484507551948582e+02    3.8446498170293421e+03\nDual infeasibility......:   2.2694405419276139e-07    2.5301808793809917e-06\nConstraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\nComplementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00\nOverall NLP error.......:   2.2694405419276139e-07    2.5301808793809917e-06\n\n\nNumber of objective function evaluations             = 64\nNumber of objective gradient evaluations             = 64\nNumber of equality constraint evaluations            = 0\nNumber of inequality constraint evaluations          = 0\nNumber of equality constraint Jacobian evaluations   = 0\nNumber of inequality constraint Jacobian evaluations = 0\nNumber of Lagrangian Hessian evaluations             = 63\nTotal CPU secs in IPOPT (w/o function evaluations)   =      0.021\nTotal CPU secs in NLP function evaluations           =      0.650\n\nEXIT: Solved To Acceptable Level.\n  0.748622 seconds (160.13 k allocations: 8.986 MB, 17.15% gc time)\n\n\n\n\n\nvcmodel_constr\n.\nB\n\n\n\n\n\n\n2x2 Array{Float64,2}:\n 1.07177   1.07177\n 0.955683  1.01591\n\n\n\n\n\nvcmodel_constr\n.\n\u03a3\n\n\n\n\n\n\n(\n2x2 Array{Float64,2}:\n  0.380539  -0.305626\n -0.305626   4.52116 ,\n\n2x2 Array{Float64,2}:\n 1.8405    0.264881\n 0.264881  2.17348 )", 
            "title": "MLE/REML"
        }, 
        {
            "location": "/man/mle_reml/#mle-and-reml", 
            "text": "", 
            "title": "MLE and REML"
        }, 
        {
            "location": "/man/mle_reml/#demo-data", 
            "text": "For demonstration, we generate a random data set.  # generate data from a d-variate response variane component model  srand ( 123 )  n   =   1000     # no. observations  d   =   2        # dimension of responses  m   =   2        # no. variance components  p   =   2        # no. covariates  # n-by-p design matrix  X   =   randn ( n ,   p )  # p-by-d mean component regression coefficient  B   =   ones ( p ,   d )    # a tuple of m covariance matrices  V   =   ntuple ( x   -   zeros ( n ,   n ),   m )   for   i   =   1 : m - 1 \n   Vi   =   randn ( n ,   50 ) \n   copy! ( V [ i ],   Vi   *   Vi )  end  copy! ( V [ m ],   eye ( n ))   # last covarianec matrix is idendity  # a tuple of m d-by-d variance component parameters  \u03a3   =   ntuple ( x   -   zeros ( d ,   d ),   m )   for   i   in   1 : m \n   \u03a3i   =   randn ( d ,   d ) \n   copy! ( \u03a3 [ i ],   \u03a3i   *   \u03a3i )  end  # form overall nd-by-nd covariance matrix \u03a9  \u03a9   =   zeros ( n   *   d ,   n   *   d )  for   i   =   1 : m \n   \u03a9   +=   kron ( \u03a3 [ i ],   V [ i ])  end  \u03a9chol   =   cholfact ( \u03a9 )  # n-by-d responses  Y   =   X   *   B   +   reshape ( \u03a9chol [: L ]   *   randn ( n * d ),   n ,   d );", 
            "title": "Demo data"
        }, 
        {
            "location": "/man/mle_reml/#maximum-likelihood-estimation-mle", 
            "text": "To find the MLE of parameters $(B,\\Sigma_1,\\ldots,\\Sigma_m)$, we take 3 steps:    Step 1 (Construct data) . Construct an instance of  VarianceComponentVariate , which consists fields     Y : $n$-by-$d$ responses    X : $n$-by-$p$ covariate matrix    V=(V[1],...,V[m]) : a tuple of $n$-by-$n$ covariance matrices. The last covariance matrix must be positive definite and usually is the identity matrix.    using   VarianceComponentModels  vcdata   =   VarianceComponentVariate ( Y ,   X ,   V )  fieldnames ( vcdata )   3-element Array{Symbol,1}:\n :Y\n :X\n :V  In the absence of covariates $X$, we can simply initialize by  vcdata = VarianceComponentVariate(Y, V) .  Step 2 (Construct a model) . Construct an instance of  VarianceComponentModel , which consists of fields     B : $n$-by-$p$ mean regression coefficients    \u03a3=(\u03a3[1],...,\u03a3[m]) : variane component parameters respectively.    When constructed from a  VarianceComponentVariate  instance, the mean parameters $B$ are initialized to be zero and the tuple of variance component parameters $\\Sigma$ to be  (eye(d),...,eye(d)) .  vcmodel   =   VarianceComponentModel ( vcdata )  fieldnames ( vcmodel )   7-element Array{Symbol,1}:\n :B    \n :\u03a3    \n :A    \n :sense\n :b    \n :lb   \n :ub  vcmodel   VarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(2x2 Array{Float64,2}:\n 0.0  0.0\n 0.0  0.0,(\n2x2 Array{Float64,2}:\n 1.0  0.0\n 0.0  1.0,\n\n2x2 Array{Float64,2}:\n 1.0  0.0\n 0.0  1.0),0x4 Array{Float64,2},Char[],Float64[],-Inf,Inf)  The remaining fields  A ,  sense ,  b ,  lb ,  ub  specify (optional) constraints on the mean parameters  B :  $A * \\text{vec}(B) \\,\\, =(\\text{or } \\ge \\text{or } \\le) \\,\\, b$  $lb \\le \\text{vec}(B) \\le ub$  A  is an constraint matrix with $pd$ columns,  sense  is a vector of charaters taking values  ' ' ,  '='  or  ' ' , and  lb  and  ub  are the lower and upper bounds for  vec(B) . By default,  A ,  sense ,  b  are empty,  lb  is  -Inf , and  ub  is  Inf . If any constraits are non-trivial, final estimates of  B  are enforced to satisfy them.  When a better initial guess is available, we can initialize by calling  vcmodel=VarianceComponentModel(B0, \u03a30)  directly.  Step 3 (Fit model) . Call optmization routine  fit_mle! . The keywork  algo  dictates the optimization algorithm:  :MM  (minorization-maximization algorithm) or  :FS  (Fisher scoring algorithm).  vcmodel_mle   =   deepcopy ( vcmodel )  @ time   logl ,   vcmodel_mle ,   \u03a3se ,   \u03a3cov ,   Bse ,   Bcov   =   fit_mle! ( vcmodel_mle ,   vcdata ;   algo   =   : MM );        MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0  -6.253551e+03\n       1  -3.881454e+03\n       2  -3.853179e+03\n       3  -3.846525e+03\n       4  -3.844906e+03\n       5  -3.844506e+03\n       6  -3.844406e+03\n       7  -3.844381e+03\n       8  -3.844375e+03\n       9  -3.844374e+03\n      10  -3.844373e+03\n\n  0.369037 seconds (13.81 k allocations: 23.961 MB, 1.31% gc time)  The output of  fit_mle!  contains     final log-likelihood     logl   -3844.373181418088   fitted model   fieldnames ( vcmodel_mle )   7-element Array{Symbol,1}:\n :B    \n :\u03a3    \n :A    \n :sense\n :b    \n :lb   \n :ub  vcmodel_mle   VarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(2x2 Array{Float64,2}:\n 1.092     1.04727\n 0.955346  1.01632,(\n2x2 Array{Float64,2}:\n  0.380637  -0.305465\n -0.305465   4.51938 ,\n\n2x2 Array{Float64,2}:\n 1.84009   0.265569\n 0.265569  2.17275 ),0x4 Array{Float64,2},Char[],Float64[],-Inf,Inf)   standard errors of the estimated varianec component parameters   \u03a3se   (\n2x2 Array{Float64,2}:\n 0.0765136  0.263047\n 0.263047   0.904332,\n\n2x2 Array{Float64,2}:\n 0.0844292  0.0917441\n 0.0917441  0.0996927)   covariance matrix of the variance component parameters estimates   \u03a3cov   8x8 Array{Float64,2}:\n  0.00585433  -0.00467019  -0.00467019  \u2026  -1.07903e-6   -1.557e-7   \n -0.00467019   0.0691937    0.00372555     -1.557e-7     -1.27444e-6 \n -0.00467019   0.00372555   0.0691937      -8.83212e-6   -1.27444e-6 \n  0.00372555  -0.055198    -0.055198       -1.27444e-6   -1.04316e-5 \n -7.4779e-6   -1.07903e-6  -1.07903e-6      0.00102878    0.000148477\n -1.07903e-6  -8.83212e-6  -1.557e-7    \u2026   0.000148477   0.00121477 \n -1.07903e-6  -1.557e-7    -8.83212e-6      0.00841698    0.00121477 \n -1.557e-7    -1.27444e-6  -1.27444e-6      0.00121477    0.00993864   standard errors of the estimated mean parameters   Bse   2x2 Array{Float64,2}:\n 0.042556   0.0483538\n 0.0430622  0.0495727   covariance matrix of the mean parameter estimates   Bcov   4x4 Array{Float64,2}:\n  0.00181101   -1.98163e-5    0.000243689  -2.44708e-6 \n -1.98163e-5    0.00185435   -2.44708e-6    0.000243907\n  0.000243689  -2.44708e-6    0.00233809   -2.80614e-5 \n -2.44708e-6    0.000243907  -2.80614e-5    0.00245745", 
            "title": "Maximum likelihood estimation (MLE)"
        }, 
        {
            "location": "/man/mle_reml/#restricted-maximum-likelihood-estimation-reml", 
            "text": "REML (restricted maximum likelihood estimation)  is a popular alternative to the MLE. To find the REML of a variane component model, we replace the above step 3 by    Step 3 . Call optmization routine  fit_reml! .  vcmodel_reml   =   deepcopy ( vcmodel )  @ time   logl ,   vcmodel_reml ,   \u03a3se ,   \u03a3cov ,   Bse ,   Bcov   =   fit_reml! ( vcmodel_reml ,   vcdata ;   algo   =   : MM );        MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0  -4.215053e+03\n       1  -3.925799e+03\n       2  -3.865114e+03\n       3  -3.851105e+03\n       4  -3.847732e+03\n       5  -3.846903e+03\n       6  -3.846698e+03\n       7  -3.846647e+03\n       8  -3.846634e+03\n       9  -3.846631e+03\n      10  -3.846630e+03\n\n  0.677764 seconds (16.35 k allocations: 62.680 MB, 1.06% gc time)  The output of  fit_reml!  contains   the final log-likelihood at REML estimate   logl   -3844.377717902519   REML estimates   fieldnames ( vcmodel_reml )   7-element Array{Symbol,1}:\n :B    \n :\u03a3    \n :A    \n :sense\n :b    \n :lb   \n :ub  vcmodel_reml   VarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(2x2 Array{Float64,2}:\n 1.092     1.04727\n 0.955345  1.01632,(\n2x2 Array{Float64,2}:\n  0.380594  -0.305485\n -0.305485   4.51994 ,\n\n2x2 Array{Float64,2}:\n 1.84285   0.261963\n 0.261963  2.17842 ),0x4 Array{Float64,2},Char[],Float64[],-Inf,Inf)   standard errors of the estimated varianec component parameters   \u03a3se   (\n2x2 Array{Float64,2}:\n 0.0765055  0.26305 \n 0.26305    0.904446,\n\n2x2 Array{Float64,2}:\n 0.0845559  0.0919325\n 0.0919325  0.0999526)   covariance matrix of the variance component parameters estimates   \u03a3cov   8x8 Array{Float64,2}:\n  0.0058531   -0.00467005  -0.00467005  \u2026  -1.06597e-6   -1.51499e-7 \n -0.00467005   0.0691951    0.00372613     -1.51499e-7   -1.26041e-6 \n -0.00467005   0.00372613   0.0691951      -8.86843e-6   -1.26041e-6 \n  0.00372613  -0.0552092   -0.0552092      -1.26041e-6   -1.0486e-5  \n -7.50035e-6  -1.06597e-6  -1.06597e-6      0.00101633    0.000144472\n -1.06597e-6  -8.86843e-6  -1.51499e-7  \u2026   0.000144472   0.0012014  \n -1.06597e-6  -1.51499e-7  -8.86843e-6      0.00845158    0.0012014  \n -1.51499e-7  -1.26041e-6  -1.26041e-6      0.0012014     0.00999052   standard errors of the estimated mean parameters   Bse   2x2 Array{Float64,2}:\n 0.0425878  0.0484189\n 0.0430944  0.04964   covariance matrix of the mean parameter estimates   Bcov   4x4 Array{Float64,2}:\n  0.00181372   -1.9846e-5    0.000240116  -2.40768e-6\n -1.9846e-5     0.00185713  -2.40768e-6    0.00024024\n  0.000240116  -2.40768e-6   0.00234439   -2.81393e-5\n -2.40768e-6    0.00024024  -2.81393e-5    0.00246413", 
            "title": "Restricted maximum likelihood estimation (REML)"
        }, 
        {
            "location": "/man/mle_reml/#optimization-algorithms", 
            "text": "Finding the MLE or REML of variance component models is a non-trivial nonlinear optimization problem. The main complications are the non-convexity of objective function and the positive semi-definiteness constraint of variane component parameters $\\Sigma_1,\\ldots,\\Sigma_m$. In specific applications, users should try different algorithms with different starting points in order to find a better solution. Here are some tips for efficient computation.   In general the optimization algorithm needs to invert the $nd$ by $nd$ overall covariance matrix $\\Omega = \\Sigma_1 \\otimes V_1 + \\cdots + \\Sigma_m \\otimes V_m$ in each iteration. Inverting a matrix is an expensive operation with $O(n^3 d^3)$ floating operations. When there are only  two  varianec components ($m=2$), this tedious task can be avoided by taking one (generalized) eigendecomposion of $(V_1, V_2)$ and rotating data $(Y, X)$ by the eigen-vectors.   vcdatarot   =   TwoVarCompVariateRotate ( vcdata )  fieldnames ( vcdatarot )   4-element Array{Symbol,1}:\n :Yrot    \n :Xrot    \n :eigval  \n :logdetV2  Two optimization algorithms are implemented:  Fisher scoring  ( mle_fs! ) and the  minorization-maximization (MM) algorithm  ( mle_mm! ). Both take the rotated data as input. These two functions give finer control of the optimization algorithms. Generally speaking, MM algorithm is more stable while Fisher scoring (if it converges) yields more accurate answer.  vcmodel_mm   =   deepcopy ( vcmodel )  @ time   mle_mm! ( vcmodel_mm ,   vcdatarot ;   maxiter = 10000 ,   funtol = 1e-8 ,   verbose   =   true );        MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0  -6.253551e+03\n       1  -3.881454e+03\n       2  -3.853179e+03\n       3  -3.846525e+03\n       4  -3.844906e+03\n       5  -3.844506e+03\n       6  -3.844406e+03\n       7  -3.844381e+03\n       8  -3.844375e+03\n       9  -3.844374e+03\n      10  -3.844373e+03\n\n  0.021236 seconds (9.75 k allocations: 619.875 KB)  # MM estimates  vcmodel_mm . B   2x2 Array{Float64,2}:\n 1.092     1.04727\n 0.955346  1.01632  # MM estimates  vcmodel_mm . \u03a3   (\n2x2 Array{Float64,2}:\n  0.380637  -0.305465\n -0.305465   4.51938 ,\n\n2x2 Array{Float64,2}:\n 1.84009   0.265569\n 0.265569  2.17275 )  Fisher scoring ( mle_fs! ) uses either  Ipopt.jl  (keyword  solver=:Ipopt ) or  KNITRO.jl  (keyword  solver=:Knitro ) as the backend solver. Ipopt is open source and installation of  Ipopt.jl  package alone is sufficient. Knitro is a commercial software and users need to follow instructions at  KNITRO.jl  for proper functioning.  # Fisher scoring using Ipopt  vcmodel_ipopt   =   deepcopy ( vcmodel )  @ time   mle_fs! ( vcmodel_ipopt ,   vcdatarot ;   solver = : Ipopt ,   maxiter = 1000 ,   verbose = true );   This is Ipopt version 3.12.4, running with linear solver mumps.\nNOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n\nNumber of nonzeros in equality constraint Jacobian...:        0\nNumber of nonzeros in inequality constraint Jacobian.:        0\nNumber of nonzeros in Lagrangian Hessian.............:       21\n\nTotal number of variables............................:        6\n                     variables with only lower bounds:        0\n                variables with lower and upper bounds:        0\n                     variables with only upper bounds:        0\nTotal number of equality constraints.................:        0\nTotal number of inequality constraints...............:        0\n        inequality constraints with only lower bounds:        0\n   inequality constraints with lower and upper bounds:        0\n        inequality constraints with only upper bounds:        0\n\niter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n   0  4.2109423e+03 0.00e+00 1.00e+02   0.0 0.00e+00    -  0.00e+00 0.00e+00   0 \n   5  3.8445586e+03 0.00e+00 7.87e-01 -11.0 4.94e-02    -  1.00e+00 1.00e+00f  1 MaxS\n  10  3.8443870e+03 0.00e+00 2.25e-01 -11.0 1.38e-02    -  1.00e+00 1.00e+00f  1 MaxS\n  15  3.8443742e+03 0.00e+00 6.23e-02 -11.0 3.78e-03    -  1.00e+00 1.00e+00f  1 MaxS\n  20  3.8443733e+03 0.00e+00 1.70e-02 -11.0 1.03e-03    -  1.00e+00 1.00e+00f  1 MaxS\n  25  3.8443732e+03 0.00e+00 4.61e-03 -11.0 2.79e-04    -  1.00e+00 1.00e+00f  1 MaxS\n  30  3.8443732e+03 0.00e+00 1.25e-03 -11.0 7.56e-05    -  1.00e+00 1.00e+00f  1 MaxS\n  35  3.8443732e+03 0.00e+00 3.39e-04 -11.0 2.05e-05    -  1.00e+00 1.00e+00f  1 MaxS\n  40  3.8443732e+03 0.00e+00 9.19e-05 -11.0 5.55e-06    -  1.00e+00 1.00e+00f  1 MaxS\n  45  3.8443732e+03 0.00e+00 2.49e-05 -11.0 1.51e-06    -  1.00e+00 1.00e+00f  1 MaxS\niter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n  50  3.8443732e+03 0.00e+00 6.76e-06 -11.0 4.08e-07    -  1.00e+00 1.00e+00f  1 MaxSA\n  55  3.8443732e+03 0.00e+00 1.83e-06 -11.0 1.11e-07    -  1.00e+00 1.00e+00f  1 MaxSA\n  60  3.8443732e+03 0.00e+00 4.97e-07 -11.0 3.00e-08    -  1.00e+00 1.00e+00h  1 MaxSA\n\nNumber of Iterations....: 63\n\n                                   (scaled)                 (unscaled)\nObjective...............:   3.4496886481727671e+02    3.8443731733053760e+03\nDual infeasibility......:   2.2693632135739328e-07    2.5290047736252332e-06\nConstraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\nComplementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00\nOverall NLP error.......:   2.2693632135739328e-07    2.5290047736252332e-06\n\n\nNumber of objective function evaluations             = 64\nNumber of objective gradient evaluations             = 64\nNumber of equality constraint evaluations            = 0\nNumber of inequality constraint evaluations          = 0\nNumber of equality constraint Jacobian evaluations   = 0\nNumber of inequality constraint Jacobian evaluations = 0\nNumber of Lagrangian Hessian evaluations             = 63\nTotal CPU secs in IPOPT (w/o function evaluations)   =      0.019\nTotal CPU secs in NLP function evaluations           =      0.263\n\nEXIT: Solved To Acceptable Level.\n  0.314060 seconds (110.60 k allocations: 6.978 MB)  # Ipopt estimates  vcmodel_ipopt . B   2x2 Array{Float64,2}:\n 1.092     1.04727\n 0.955346  1.01632  # Ipopt estimates  vcmodel_ipopt . \u03a3   (\n2x2 Array{Float64,2}:\n  0.380552  -0.305594\n -0.305594   4.52106 ,\n\n2x2 Array{Float64,2}:\n 1.84008   0.265385\n 0.265385  2.17287 )  # Fisher scoring using Knitro  vcmodel_knitro   =   deepcopy ( vcmodel )  @ time   mle_fs! ( vcmodel_knitro ,   vcdatarot ;   solver = : Knitro ,   maxiter = 1000 ,   verbose = true );   Knitro 10.1.0 STUDENT LICENSE (problem size limit = 300)\n\n=======================================\n            Student License\n       (NOT FOR COMMERCIAL USE)\n         Artelys Knitro 10.1.0\n=======================================\n\nKnitro presolve eliminated 0 variables and 0 constraints.\n\nThe problem is identified as unconstrained.\nKnitro changing algorithm from AUTO to 1.\nKnitro changing bar_initpt from AUTO to 3.\nKnitro changing bar_murule from AUTO to 4.\nKnitro changing bar_penaltycons from AUTO to 1.\nKnitro changing bar_penaltyrule from AUTO to 2.\nKnitro changing bar_switchrule from AUTO to 1.\nKnitro changing linsolver from AUTO to 2.\n\nProblem Characteristics                    ( Presolved)\n-----------------------\nObjective goal:  Maximize\nNumber of variables:                     6 (         6)\n    bounded below:                       0 (         0)\n    bounded above:                       0 (         0)\n    bounded below and above:             0 (         0)\n    fixed:                               0 (         0)\n    free:                                6 (         6)\nNumber of constraints:                   0 (         0)\n    linear equalities:                   0 (         0)\n    nonlinear equalities:                0 (         0)\n    linear inequalities:                 0 (         0)\n    nonlinear inequalities:              0 (         0)\n    range:                               0 (         0)\nNumber of nonzeros in Jacobian:          0 (         0)\nNumber of nonzeros in Hessian:          21 (        21)\n\n  Iter      Objective      FeasError   OptError    ||Step||    CGits \n--------  --------------  ----------  ----------  ----------  -------\n       0   -4.210942e+03   0.000e+00\n      10   -3.844387e+03   0.000e+00   2.254e-01   1.390e-02        0\n      20   -3.844373e+03   0.000e+00   1.698e-02   1.034e-03        0\n      30   -3.844373e+03   0.000e+00   1.250e-03   7.606e-05        0\n      40   -3.844373e+03   0.000e+00   9.191e-05   5.591e-06        0\n\nEXIT: Locally optimal solution found.\n\nFinal Statistics\n----------------\nFinal objective value               =  -3.84437317330763e+03\nFinal feasibility error (abs / rel) =   0.00e+00 / 0.00e+00\nFinal optimality error  (abs / rel) =   9.19e-05 / 9.19e-07\n# of iterations                     =         40 \n# of CG iterations                  =          0 \n# of function evaluations           =         42\n# of gradient evaluations           =         42\n# of Hessian evaluations            =         40\nTotal program time (secs)           =       0.18812 (     0.188 CPU time)\nTime spent in evaluations (secs)    =       0.18277\n\n===============================================================================\n\n  0.191113 seconds (73.31 k allocations: 4.642 MB)\n\n\n### Could not find a valid license.\n    Your machine ID is 1f-aa-f6-5b-46.\n    Please contact licensing@artelys.com or your local distributor to obtain a license.\n    If you already have a license, please execute `get_machine_ID -v` and send the output to support.  # Knitro estimates  vcmodel_knitro . B   2x2 Array{Float64,2}:\n 1.092     1.04727\n 0.955346  1.01632  # Knitro estimates  vcmodel_knitro . \u03a3   (\n2x2 Array{Float64,2}:\n  0.380552  -0.305582\n -0.305582   4.52106 ,\n\n2x2 Array{Float64,2}:\n 1.84008   0.265385\n 0.265385  2.17287 )", 
            "title": "Optimization algorithms"
        }, 
        {
            "location": "/man/mle_reml/#starting-point", 
            "text": "Here are a few strategies for successful optimization.    For $d 1$ (multivariate response), initialize $B, \\Sigma$ from univariate estimates.    Use REML estimate as starting point for MLE.    When there are only $m=2$ variance components, pre-compute  TwoVarCompVariateRotate  and use it for optimization.", 
            "title": "Starting point"
        }, 
        {
            "location": "/man/mle_reml/#constrained-estimation-of-b", 
            "text": "Many applications invoke constraints on the mean parameters  B . For demonstration, we enforce  B[1,1]=B[1,2]  and all entries of  B  are within [0, 2].  # set up constraints on B  vcmodel_constr   =   deepcopy ( vcmodel )  vcmodel_constr . A   =   [ 1.0   0.0   - 1.0   0.0 ]  vcmodel_constr . sense   =   =  vcmodel_constr . b   =   0.0  vcmodel_constr . lb   =   0.0  vcmodel_constr . ub   =   2.0  vcmodel_constr   VarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(2x2 Array{Float64,2}:\n 0.0  0.0\n 0.0  0.0,(\n2x2 Array{Float64,2}:\n 1.0  0.0\n 0.0  1.0,\n\n2x2 Array{Float64,2}:\n 1.0  0.0\n 0.0  1.0),1x4 Array{Float64,2}:\n 1.0  0.0  -1.0  0.0, = ,0.0,0.0,2.0)  We first try the MM algorithm.  # MM algorithm for constrained estimation of B  @ time   mle_mm! ( vcmodel_constr ,   vcdatarot ;   maxiter = 10000 ,   funtol = 1e-8 ,   verbose   =   true );        MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0  -6.253551e+03\n       1  -3.881820e+03\n       2  -3.853477e+03\n       3  -3.846807e+03\n       4  -3.845184e+03\n       5  -3.844783e+03\n       6  -3.844683e+03\n       7  -3.844658e+03\n       8  -3.844652e+03\n       9  -3.844650e+03\n      10  -3.844650e+03\n\n  0.095903 seconds (34.73 k allocations: 1.715 MB)  fieldnames ( vcmodel_constr )   7-element Array{Symbol,1}:\n :B    \n :\u03a3    \n :A    \n :sense\n :b    \n :lb   \n :ub  vcmodel_constr . B   2x2 Array{Float64,2}:\n 1.07177   1.07177\n 0.955683  1.01591  vcmodel_constr . \u03a3   (\n2x2 Array{Float64,2}:\n  0.380624  -0.305498\n -0.305498   4.51948 ,\n\n2x2 Array{Float64,2}:\n 1.84051   0.265065\n 0.265065  2.17336 )  Now let's try Fisher scoring.  # Fisher scoring using Ipopt for constrained estimation of B  vcmodel_constr   =   deepcopy ( vcmodel )  vcmodel_constr . A   =   [ 1.0   0.0   - 1.0   0.0 ]  vcmodel_constr . sense   =   =  vcmodel_constr . b   =   0.0  vcmodel_constr . lb   =   0.0  vcmodel_constr . ub   =   2.0  vcmodel_constr  @ time   mle_fs! ( vcmodel_constr ,   vcdatarot ;   solver = : Ipopt ,   maxiter = 1000 ,   verbose = true );   This is Ipopt version 3.12.4, running with linear solver mumps.\nNOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n\nNumber of nonzeros in equality constraint Jacobian...:        0\nNumber of nonzeros in inequality constraint Jacobian.:        0\nNumber of nonzeros in Lagrangian Hessian.............:       21\n\nTotal number of variables............................:        6\n                     variables with only lower bounds:        0\n                variables with lower and upper bounds:        0\n                     variables with only upper bounds:        0\nTotal number of equality constraints.................:        0\nTotal number of inequality constraints...............:        0\n        inequality constraints with only lower bounds:        0\n   inequality constraints with lower and upper bounds:        0\n        inequality constraints with only upper bounds:        0\n\niter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n   0  4.2114270e+03 0.00e+00 1.00e+02   0.0 0.00e+00    -  0.00e+00 0.00e+00   0 \n   5  3.8448353e+03 0.00e+00 7.87e-01 -11.0 4.94e-02    -  1.00e+00 1.00e+00f  1 MaxS\n  10  3.8446636e+03 0.00e+00 2.25e-01 -11.0 1.38e-02    -  1.00e+00 1.00e+00f  1 MaxS\n  15  3.8446509e+03 0.00e+00 6.23e-02 -11.0 3.78e-03    -  1.00e+00 1.00e+00f  1 MaxS\n  20  3.8446499e+03 0.00e+00 1.70e-02 -11.0 1.03e-03    -  1.00e+00 1.00e+00f  1 MaxS\n  25  3.8446498e+03 0.00e+00 4.61e-03 -11.0 2.79e-04    -  1.00e+00 1.00e+00f  1 MaxS\n  30  3.8446498e+03 0.00e+00 1.25e-03 -11.0 7.56e-05    -  1.00e+00 1.00e+00f  1 MaxS\n  35  3.8446498e+03 0.00e+00 3.39e-04 -11.0 2.05e-05    -  1.00e+00 1.00e+00f  1 MaxS\n  40  3.8446498e+03 0.00e+00 9.19e-05 -11.0 5.56e-06    -  1.00e+00 1.00e+00f  1 MaxS\n  45  3.8446498e+03 0.00e+00 2.49e-05 -11.0 1.51e-06    -  1.00e+00 1.00e+00f  1 MaxS\niter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n  50  3.8446498e+03 0.00e+00 6.76e-06 -11.0 4.08e-07    -  1.00e+00 1.00e+00f  1 MaxSA\n  55  3.8446498e+03 0.00e+00 1.83e-06 -11.0 1.11e-07    -  1.00e+00 1.00e+00f  1 MaxSA\n  60  3.8446498e+03 0.00e+00 4.97e-07 -11.0 3.00e-08    -  1.00e+00 1.00e+00f  1 MaxSA\n\nNumber of Iterations....: 63\n\n                                   (scaled)                 (unscaled)\nObjective...............:   3.4484507551948582e+02    3.8446498170293421e+03\nDual infeasibility......:   2.2694405419276139e-07    2.5301808793809917e-06\nConstraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\nComplementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00\nOverall NLP error.......:   2.2694405419276139e-07    2.5301808793809917e-06\n\n\nNumber of objective function evaluations             = 64\nNumber of objective gradient evaluations             = 64\nNumber of equality constraint evaluations            = 0\nNumber of inequality constraint evaluations          = 0\nNumber of equality constraint Jacobian evaluations   = 0\nNumber of inequality constraint Jacobian evaluations = 0\nNumber of Lagrangian Hessian evaluations             = 63\nTotal CPU secs in IPOPT (w/o function evaluations)   =      0.021\nTotal CPU secs in NLP function evaluations           =      0.650\n\nEXIT: Solved To Acceptable Level.\n  0.748622 seconds (160.13 k allocations: 8.986 MB, 17.15% gc time)  vcmodel_constr . B   2x2 Array{Float64,2}:\n 1.07177   1.07177\n 0.955683  1.01591  vcmodel_constr . \u03a3   (\n2x2 Array{Float64,2}:\n  0.380539  -0.305626\n -0.305626   4.52116 ,\n\n2x2 Array{Float64,2}:\n 1.8405    0.264881\n 0.264881  2.17348 )", 
            "title": "Constrained estimation of B"
        }, 
        {
            "location": "/man/heritability/", 
            "text": "Heritability Analysis\n\n\nAs an application of the variance component model, this note demonstrates the workflow for heritability analysis in genetics, using a sample data set \ncg10k\n with \n6,670\n individuals and \n630,860\n SNPs. Person IDs and phenotype names are masked for privacy. \ncg10k.bed\n, \ncg10k.bim\n, and \ncg10k.fam\n is a set of Plink files in binary format. \ncg10k_traits.txt\n contains 13 phenotypes of the 6,670 individuals.\n\n\n;\nls\n \ncg10k\n*.*\n\n\n\n\n\n\ncg10k.bed\ncg10k.bim\ncg10k.fam\ncg10k_traits.txt\n\n\n\n\n\nMachine information:\n\n\nversioninfo\n()\n\n\n\n\n\n\nJulia Version 0.4.6\nCommit 2e358ce (2016-06-19 17:16 UTC)\nPlatform Info:\n  System: Darwin (x86_64-apple-darwin13.4.0)\n  CPU: Intel(R) Core(TM) i7-3720QM CPU @ 2.60GHz\n  WORD_SIZE: 64\n  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Sandybridge)\n  LAPACK: libopenblas64_\n  LIBM: libopenlibm\n  LLVM: libLLVM-3.3\n\n\n\n\n\n\n\nRead in binary SNP data\n\n\nWe will use the \nSnpArrays.jl\n package to read in binary SNP data and compute the empirical kinship matrix. Issue \nPkg.clone(\"git@github.com:OpenMendel/SnpArrays.jl.git\")\n within \nJulia\n to install the \nSnpArrays\n package.\n\n\n#Pkg.clone(\ngit@github.com:OpenMendel/SnpArrays.jl.git\n)\n\n\nusing\n \nSnpArrays\n\n\n\n\n\n\n# read in genotype data from Plink binary file (~50 secs on my laptop)\n\n\n@\ntime\n \ncg10k\n \n=\n \nSnpArray\n(\ncg10k\n)\n\n\n\n\n\n\n 55.188439 seconds (514.43 k allocations: 1.003 GB, 0.02% gc time)\n\n\n\n\n\n6670x630860 SnpArrays.SnpArray{2}:\n (false,true)   (false,true)   (true,true)   \u2026  (true,true)    (true,true) \n (true,true)    (true,true)    (false,true)     (false,true)   (true,false)\n (true,true)    (true,true)    (false,true)     (true,true)    (true,true) \n (true,true)    (true,true)    (true,true)      (false,true)   (true,true) \n (true,true)    (true,true)    (true,true)      (true,true)    (false,true)\n (false,true)   (false,true)   (true,true)   \u2026  (true,true)    (true,true) \n (false,false)  (false,false)  (true,true)      (true,true)    (true,true) \n (true,true)    (true,true)    (true,true)      (true,true)    (false,true)\n (true,true)    (true,true)    (false,true)     (true,true)    (true,true) \n (true,true)    (true,true)    (true,true)      (false,true)   (true,true) \n (true,true)    (true,true)    (false,true)  \u2026  (true,true)    (true,true) \n (false,true)   (false,true)   (true,true)      (true,true)    (false,true)\n (true,true)    (true,true)    (true,true)      (true,true)    (false,true)\n \u22ee                                           \u22f1                             \n (false,true)   (false,true)   (true,true)      (false,true)   (false,true)\n (false,true)   (false,true)   (false,true)     (false,true)   (true,true) \n (true,true)    (true,true)    (false,true)  \u2026  (false,true)   (true,true) \n (false,true)   (false,true)   (true,true)      (true,true)    (false,true)\n (true,true)    (true,true)    (true,true)      (false,true)   (true,true) \n (true,true)    (true,true)    (true,false)     (false,false)  (false,true)\n (true,true)    (true,true)    (true,true)      (true,true)    (false,true)\n (true,true)    (true,true)    (false,true)  \u2026  (true,true)    (true,true) \n (true,true)    (true,true)    (true,true)      (false,true)   (true,true) \n (true,true)    (true,true)    (true,true)      (true,true)    (false,true)\n (false,true)   (false,true)   (true,true)      (true,true)    (true,true) \n (true,true)    (true,true)    (true,true)      (true,true)    (true,true)\n\n\n\n\n\n\n\nSummary statistics of SNP data\n\n\npeople\n,\n \nsnps\n \n=\n \nsize\n(\ncg10k\n)\n\n\n\n\n\n\n(6670,630860)\n\n\n\n\n\n# summary statistics (~50 secs on my laptop)\n\n\n@\ntime\n \nmaf\n,\n \n_\n,\n \nmissings_by_snp\n,\n \n=\n \nsummarize\n(\ncg10k\n);\n\n\n\n\n\n\n 38.734869 seconds (21 allocations: 9.753 MB, 0.01% gc time)\n\n\n\n\n\n# 5 number summary and average MAF (minor allele frequencies)\n\n\nquantile\n(\nmaf\n,\n \n[\n0.0\n \n.\n25\n \n.\n5\n \n.\n75\n \n1.0\n]),\n \nmean\n(\nmaf\n)\n\n\n\n\n\n\n(\n1x5 Array{Float64,2}:\n 0.00841726  0.124063  0.236953  0.364253  0.5,\n\n0.24536516625042462)\n\n\n\n\n\nusing\n \nPlots\n\n\npyplot\n()\n\n\n\nhistogram\n(\nmaf\n,\n \nxlab\n \n=\n \nMinor Allele Frequency (MAF)\n,\n \nlabel\n \n=\n \nMAF\n)\n\n\n\n\n\n\n\n\n# proportion of missing genotypes\n\n\nsum\n(\nmissings_by_snp\n)\n \n/\n \nlength\n(\ncg10k\n)\n\n\n\n\n\n\n0.0013128198764010824\n\n\n\n\n\n# proportion of rare SNPs with maf \n 0.05\n\n\ncountnz\n(\nmaf\n \n.\n \n0.05\n)\n \n/\n \nlength\n(\nmaf\n)\n\n\n\n\n\n\n0.07228069619249913\n\n\n\n\n\n\n\nEmpirical kinship matrix\n\n\nWe estimate empirical kinship based on all SNPs by the genetic relation matrix (GRM). Missing genotypes are imputed on the fly by drawing according to the minor allele frequencies.\n\n\n# GRM using all SNPs (~10 mins on my laptop)\n\n\nsrand\n(\n123\n)\n\n\n@\ntime\n \n\u03a6grm\n \n=\n \ngrm\n(\ncg10k\n;\n \nmethod\n \n=\n \n:\nGRM\n)\n\n\n\n\n\n\n567.048450 seconds (4.21 G allocations: 64.513 GB, 1.11% gc time)\n\n\n\n\n\n6670x6670 Array{Float64,2}:\n  0.502916      0.00329978   -0.000116213  \u2026  -6.46286e-5   -0.00281229 \n  0.00329978    0.49892      -0.00201992       0.000909871   0.00345573 \n -0.000116213  -0.00201992    0.493632         0.000294565  -0.000349854\n  0.000933977  -0.00320391   -0.0018611       -0.00241682   -0.00127078 \n -7.75429e-5   -0.0036075     0.00181442       0.00213976   -0.00158382 \n  0.00200371    0.000577386   0.0025455    \u2026   0.000943753  -1.82994e-6 \n  0.000558503   0.00241421   -0.0018782        0.001217     -0.00123924 \n -0.000659495   0.00319987   -0.00101496       0.00353646   -0.00024093 \n -0.00102619   -0.00120448   -0.00055462       0.00175586    0.00181899 \n -0.00136838    0.00211996    0.000119128     -0.00147305   -0.00105239 \n -0.00206144    0.000148818  -0.000475177  \u2026  -0.000265522  -0.00106123 \n  0.000951016   0.00167042    0.00183545      -0.000703658  -0.00313334 \n  0.000330442  -0.000904147   0.00301478       0.000754772  -0.00127413 \n  \u22ee                                        \u22f1                            \n  0.00301137    0.00116042    0.00100426       6.67254e-6    0.00307069 \n -0.00214008    0.00270925   -0.00185054      -0.00109935    0.00366816 \n  0.000546739  -0.00242646   -0.00305264   \u2026  -0.000629014   0.00210779 \n -0.00422553   -0.0020713    -0.00109052      -0.000705804  -0.000508055\n -0.00318405   -0.00075385    0.00312377       0.00052883   -3.60969e-5 \n  0.000430196  -0.00197163    0.00268545      -0.00633175   -0.00520337 \n  0.00221429    0.000849792  -0.00101111      -0.000943129  -0.000624419\n -0.00229025   -0.000130598   0.000101853  \u2026   0.000840136  -0.00230224 \n -0.00202917    0.00233007   -0.00131006       0.00197798   -0.000513771\n -0.000964907  -0.000872326  -7.06722e-5       0.00124702   -0.00295844 \n -6.46286e-5    0.000909871   0.000294565      0.500983      0.000525615\n -0.00281229    0.00345573   -0.000349854      0.000525615   0.500792\n\n\n\n\n\n\n\nPhenotypes\n\n\nRead in the phenotype data and compute descriptive statistics.\n\n\nusing\n \nDataFrames\n\n\n\ncg10k_trait\n \n=\n \nreadtable\n(\n\n    \ncg10k_traits.txt\n;\n \n    \nseparator\n \n=\n \n \n,\n\n    \nnames\n \n=\n \n[:\nFID\n;\n \n:\nIID\n;\n \n:\nTrait1\n;\n \n:\nTrait2\n;\n \n:\nTrait3\n;\n \n:\nTrait4\n;\n \n:\nTrait5\n;\n \n:\nTrait6\n;\n \n             \n:\nTrait7\n;\n \n:\nTrait8\n;\n \n:\nTrait9\n;\n \n:\nTrait10\n;\n \n:\nTrait11\n;\n \n:\nTrait12\n;\n \n:\nTrait13\n],\n  \n    \neltypes\n \n=\n \n[\nUTF8String\n;\n \nUTF8String\n;\n \nFloat64\n;\n \nFloat64\n;\n \nFloat64\n;\n \nFloat64\n;\n \nFloat64\n;\n \n               \nFloat64\n;\n \nFloat64\n;\n \nFloat64\n;\n \nFloat64\n;\n \nFloat64\n;\n \nFloat64\n;\n \nFloat64\n;\n \nFloat64\n]\n\n    \n)\n\n\n\n\n\n\nFID\nIID\nTrait1\nTrait2\nTrait3\nTrait4\nTrait5\nTrait6\nTrait7\nTrait8\nTrait9\nTrait10\nTrait11\nTrait12\nTrait13\n1\n10002K\n10002K\n-1.81573145026234\n-0.94615046147283\n1.11363077580442\n-2.09867121119159\n0.744416614111748\n0.00139171884080131\n0.934732480409667\n-1.22677315418103\n1.1160784277875\n-0.4436280335029\n0.824465656443384\n-1.02852542216546\n-0.394049201727681\n2\n10004O\n10004O\n-1.24440094378729\n0.109659992547179\n0.467119394241789\n-1.62131304097589\n1.0566758355683\n0.978946979419181\n1.00014633946047\n0.32487427140228\n1.16232175219696\n2.6922706948705\n3.08263672461047\n1.09064954786013\n0.0256616415357438\n3\n10005Q\n10005Q\n1.45566914502305\n1.53866932923243\n1.09402959376555\n0.586655272226893\n-0.32796454430367\n-0.30337709778827\n-0.0334354881314741\n-0.464463064285437\n-0.3319396273436\n-0.486839089635991\n-1.10648681564373\n-1.42015780427231\n-0.687463456644413\n4\n10006S\n10006S\n-0.768809276698548\n0.513490885514249\n0.244263028382142\n-1.31740254475691\n1.19393774326845\n1.17344127734288\n1.08737426675232\n0.536022583732261\n0.802759240762068\n0.234159411749815\n0.394174866891074\n-0.767365892476029\n0.0635385761884935\n5\n10009Y\n10009Y\n-0.264415132547719\n-0.348240421825694\n-0.0239065083413606\n0.00473915802244948\n1.25619191712193\n1.2038883667631\n1.29800739042627\n0.310113660247311\n0.626159861059352\n0.899289129831224\n0.54996783350812\n0.540687809542048\n0.179675416046033\n6\n10010J\n10010J\n-1.37617270917293\n-1.47191967744564\n0.291179894254146\n-0.803110740704731\n-0.264239977442213\n-0.260573027836772\n-0.165372266287781\n-0.219257294118362\n1.04702422290318\n-0.0985815534616482\n0.947393438068448\n0.594014812031438\n0.245407436348479\n7\n10011L\n10011L\n0.1009416296374\n-0.191615722103455\n-0.567421321596677\n0.378571487240382\n-0.246656179817904\n-0.608810750053858\n0.189081058215596\n-1.27077787326519\n-0.452476199143965\n0.702562877297724\n0.332636218957179\n0.0026916503626181\n0.317117176705358\n8\n10013P\n10013P\n-0.319818276367464\n1.35774480657283\n0.818689545938528\n-1.15565531644352\n0.63448368102259\n0.291461908634679\n0.933323714954726\n-0.741083289682492\n0.647477683507572\n-0.970877627077966\n0.220861165411304\n0.852512250237764\n-0.225904624283945\n9\n10014R\n10014R\n-0.288334173342032\n0.566082538090752\n0.254958336116175\n-0.652578302869714\n0.668921559277347\n0.978309199170558\n0.122862966041938\n1.4790926378214\n0.0672132424173449\n0.0795903917527827\n0.167532455243232\n0.246915579442139\n0.539932616458363\n10\n10015T\n10015T\n-1.15759732583991\n-0.781198583545165\n-0.595807759833517\n-1.00554980260402\n0.789828885933321\n0.571058413379044\n0.951304176233755\n-0.295962982984816\n0.99042002479707\n0.561309366988983\n0.733100030623233\n-1.73467772245684\n-1.35278484330654\n11\n10017X\n10017X\n0.740569150459031\n1.40873846755415\n0.734689999440088\n0.0208322841295094\n-0.337440968561619\n-0.458304040611395\n-0.142582512772326\n-0.580392297464107\n-0.684684998101516\n-0.00785381461893456\n-0.712244337518008\n-0.313345561230878\n-0.345419463162219\n12\n10020M\n10020M\n-0.675892486454995\n0.279892613829682\n0.267915996308248\n-1.04103665392985\n0.910741715645888\n0.866027618513171\n1.07414431702005\n0.0381751003538302\n0.766355377018601\n-0.340118016143495\n-0.809013958505059\n0.548521663785885\n-0.0201828675962336\n13\n10022Q\n10022Q\n-0.795410435603455\n-0.699989939762738\n0.3991295030063\n-0.510476261900736\n1.51552245416844\n1.28743032939467\n1.53772393250903\n0.133989160117702\n1.02025736886037\n0.499018733899186\n-0.36948273277931\n-1.10153460436318\n-0.598132438886619\n14\n10023S\n10023S\n-0.193483122930324\n-0.286021160323518\n-0.691494225262995\n0.0131581678700699\n1.52337470686782\n1.4010638072262\n1.53114620451896\n0.333066483478075\n1.04372480381099\n0.163206783570466\n-0.422883765001728\n-0.383527976713573\n-0.489221907788158\n15\n10028C\n10028C\n0.151246203379718\n2.09185108993614\n2.03800472474384\n-1.12474717143531\n1.66557024390713\n1.62535675109576\n1.58751070483655\n0.635852186043776\n0.842577784605979\n0.450761870778952\n-1.39479033623028\n-0.560984107567768\n0.289349776549287\n16\n10031R\n10031R\n-0.464608740812712\n0.36127694772303\n1.2327673928287\n-0.826033731086383\n1.43475224709983\n1.74451823818846\n0.211096887484638\n2.64816425140548\n1.02511433146096\n0.11975731603184\n0.0596832073448267\n-0.631231612661616\n-0.207878671782927\n17\n10032T\n10032T\n-0.732977488012215\n-0.526223425889779\n0.61657871336593\n-0.55447974332593\n0.947484859025104\n0.936833214138173\n0.972516806335524\n0.290251013865227\n1.01285359725723\n0.516207422283291\n-0.0300689171988194\n0.8787322524583\n0.450254629309513\n18\n10034X\n10034X\n-0.167326459622119\n0.175327165487237\n0.287467725892572\n-0.402652532084246\n0.551181509418056\n0.522204743290975\n0.436837660094653\n0.299564933845579\n0.583109520896067\n-0.704415820005353\n-0.730810367994577\n-1.95140580379896\n-0.933504665700164\n19\n10035Z\n10035Z\n1.41159485787418\n1.78722407901017\n0.84397639585364\n0.481278083772991\n-0.0887673728508268\n-0.49957757426858\n0.304195897924847\n-1.23884208383369\n-0.153475724036624\n-0.870486102788329\n0.0955473331150403\n-0.983708050882817\n-0.3563445644514\n20\n10041U\n10041U\n-1.42997091652825\n-0.490147045034213\n0.272730237607695\n-1.61029992954153\n0.990787817197748\n0.711687532608184\n1.1885836012715\n-0.371229188075638\n1.24703459239952\n-0.0389162332271516\n0.883495749072872\n2.58988026321017\n3.33539552370368\n21\n10047G\n10047G\n-0.147247288176765\n0.12328430415652\n0.617549051912237\n-0.18713077178262\n0.256438107586694\n0.17794983735083\n0.412611806463263\n-0.244809124559737\n0.0947624806136492\n0.723017223849532\n-0.683948354633436\n0.0873751276309269\n-0.262209652750371\n22\n10051X\n10051X\n-0.187112676773894\n-0.270777264595619\n-1.01556818551606\n0.0602850568600233\n0.272419757757978\n0.869133161879197\n-0.657519461414234\n2.32388522018189\n-0.999936011525034\n1.44671844178306\n0.971157886040772\n-0.358747904241515\n-0.439657942096136\n23\n10052Z\n10052Z\n-1.82434047163768\n-0.933480446068067\n1.29474003766977\n-1.94545221151036\n0.33584651189654\n0.359201654302844\n0.513652924365886\n-0.073197696696958\n1.57139042812005\n1.53329371326728\n1.82076821859528\n2.22740301867829\n1.50063347195857\n24\n10056H\n10056H\n-2.29344084351335\n-2.49161842344418\n0.40383988742336\n-2.36488074752948\n1.4105254831956\n1.42244117147792\n1.17024166272172\n0.84476650176855\n1.79026875432495\n0.648181858970515\n-0.0857231057403538\n-1.02789535292617\n0.491288088952859\n25\n10057J\n10057J\n-0.434135932888305\n0.740881989034652\n0.699576357578518\n-1.02405543187775\n0.759529223983713\n0.956656110895288\n0.633299568656589\n0.770733932268516\n0.824988511714526\n1.84287437634769\n1.91045942063443\n-0.502317207869366\n0.132670133448219\n26\n10058L\n10058L\n-2.1920969546557\n-2.49465664272271\n0.354854763893431\n-1.93155848635714\n0.941979400289938\n0.978917101414106\n0.894860097289736\n0.463239402831873\n1.12537133317163\n1.70528446191955\n0.717792714479123\n0.645888049108261\n0.783968250169388\n27\n10060Y\n10060Y\n-1.46602269088422\n-1.24921677101897\n0.307977693653039\n-1.55097364660989\n0.618908494474798\n0.662508171662042\n0.475957173906078\n0.484718674597707\n0.401564892028249\n0.55987973254026\n-0.376938143754217\n-0.933982629228218\n0.390013151672955\n28\n10062C\n10062C\n-1.83317744236881\n-1.53268787828701\n2.55674262685865\n-1.51827745783835\n0.789409601746455\n0.908747799728588\n0.649971922941479\n0.668373649931667\n1.20058303519903\n0.277963256075637\n1.2504953198275\n3.31370445071638\n2.22035828885342\n29\n10064G\n10064G\n-0.784546628243178\n0.276582579543931\n3.01104958800057\n-1.11978843206758\n0.920823858422707\n0.750217689886151\n1.26153730009639\n-0.403363882922417\n0.400667296857811\n-0.217597941303479\n-0.724669537565068\n-0.391945338467193\n-0.650023936358253\n30\n10065I\n10065I\n0.464455916345135\n1.3326356122229\n-1.23059563374303\n-0.357975958937414\n1.18249746977104\n1.54315938069757\n-0.60339041154062\n3.38308845958422\n0.823740765148641\n-0.129951318508883\n-0.657979878422938\n-0.499534924074273\n-0.414476569095651\n\n\n\ndescribe\n(\ncg10k_trait\n)\n\n\n\n\n\n\nFID\nLength  6670\nType    UTF8String\nNAs     0\nNA%     0.0%\nUnique  6670\n\nIID\nLength  6670\nType    UTF8String\nNAs     0\nNA%     0.0%\nUnique  6670\n\nTrait1\nMin      -3.2041280147118\n1st Qu.  -0.645770976594801\nMedian   0.12500996951180798\nMean     0.0022113846331389903\n3rd Qu.  0.723315489763611\nMax      3.47939787136478\nNAs      0\nNA%      0.0%\n\nTrait2\nMin      -3.51165862877157\n1st Qu.  -0.6426205239938769\nMedian   0.0335172506981786\nMean     0.0013525291443179934\n3rd Qu.  0.6574666174104795\nMax      4.91342267449592\nNAs      0\nNA%      0.0%\n\nTrait3\nMin      -3.93843646263987\n1st Qu.  -0.6409067201835313\nMedian   -0.000782161570259152\nMean     -0.0012959062525954158\n3rd Qu.  0.6371084235689337\nMax      7.91629946619107\nNAs      0\nNA%      0.0%\n\nTrait4\nMin      -3.60840330795393\n1st Qu.  -0.5460856267376792\nMedian   0.228165419346029\nMean     0.0023089259432067487\n3rd Qu.  0.7152907338009037\nMax      3.12768818152017\nNAs      0\nNA%      0.0%\n\nTrait5\nMin      -4.14874907974159\n1st Qu.  -0.6907651815712426\nMedian   0.03103429560265845\nMean     -0.0017903947913742396\n3rd Qu.  0.7349158784775833\nMax      2.71718436484651\nNAs      0\nNA%      0.0%\n\nTrait6\nMin      -3.82479174931095\n1st Qu.  -0.6627963069407601\nMedian   0.03624198629403995\nMean     -0.001195980597331062\n3rd Qu.  0.7411755243742835\nMax      2.58972802240228\nNAs      0\nNA%      0.0%\n\nTrait7\nMin      -4.27245540828955\n1st Qu.  -0.6389232588654877\nMedian   0.0698010018021233\nMean     -0.0019890555724116853\n3rd Qu.  0.7104228734967848\nMax      2.65377857124275\nNAs      0\nNA%      0.0%\n\nTrait8\nMin      -5.62548796912517\n1st Qu.  -0.6015747053036895\nMedian   -0.0386301401797661\nMean     0.0006140754882985941\n3rd Qu.  0.5273417705306229\nMax      5.8057022359485\nNAs      0\nNA%      0.0%\n\nTrait9\nMin      -5.38196778211456\n1st Qu.  -0.6014287731518224\nMedian   0.10657100636146799\nMean     -0.0018096522573535152\n3rd Qu.  0.6985667613073132\nMax      2.57193558386964\nNAs      0\nNA%      0.0%\n\nTrait10\nMin      -3.54850550601412\n1st Qu.  -0.6336406665339003\nMedian   -0.0966507436079331\nMean     -0.0004370294352533275\n3rd Qu.  0.49861036457390195\nMax      6.53782005410551\nNAs      0\nNA%      0.0%\n\nTrait11\nMin      -3.26491021902041\n1st Qu.  -0.6736846396608624\nMedian   -0.0680437088585371\nMean     -0.0006159181111862523\n3rd Qu.  0.6554864114250585\nMax      4.26240968462615\nNAs      0\nNA%      0.0%\n\nTrait12\nMin      -8.85190902714652\n1st Qu.  -0.5396855871831098\nMedian   -0.1410985990171995\nMean     -0.0005887830910961934\n3rd Qu.  0.35077884186653374\nMax      13.2114017261714\nNAs      0\nNA%      0.0%\n\nTrait13\nMin      -5.59210353493304\n1st Qu.  -0.49228904714392474\nMedian   -0.14102175804213551\nMean     -0.0001512383146454028\n3rd Qu.  0.32480412746681697\nMax      24.174436145414\nNAs      0\nNA%      0.0%\n\n\n\n\n\nY\n \n=\n \nconvert\n(\nMatrix\n{\nFloat64\n},\n \ncg10k_trait\n[:,\n \n3\n:\n15\n])\n\n\nhistogram\n(\nY\n,\n \nlayout\n \n=\n \n13\n)\n\n\n\n\n\n\n\n\n\n\nPre-processing data for heritability analysis\n\n\nTo prepare variance component model fitting, we form an instance of \nVarianceComponentVariate\n. The two variance components are $(2\\Phi, I)$.\n\n\nusing\n \nVarianceComponentModels\n\n\n\n# form data as VarianceComponentVariate\n\n\ncg10kdata\n \n=\n \nVarianceComponentVariate\n(\nY\n,\n \n(\n2\n\u03a6grm\n,\n \neye\n(\nsize\n(\nY\n,\n \n1\n))))\n\n\nfieldnames\n(\ncg10kdata\n)\n\n\n\n\n\n\n3-element Array{Symbol,1}:\n :Y\n :X\n :V\n\n\n\n\n\ncg10kdata\n\n\n\n\n\n\nVarianceComponentModels.VarianceComponentVariate{Float64,2,Array{Float64,2},Array{Float64,2},Array{Float64,2}}(6670x13 Array{Float64,2}:\n -1.81573   -0.94615     1.11363    \u2026   0.824466  -1.02853     -0.394049 \n -1.2444     0.10966     0.467119       3.08264    1.09065      0.0256616\n  1.45567    1.53867     1.09403       -1.10649   -1.42016     -0.687463 \n -0.768809   0.513491    0.244263       0.394175  -0.767366     0.0635386\n -0.264415  -0.34824    -0.0239065      0.549968   0.540688     0.179675 \n -1.37617   -1.47192     0.29118    \u2026   0.947393   0.594015     0.245407 \n  0.100942  -0.191616   -0.567421       0.332636   0.00269165   0.317117 \n -0.319818   1.35774     0.81869        0.220861   0.852512    -0.225905 \n -0.288334   0.566083    0.254958       0.167532   0.246916     0.539933 \n -1.1576    -0.781199   -0.595808       0.7331    -1.73468     -1.35278  \n  0.740569   1.40874     0.73469    \u2026  -0.712244  -0.313346    -0.345419 \n -0.675892   0.279893    0.267916      -0.809014   0.548522    -0.0201829\n -0.79541   -0.69999     0.39913       -0.369483  -1.10153     -0.598132 \n  \u22ee                                 \u22f1   \u22ee                                \n -0.131005   0.425378   -1.09015        0.35674    0.456428     0.882577 \n -0.52427    1.04173     1.13749        0.366737   1.78286      1.90764  \n  1.32516    0.905899    0.84261    \u2026  -0.418756  -0.275519    -0.912778 \n -1.44368   -2.55708    -0.868193       1.31914   -1.44981     -1.77373  \n -1.8518    -1.25726     1.81724        0.770329  -0.0470789    1.50496  \n -0.810034   0.0896703   0.530939       0.757479   1.10001      1.29115  \n -1.22395   -1.48953    -2.95847        1.29209    0.697478     0.228819 \n -0.282847  -1.54129    -1.38819    \u2026   1.00973   -0.362158    -1.55022  \n  0.475008   1.46697     0.497403       0.141684   0.183218     0.122664 \n -0.408154  -0.325323    0.0850869     -0.2214    -0.575183     0.399583 \n  0.886626   0.487408   -0.0977307     -0.985545  -0.636874    -0.439825 \n -1.24394    0.213697    2.74965        1.39201    0.299931     0.392809 ,6670x0 Array{Float64,2},(\n6670x6670 Array{Float64,2}:\n  1.00583       0.00659955   -0.000232427  \u2026  -0.000129257  -0.00562459 \n  0.00659955    0.99784      -0.00403985       0.00181974    0.00691145 \n -0.000232427  -0.00403985    0.987264         0.00058913   -0.000699707\n  0.00186795   -0.00640781   -0.00372219      -0.00483365   -0.00254155 \n -0.000155086  -0.00721501    0.00362883       0.00427952   -0.00316764 \n  0.00400741    0.00115477    0.005091     \u2026   0.00188751   -3.65987e-6 \n  0.00111701    0.00482842   -0.00375641       0.00243399   -0.00247849 \n -0.00131899    0.00639975   -0.00202991       0.00707293   -0.00048186 \n -0.00205238   -0.00240896   -0.00110924       0.00351173    0.00363799 \n -0.00273677    0.00423992    0.000238256     -0.0029461    -0.00210478 \n -0.00412287    0.000297635  -0.000950353  \u2026  -0.000531045  -0.00212246 \n  0.00190203    0.00334083    0.0036709       -0.00140732   -0.00626668 \n  0.000660883  -0.00180829    0.00602955       0.00150954   -0.00254826 \n  \u22ee                                        \u22f1                            \n  0.00602273    0.00232083    0.00200852       1.33451e-5    0.00614137 \n -0.00428016    0.0054185    -0.00370108      -0.00219871    0.00733631 \n  0.00109348   -0.00485292   -0.00610528   \u2026  -0.00125803    0.00421559 \n -0.00845106   -0.00414261   -0.00218104      -0.00141161   -0.00101611 \n -0.00636811   -0.0015077     0.00624753       0.00105766   -7.21938e-5 \n  0.000860393  -0.00394326    0.0053709       -0.0126635    -0.0104067  \n  0.00442858    0.00169958   -0.00202223      -0.00188626   -0.00124884 \n -0.0045805    -0.000261196   0.000203706  \u2026   0.00168027   -0.00460447 \n -0.00405834    0.00466013   -0.00262013       0.00395595   -0.00102754 \n -0.00192981   -0.00174465   -0.000141344      0.00249404   -0.00591688 \n -0.000129257   0.00181974    0.00058913       1.00197       0.00105123 \n -0.00562459    0.00691145   -0.000699707      0.00105123    1.00158    ,\n\n6670x6670 Array{Float64,2}:\n 1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \u2026  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \u2026  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \u2026  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n \u22ee                        \u22ee              \u22f1            \u22ee                      \n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \u2026  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  1.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \u2026  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  1.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  1.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  1.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  1.0))\n\n\n\n\n\nBefore fitting the variance component model, we pre-compute the eigen-decomposition of $2\\Phi_{\\text{GRM}}$, the rotated responses, and the constant part in log-likelihood, and store them as a \nTwoVarCompVariateRotate\n instance, which is re-used in various variane component estimation procedures.\n\n\n# pre-compute eigen-decomposition (~50 secs on my laptop)\n\n\n@\ntime\n \ncg10kdata_rotated\n \n=\n \nTwoVarCompVariateRotate\n(\ncg10kdata\n)\n\n\nfieldnames\n(\ncg10kdata_rotated\n)\n\n\n\n\n\n\n 55.887248 seconds (1.06 M allocations: 1.043 GB, 0.28% gc time)\n\n\n\n\n\n4-element Array{Symbol,1}:\n :Yrot    \n :Xrot    \n :eigval  \n :logdetV2\n\n\n\n\n\n\n\nSave intermediate results\n\n\nWe don't want to re-compute SnpArray and empirical kinship matrices again and again for heritibility analysis.\n\n\n#using JLD\n\n\n#@save \ncg10k.jld\n\n\n#whos()\n\n\n\n\n\n\n                 #210#wsession    280 bytes  JLD.JldWriteSession\n                 #212#wsession    280 bytes  JLD.JldWriteSession\n                          Base  34564 KB     Module\n                       BinDeps    207 KB     Module\n                         Blosc     37 KB     Module\n                    ColorTypes    311 KB     Module\n                        Colors    715 KB     Module\n                        Compat    323 KB     Module\n                         Conda     65 KB     Module\n                          Core   6836 KB     Module\n                    DataArrays    782 KB     Module\n                    DataFrames   1822 KB     Module\n                        Docile    414 KB     Module\n                        FileIO    536 KB     Module\n             FixedPointNumbers     32 KB     Module\n               FixedSizeArrays    157 KB     Module\n                          GZip    771 KB     Module\n                          HDF5   3209 KB     Module\n                        IJulia 2083312 KB     Module\n                IPythonDisplay     36 KB     Module\n                         Ipopt     26 KB     Module\n              IterativeSolvers    485 KB     Module\n                           JLD   1240 KB     Module\n                          JSON    239 KB     Module\n                        KNITRO    274 KB     Module\n                  LaTeXStrings   3108 bytes  Module\n                 LegacyStrings     12 KB     Module\n                    MacroTools    123 KB     Module\n                          Main 2145169 KB     Module\n                  MathProgBase    302 KB     Module\n                      Measures     15 KB     Module\n                        Nettle     58 KB     Module\n                     PlotUtils    441 KB     Module\n                         Plots   2721 KB     Module\n                        PyCall   1016 KB     Module\n                        PyPlot   1252 KB     Module\n                   RecipesBase    174 KB     Module\n                      Reexport   3648 bytes  Module\n                           SHA     50 KB     Module\n                     SnpArrays    439 KB     Module\n             SortingAlgorithms     39 KB     Module\n                     StatsBase    800 KB     Module\n                     StatsFuns    286 KB     Module\n                     URIParser    102 KB     Module\n       VarianceComponentModels    302 KB     Module\n                             Y    677 KB     6670x13 Array{Float64,2}\n                           ZMQ     81 KB     Module\n                             _     77 KB     630860-element BitArray{1}\n                         cg10k 1027303 KB     6670x630860 SnpArrays.SnpArray{2}\n                   cg10k_trait    978 KB     6670\u00d715 DataFrames.DataFrame\n                     cg10kdata 695816 KB     VarianceComponentModels.VarianceCo\u2026\n             cg10kdata_rotated    729 KB     VarianceComponentModels.TwoVarComp\u2026\n                           maf   4928 KB     630860-element Array{Float64,1}\n               missings_by_snp   4928 KB     630860-element Array{Int64,1}\n                        people      8 bytes  Int64\n                          snps      8 bytes  Int64\n                          \u03a6grm 347569 KB     6670x6670 Array{Float64,2}\n\n\n\n\n\nTo load workspace\n\n\n#using SnpArrays, JLD, DataFrames, VarianceComponentModels, Plots\n\n\n#pyplot()\n\n\n#@load \ncg10k.jld\n\n\n#whos()\n\n\n\n\n\n\n\n\nHeritability of single traits\n\n\nWe use Fisher scoring algorithm to fit variance component model for each single trait.\n\n\n# heritability from single trait analysis\n\n\nhST\n \n=\n \nzeros\n(\n13\n)\n\n\n# standard errors of estimated heritability\n\n\nhST_se\n \n=\n \nzeros\n(\n13\n)\n\n\n# additive genetic effects\n\n\n\u03c32a\n \n=\n \nzeros\n(\n13\n)\n\n\n# enviromental effects\n\n\n\u03c32e\n \n=\n \nzeros\n(\n13\n)\n\n\n\n@\ntime\n \nfor\n \ntrait\n \nin\n \n1\n:\n13\n\n    \nprintln\n(\nnames\n(\ncg10k_trait\n)[\ntrait\n \n+\n \n2\n])\n\n    \n# form data set for trait j\n\n    \ntraitj_data\n \n=\n \nTwoVarCompVariateRotate\n(\ncg10kdata_rotated\n.\nYrot\n[:,\n \ntrait\n],\n \ncg10kdata_rotated\n.\nXrot\n,\n \n        \ncg10kdata_rotated\n.\neigval\n,\n \ncg10kdata_rotated\n.\nlogdetV2\n)\n\n    \n# initialize model parameters\n\n    \ntraitj_model\n \n=\n \nVarianceComponentModel\n(\ntraitj_data\n)\n\n    \n# estimate variance components\n\n    \n_\n,\n \n_\n,\n \n_\n,\n \n\u03a3cov\n,\n \n_\n,\n \n_\n \n=\n \nmle_fs!\n(\ntraitj_model\n,\n \ntraitj_data\n;\n \nsolver\n=\n:\nIpopt\n,\n \nverbose\n=\nfalse\n)\n\n    \n\u03c32a\n[\ntrait\n]\n \n=\n \ntraitj_model\n.\n\u03a3\n[\n1\n][\n1\n]\n\n    \n\u03c32e\n[\ntrait\n]\n \n=\n \ntraitj_model\n.\n\u03a3\n[\n2\n][\n1\n]\n\n    \n@\nshow\n \n\u03c32a\n[\ntrait\n],\n \n\u03c32e\n[\ntrait\n]\n\n    \nh\n,\n \nhse\n \n=\n \nheritability\n(\ntraitj_model\n.\n\u03a3\n,\n \n\u03a3cov\n)\n\n    \nhST\n[\ntrait\n]\n \n=\n \nh\n[\n1\n]\n\n    \nhST_se\n[\ntrait\n]\n \n=\n \nhse\n[\n1\n]\n\n\nend\n\n\n\n\n\n\nTrait1\n(\u03c32a[trait],\u03c32e[trait]) = (0.26104123217397407,0.7356884432614137)\nTrait2\n(\u03c32a[trait],\u03c32e[trait]) = (0.1887414738028781,0.8106899991616237)\nTrait3\n(\u03c32a[trait],\u03c32e[trait]) = (0.31857192765473236,0.6801458862875933)\nTrait4\n(\u03c32a[trait],\u03c32e[trait]) = (0.26556901333953215,0.7303588364945378)\nTrait5\n(\u03c32a[trait],\u03c32e[trait]) = (0.28123321193920503,0.7167989047155238)\nTrait6\n(\u03c32a[trait],\u03c32e[trait]) = (0.2829461149704314,0.716562953439665)\nTrait7\n(\u03c32a[trait],\u03c32e[trait]) = (0.2154385640394616,0.7816211121586024)\nTrait8\n(\u03c32a[trait],\u03c32e[trait]) = (0.19412648732666243,0.8055277649986169)\nTrait9\n(\u03c32a[trait],\u03c32e[trait]) = (0.24789561127297127,0.7504615853619782)\nTrait10\n(\u03c32a[trait],\u03c32e[trait]) = (0.10007455815563934,0.8998152773605567)\nTrait11\n(\u03c32a[trait],\u03c32e[trait]) = (0.1648677816930128,0.8338002257315535)\nTrait12\n(\u03c32a[trait],\u03c32e[trait]) = (0.08298660416199151,0.9158035668415299)\nTrait13\n(\u03c32a[trait],\u03c32e[trait]) = (0.05684248094793726,0.942365338132603)\n  1.277847 seconds (27.43 M allocations: 449.203 MB, 6.96% gc time)\n\n\n\n\n\n# heritability and standard errors\n\n\n[\nhST\n;\n \nhST_se\n]\n\n\n\n\n\n\n2x13 Array{Float64,2}:\n 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n\n\n\n\n\n\n\nPairwise traits\n\n\nJoint analysis of multiple traits is subject to intensive research recently. Following code snippet does joint analysis of all pairs of traits, a total of 78 bivariate variane component models.\n\n\n# additive genetic effects (2x2 psd matrices) from bavariate trait analysis;\n\n\n\u03a3a\n \n=\n \nArray\n{\nMatrix\n{\nFloat64\n}}(\n13\n,\n \n13\n)\n\n\n# environmental effects (2x2 psd matrices) from bavariate trait analysis;\n\n\n\u03a3e\n \n=\n \nArray\n{\nMatrix\n{\nFloat64\n}}(\n13\n,\n \n13\n)\n\n\n\n@\ntime\n \nfor\n \ni\n \nin\n \n1\n:\n13\n\n    \nfor\n \nj\n \nin\n \n(\ni\n+\n1\n):\n13\n\n        \nprintln\n(\nnames\n(\ncg10k_trait\n)[\ni\n \n+\n \n2\n],\n \nnames\n(\ncg10k_trait\n)[\nj\n \n+\n \n2\n])\n\n        \n# form data set for (trait1, trait2)\n\n        \ntraitij_data\n \n=\n \nTwoVarCompVariateRotate\n(\ncg10kdata_rotated\n.\nYrot\n[:,\n \n[\ni\n;\nj\n]],\n \ncg10kdata_rotated\n.\nXrot\n,\n \n            \ncg10kdata_rotated\n.\neigval\n,\n \ncg10kdata_rotated\n.\nlogdetV2\n)\n\n        \n# initialize model parameters\n\n        \ntraitij_model\n \n=\n \nVarianceComponentModel\n(\ntraitij_data\n)\n\n        \n# estimate variance components\n\n        \nmle_fs!\n(\ntraitij_model\n,\n \ntraitij_data\n;\n \nsolver\n=\n:\nIpopt\n,\n \nverbose\n=\nfalse\n)\n\n        \n\u03a3a\n[\ni\n,\n \nj\n]\n \n=\n \ntraitij_model\n.\n\u03a3\n[\n1\n]\n\n        \n\u03a3e\n[\ni\n,\n \nj\n]\n \n=\n \ntraitij_model\n.\n\u03a3\n[\n2\n]\n\n        \n@\nshow\n \n\u03a3a\n[\ni\n,\n \nj\n],\n \n\u03a3e\n[\ni\n,\n \nj\n]\n\n    \nend\n\n\nend\n\n\n\n\n\n\nTrait1Trait2\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26011943486601186 0.1762158250617613\n 0.1762158250617613 0.18737615484007947],\n\n[0.7365894055260143 0.5838920954615305\n 0.5838920954615305 0.8120331390284958])\nTrait1Trait3\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2615639935561912 -0.013126818537540254\n -0.013126818537540254 0.3190566225472985],\n\n[0.7351802111599617 -0.12112674834388097\n -0.12112674834388097 0.6796789899243143])\nTrait1Trait4\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2608796031577277 0.22261440559416618\n 0.22261440559416618 0.2655808327606219],\n\n[0.735845998165887 0.5994353345883121\n 0.5994353345883121 0.7303474474501164])\nTrait1Trait5\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2607830377026644 -0.14701178378031446\n -0.14701178378031446 0.28187724546298826],\n\n[0.7359373011287004 -0.25458389055860414\n -0.25458389055860414 0.7161761242033678])\nTrait1Trait6\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2607070355193131 -0.12935642592773852\n -0.12935642592773852 0.28318838486253467],\n\n[0.7360128807197885 -0.231361283307625\n -0.231361283307625 0.716329432342681])\nTrait1Trait7\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26030750074784287 -0.1402575370655325\n -0.1402575370655325 0.2150805562425413],\n\n[0.7364055998763509 -0.19780547645064997\n -0.19780547645064997 0.7819851899285041])\nTrait1Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2610345999103056 -0.03352962807192369\n -0.03352962807192369 0.19414307314249296],\n\n[0.7356949687057843 -0.12627246367180997\n -0.12627246367180997 0.8055115370762379])\nTrait1Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2630163159971886 -0.20486492716336502\n -0.20486492716336502 0.24679565235659717],\n\n[0.7337944623091683 -0.30745013667607846\n -0.30745013667607846 0.7515442213452723])\nTrait1Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26089807908065815 -0.0998175618122165\n -0.0998175618122165 0.09702328543308451],\n\n[0.7358279769605037 -0.30360875962256173\n -0.30360875962256173 0.9028534651901434])\nTrait1Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2607397076711653 -0.13898341539579964\n -0.13898341539579964 0.1630626318546552],\n\n[0.735982002778579 -0.35917453215273204\n -0.35917453215273204 0.8355950431900447])\nTrait1Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26306860075660077 -0.14553553813998849\n -0.14553553813998849 0.08051357250838533],\n\n[0.7337809595143813 -0.04169751340916241\n -0.04169751340916241 0.9183594535088752])\nTrait1Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26234367607968223 -0.10889551714052524\n -0.10889551714052524 0.051294038316720095],\n\n[0.7344496461774143 -0.11399558206598119\n -0.11399558206598119 0.9479424008071721])\nTrait2Trait3\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18901532602813093 0.14615743012019033\n 0.14615743012019033 0.32052865893860505],\n\n[0.8104184413504798 0.09749923852684478\n 0.09749923852684478 0.6782713240483099])\nTrait2Trait4\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18839514990246123 0.07521464811372748\n 0.07521464811372748 0.2655584804130378],\n\n[0.811030102837779 0.2204948315759956\n 0.2204948315759956 0.7303691342564813])\nTrait2Trait5\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18871644001954374 -0.01131401822579143\n -0.01131401822579143 0.2812465335267498],\n\n[0.810714524791035 -0.037010470173424806\n -0.037010470173424806 0.7167859986688715])\nTrait2Trait6\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18877375983465075 -0.00310660369976054\n -0.00310660369976054 0.28301251325859456],\n\n[0.8106583657780116 -0.021182656859443615\n -0.021182656859443615 0.7164985874171053])\nTrait2Trait7\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.1883522257140152 -0.02995792853603445\n -0.02995792853603445 0.21518854248912628],\n\n[0.8110719442656862 -0.0013693865327215602\n -0.0013693865327215602 0.7818678818059402])\nTrait2Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18926168900120724 0.03314229844995283\n 0.03314229844995283 0.19466629556483447],\n\n[0.8101822287422975 -0.0326002707144356\n -0.0326002707144356 0.8050045055369501])\nTrait2Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18728489562655376 -0.08541458777339436\n -0.08541458777339436 0.24671880340597185],\n\n[0.8121330456004312 -0.08087908481059602\n -0.08087908481059602 0.7516171286974279])\nTrait2Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18896456296522746 -0.12531880400522133\n -0.12531880400522133 0.10012137187907984],\n\n[0.8104983819177826 -0.2710710218698844\n -0.2710710218698844 0.8998490679641975])\nTrait2Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18776200371864812 -0.1184792033068952\n -0.1184792033068952 0.16627341912779045],\n\n[0.8116528153526548 -0.2955489949517167\n -0.2955489949517167 0.832437271728203])\nTrait2Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.1881906352068438 -0.09053833116422316\n -0.09053833116422316 0.08226341390094308],\n\n[0.8112716597648593 0.04542203421425378\n 0.04542203421425378 0.9165863321461983])\nTrait2Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18826030571129157 -0.07070412373895248\n -0.07070412373895248 0.05472389417033724],\n\n[0.8112166105484152 0.07379770160245963\n 0.07379770160245963 0.944520839730775])\nTrait3Trait4\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.31852039539972626 -0.15433893723696576\n -0.15433893723696576 0.2647540990554418],\n\n[0.6801958865837233 -0.3034399519706689\n -0.3034399519706689 0.7311518515398231])\nTrait3Trait5\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.31896997787053516 0.18435446676116027\n 0.18435446676116027 0.28250017723831466],\n\n[0.6797599597910079 0.3364105248337092\n 0.3364105248337092 0.7155665412298342])\nTrait3Trait6\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.31956636442184144 0.16663988772517022\n 0.16663988772517022 0.28503131823058603],\n\n[0.6791832508344973 0.2976976595437346\n 0.2976976595437346 0.7145358500001604])\nTrait3Trait7\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.3185755051457358 0.16685216000502112\n 0.16685216000502112 0.21523224225933885],\n\n[0.6801424314858139 0.3471388423850005\n 0.3471388423850005 0.781823130995854])\nTrait3Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.3204992348069676 0.05753194037710734\n 0.05753194037710734 0.1972448985403006],\n\n[0.6782830498092438 0.04425974188550198\n 0.04425974188550198 0.802473783267546])\nTrait3Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.3187191200121132 0.13729240537787007\n 0.13729240537787007 0.24697586633850704],\n\n[0.6800039145599909 0.26710543782880997\n 0.26710543782880997 0.7513573840679394])\nTrait3Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.3189152132176088 -0.07863382344383743\n -0.07863382344383743 0.10110317193536325],\n\n[0.6798145588849664 -0.14078871656381564\n -0.14078871656381564 0.8987982713097735])\nTrait3Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.31782233045956043 -0.01798395917118423\n -0.01798395917118423 0.1647429211651019],\n\n[0.6808712744794143 -0.11416573111891\n -0.11416573111891 0.8339228729012033])\nTrait3Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.3208883401712095 0.08452483760012779\n 0.08452483760012779 0.0869867503137195],\n\n[0.6779139477283616 0.034013271781512075\n 0.034013271781512075 0.9118411342566285])\nTrait3Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.3230087933057131 0.11068106827250586\n 0.11068106827250586 0.06117389942330572],\n\n[0.6759011385391952 -0.007296623887800238\n -0.007296623887800238 0.9380722549963341])\nTrait4Trait5\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2656669903604965 -0.21584756082780146\n -0.21584756082780146 0.2829186620095413],\n\n[0.730254403023407 -0.3766752828931733\n -0.3766752828931733 0.7151643527059122])\nTrait4Trait6\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26614305300780366 -0.20063378204208704\n -0.20063378204208704 0.2844419499811047],\n\n[0.7297943215361493 -0.3468040727735064\n -0.3468040727735064 0.7151119490184537])\nTrait4Trait7\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26448980293893115 -0.18275157344067408\n -0.18275157344067408 0.2141168002370858],\n\n[0.7314145610176318 -0.32617199552839854\n -0.32617199552839854 0.7829351279943724])\nTrait4Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2666939542160246 -0.0976354011540246\n -0.0976354011540246 0.19612608720215985],\n\n[0.7292655955853755 -0.1503604822556339\n -0.1503604822556339 0.8035709853977226])\nTrait4Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.27003652025126973 -0.22740698731778375\n -0.22740698731778375 0.24804582217578136],\n\n[0.7260245141082378 -0.415601435658805\n -0.415601435658805 0.7502976667302643])\nTrait4Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26554294182732757 -0.03381072154054875\n -0.03381072154054875 0.09960982635744982],\n\n[0.7303952879672779 -0.22772490049245936\n -0.22772490049245936 0.9002752447796257])\nTrait4Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2656276022060441 -0.09674003324481623\n -0.09674003324481623 0.16327409085920214],\n\n[0.7303019079384457 -0.2726111957438671\n -0.2726111957438671 0.8353713025178962])\nTrait4Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2681636965467903 -0.14161261172764802\n -0.14161261172764802 0.08039677342809182],\n\n[0.7278825933087102 -0.08284654588272211\n -0.08284654588272211 0.918445560967837])\nTrait4Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2661712320522607 -0.0980730872961898\n -0.0980730872961898 0.05401019173275427],\n\n[0.729774933270783 -0.22505950767232102\n -0.22505950767232102 0.9452044744873448])\nTrait5Trait6\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28159165289454874 0.2808983718818519\n 0.2808983718818519 0.28229805042654726],\n\n[0.7164553609549211 0.6603676496785938\n 0.6603676496785938 0.717195064496623])\nTrait5Trait7\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28081437389240205 0.23209986889788878\n 0.23209986889788878 0.21166204275984282],\n\n[0.7172180317169196 0.6743038172587597\n 0.6743038172587597 0.7853426270989494])\nTrait5Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28134012176468737 0.16394787427626617\n 0.16394787427626617 0.19270331039605396],\n\n[0.7167009109174287 0.2210321091237623\n 0.2210321091237623 0.8069220956477239])\nTrait5Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2838778024838298 0.2445317256807396\n 0.2445317256807396 0.24129303734021107],\n\n[0.7142441395397906 0.5084169870307738\n 0.5084169870307738 0.7568942338389598])\nTrait5Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2818130149574279 -0.04621141466301363\n -0.04621141466301363 0.10148069053449221],\n\n[0.7162383352815093 -0.057211134789489596\n -0.057211134789489596 0.8984242888573427])\nTrait5Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2804235419822887 0.02024954557852043\n 0.02024954557852043 0.16400332024748288],\n\n[0.7175856258526226 -0.03524364741892967\n -0.03524364741892967 0.8346493308285122])\nTrait5Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28142706977012344 0.06161306621995005\n 0.06161306621995005 0.08271662802160216],\n\n[0.7166145561768477 0.0529286449372972\n 0.0529286449372972 0.9160739286176958])\nTrait5Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2822915336764342 0.0704220516897222\n 0.0704220516897222 0.05694630996696085],\n\n[0.7157823114676733 0.052837445512878035\n 0.052837445512878035 0.9422684292567837])\nTrait6Trait7\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2829610760516547 0.2206563210574195\n 0.2206563210574195 0.21385609770082856],\n\n[0.7165486719537999 0.5810829183833723\n 0.5810829183833723 0.7831785715716468])\nTrait6Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2829606227312136 0.18407962646923373\n 0.18407962646923373 0.19237902249802602],\n\n[0.7165491133467123 0.43659738936447606\n 0.43659738936447606 0.8072460050938695])\nTrait6Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28497844062058 0.23443573773381146\n 0.23443573773381146 0.2432071080956827],\n\n[0.7146005305265446 0.4768263391945174\n 0.4768263391945174 0.7550279957473227])\nTrait6Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28365475689672454 -0.04354848104335164\n -0.04354848104335164 0.10202532157941907],\n\n[0.7158768651032459 -0.05916812562776467\n -0.05916812562776467 0.8978859540391582])\nTrait6Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2815224136585793 0.027999198497751236\n 0.027999198497751236 0.16342991310056218],\n\n[0.7179464769867658 -0.05241060710545059\n -0.05241060710545059 0.8352130875914755])\nTrait6Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2831143444111233 0.05713989944443876\n 0.05713989944443876 0.08267893130031188],\n\n[0.7164030333442727 0.047919871306752966\n 0.047919871306752966 0.9161120298157116])\nTrait6Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28381996715653646 0.06112120329706666\n 0.06112120329706666 0.057081689702462565],\n\n[0.7157217792749953 0.05326983474671377\n 0.05326983474671377 0.942133354542685])\nTrait7Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.213856863605251 0.08845552117653824\n 0.08845552117653824 0.19237305507049685],\n\n[0.7831777634597645 -0.05683305954905118\n -0.05683305954905118 0.807251867488134])\nTrait7Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2187556960284994 0.21704186383100332\n 0.21704186383100332 0.24414386503619973],\n\n[0.7784327750440135 0.46290096824972443\n 0.46290096824972443 0.7541229287932897])\nTrait7Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2162729624537394 -0.04211457255557115\n -0.04211457255557115 0.10209048393658933],\n\n[0.7808073891161575 -0.08590745272581501\n -0.08590745272581501 0.8978220136457029])\nTrait7Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.21406877656928827 0.020696687538012654\n 0.020696687538012654 0.16347380945331402],\n\n[0.7829608191265603 -0.04814801124367421\n -0.04814801124367421 0.8351704867213441])\nTrait7Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.21493232506988705 0.07578743223300372\n 0.07578743223300372 0.08087309077189964],\n\n[0.7821316768251394 0.03469555448124276\n 0.03469555448124276 0.9179149818424026])\nTrait7Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.21595864338557708 0.07493726652342743\n 0.07493726652342743 0.05459341128356046],\n\n[0.7811387334979083 0.038905793649911785\n 0.038905793649911785 0.9446215738065965])\nTrait8Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.1945549993500238 0.11281615770315953\n 0.11281615770315953 0.24724415191290416],\n\n[0.8051240570336379 0.18477843243741904\n 0.18477843243741904 0.7510982278179416])\nTrait8Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.19444100261213867 -0.015634153642008396\n -0.015634153642008396 0.10042647889284885],\n\n[0.8052215712386805 0.011982589661319697\n 0.011982589661319697 0.8994678453453964])\nTrait8Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.1938531643383019 0.02253246401818133\n 0.02253246401818133 0.1646685438304724],\n\n[0.8057962945716937 -0.02727473686745877\n -0.02727473686745877 0.8339969682996413])\nTrait8Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.19395121849291824 -0.0028760121862793694\n -0.0028760121862793694 0.08285727475931896],\n\n[0.8056997963655848 0.03361278793070539\n 0.03361278793070539 0.9159318672878024])\nTrait8Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.19397976155497032 0.00407866657222457\n 0.00407866657222457 0.0569071232157577],\n\n[0.8056716012394011 0.03788170752125487\n 0.03788170752125487 0.9423010776566965])\nTrait9Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.24729383232785143 -0.0023083632331894533\n -0.0023083632331894533 0.09982638783372684],\n\n[0.7510505981833204 0.07407294365773788\n 0.07407294365773788 0.9000613327603086])\nTrait9Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.24782344372317563 0.031823502985820915\n 0.031823502985820915 0.1648904641109765],\n\n[0.7505321390736757 0.15228537870002187\n 0.15228537870002187 0.83377795534806])\nTrait9Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.25033469514724843 0.08457136153430893\n 0.08457136153430893 0.08875872340836785],\n\n[0.7480909649333196 0.10775632151728669\n 0.10775632151728669 0.910108091343637])\nTrait9Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.24944189418598844 0.09348451303745715\n 0.09348451303745715 0.05793201493993036],\n\n[0.7489745640206875 0.09821909822628513\n 0.09821909822628513 0.9413348855487351])\nTrait10Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.09313966827485977 0.10003371877328632\n 0.10003371877328632 0.16495492788178234],\n\n[0.906703444773408 0.4744266593662351\n 0.4744266593662351 0.8337151519529007])\nTrait10Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.09672471643798064 0.05640434659756219\n 0.05640434659756219 0.07945282707191781],\n\n[0.9031497841220121 0.08532319187443138\n 0.08532319187443138 0.9193343434315169])\nTrait10Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.10098492171842248 -0.027991587712823545\n -0.027991587712823545 0.0578369411328611],\n\n[0.8989368215861225 0.16605077488864645\n 0.16605077488864645 0.9413901799271158])\nTrait11Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.16384057742532637 0.05703178017185482\n 0.05703178017185482 0.07921436807488584],\n\n[0.8348140972542764 0.14559650974208901\n 0.14559650974208901 0.9195521322078624])\nTrait11Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.1648829333720086 -0.0015841372105068166\n -0.0015841372105068166 0.05749684374690435],\n\n[0.8337979488921528 0.20061222835020495\n 0.20061222835020495 0.9417152321030534])\nTrait12Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.08459459620614283 0.06850521854233418\n 0.06850521854233418 0.05547594264883066],\n\n[0.9142140604502765 0.573152408940862\n 0.573152408940862 0.9437349886346289])\n 98.060194 seconds (2.33 G allocations: 35.661 GB, 7.59% gc time)\n\n\n\n\n\n\n\n3-trait analysis\n\n\nResearchers want to jointly analyze traits 5-7. Our strategy is to try both Fisher scoring and MM algorithm with different starting point, and choose the best local optimum. We first form the data set and run Fisher scoring, which yields a final objective value -1.4700991+04.\n\n\ntraitidx\n \n=\n \n5\n:\n7\n\n\n# form data set\n\n\ntrait57_data\n \n=\n \nTwoVarCompVariateRotate\n(\ncg10kdata_rotated\n.\nYrot\n[:,\n \ntraitidx\n],\n \ncg10kdata_rotated\n.\nXrot\n,\n \n    \ncg10kdata_rotated\n.\neigval\n,\n \ncg10kdata_rotated\n.\nlogdetV2\n)\n\n\n# initialize model parameters\n\n\ntrait57_model\n \n=\n \nVarianceComponentModel\n(\ntrait57_data\n)\n\n\n# estimate variance components\n\n\n@\ntime\n \nmle_fs!\n(\ntrait57_model\n,\n \ntrait57_data\n;\n \nsolver\n=\n:\nIpopt\n,\n \nverbose\n=\ntrue\n)\n\n\ntrait57_model\n\n\n\n\n\n\nThis is Ipopt version 3.12.4, running with linear solver mumps.\nNOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n\nNumber of nonzeros in equality constraint Jacobian...:        0\nNumber of nonzeros in inequality constraint Jacobian.:        0\nNumber of nonzeros in Lagrangian Hessian.............:       78\n\nTotal number of variables............................:       12\n                     variables with only lower bounds:        0\n                variables with lower and upper bounds:        0\n                     variables with only upper bounds:        0\nTotal number of equality constraints.................:        0\nTotal number of inequality constraints...............:        0\n        inequality constraints with only lower bounds:        0\n   inequality constraints with lower and upper bounds:        0\n        inequality constraints with only upper bounds:        0\n\niter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n   0  3.0247512e+04 0.00e+00 1.00e+02   0.0 0.00e+00    -  0.00e+00 0.00e+00   0 \n   5  1.6834796e+04 0.00e+00 4.07e+02 -11.0 3.66e-01    -  1.00e+00 1.00e+00f  1 MaxS\n  10  1.4744497e+04 0.00e+00 1.12e+02 -11.0 2.45e-01    -  1.00e+00 1.00e+00f  1 MaxS\n  15  1.4701497e+04 0.00e+00 1.30e+01 -11.0 1.15e-01  -4.5 1.00e+00 1.00e+00f  1 MaxS\n  20  1.4700992e+04 0.00e+00 6.65e-01 -11.0 1.74e-04  -6.9 1.00e+00 1.00e+00f  1 MaxS\n  25  1.4700991e+04 0.00e+00 2.77e-02 -11.0 7.36e-06  -9.2 1.00e+00 1.00e+00f  1 MaxS\n  30  1.4700991e+04 0.00e+00 1.15e-03 -11.0 3.06e-07 -11.6 1.00e+00 1.00e+00f  1 MaxS\n  35  1.4700991e+04 0.00e+00 4.76e-05 -11.0 1.27e-08 -14.0 1.00e+00 1.00e+00h  1 MaxS\n  40  1.4700991e+04 0.00e+00 1.97e-06 -11.0 5.26e-10 -16.4 1.00e+00 1.00e+00h  1 MaxSA\n  45  1.4700991e+04 0.00e+00 8.17e-08 -11.0 2.18e-11 -18.8 1.00e+00 1.00e+00h  1 MaxSA\niter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n\nNumber of Iterations....: 49\n\n                                   (scaled)                 (unscaled)\nObjective...............:   4.4724330090668150e+02    1.4700991028593420e+04\nDual infeasibility......:   6.4551211049368979e-09    2.1218132783605816e-07\nConstraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\nComplementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00\nOverall NLP error.......:   6.4551211049368979e-09    2.1218132783605816e-07\n\n\nNumber of objective function evaluations             = 50\nNumber of objective gradient evaluations             = 50\nNumber of equality constraint evaluations            = 0\nNumber of inequality constraint evaluations          = 0\nNumber of equality constraint Jacobian evaluations   = 0\nNumber of inequality constraint Jacobian evaluations = 0\nNumber of Lagrangian Hessian evaluations             = 49\nTotal CPU secs in IPOPT (w/o function evaluations)   =      0.022\nTotal CPU secs in NLP function evaluations           =      3.613\n\nEXIT: Optimal Solution Found.\n  3.714206 seconds (93.11 M allocations: 1.410 GB, 7.39% gc time)\n\n\n\n\n\nVarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(0x3 Array{Float64,2},(\n3x3 Array{Float64,2}:\n 0.281163  0.280014  0.232384\n 0.280014  0.284899  0.220285\n 0.232384  0.220285  0.212687,\n\n3x3 Array{Float64,2}:\n 0.716875  0.66125   0.674025\n 0.66125   0.714602  0.581433\n 0.674025  0.581433  0.784324),0x0 Array{Float64,2},Char[],Float64[],-Inf,Inf)\n\n\n\n\n\nWe then run the MM algorithm, starting from the Fisher scoring answer. MM finds an improved solution with objective value 8.955397e+03.\n\n\n# trait59_model contains the fitted model by Fisher scoring now\n\n\n@\ntime\n \nmle_mm!\n(\ntrait57_model\n,\n \ntrait57_data\n;\n \nverbose\n=\ntrue\n)\n\n\ntrait57_model\n\n\n\n\n\n\n     MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0  -1.470099e+04\n       1  -1.470099e+04\n\n  0.083887 seconds (2.06 M allocations: 35.243 MB, 5.32% gc time)\n\n\n\n\n\nVarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(0x3 Array{Float64,2},(\n3x3 Array{Float64,2}:\n 0.281163  0.280014  0.232384\n 0.280014  0.284899  0.220285\n 0.232384  0.220285  0.212687,\n\n3x3 Array{Float64,2}:\n 0.716875  0.66125   0.674025\n 0.66125   0.714602  0.581433\n 0.674025  0.581433  0.784324),0x0 Array{Float64,2},Char[],Float64[],-Inf,Inf)\n\n\n\n\n\nDo another run of MM algorithm from default starting point. It leads to a slightly better local optimum -1.470104e+04, slighly worse than the Fisher scoring result. Follow up anlaysis should use the Fisher scoring result.\n\n\n# default starting point\n\n\ntrait57_model\n \n=\n \nVarianceComponentModel\n(\ntrait57_data\n)\n\n\n@\ntime\n \n_\n,\n \n_\n,\n \n_\n,\n \n\u03a3cov\n,\n \n=\n \nmle_mm!\n(\ntrait57_model\n,\n \ntrait57_data\n;\n \nverbose\n=\ntrue\n)\n\n\ntrait57_model\n\n\n\n\n\n\n     MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0  -3.024751e+04\n       1  -2.040338e+04\n       2  -1.656127e+04\n       3  -1.528591e+04\n       4  -1.491049e+04\n       5  -1.480699e+04\n       6  -1.477870e+04\n       7  -1.477026e+04\n       8  -1.476696e+04\n       9  -1.476499e+04\n      10  -1.476339e+04\n      20  -1.475040e+04\n      30  -1.474042e+04\n      40  -1.473272e+04\n      50  -1.472677e+04\n      60  -1.472215e+04\n      70  -1.471852e+04\n      80  -1.471565e+04\n      90  -1.471336e+04\n     100  -1.471152e+04\n     110  -1.471002e+04\n     120  -1.470879e+04\n     130  -1.470778e+04\n     140  -1.470694e+04\n     150  -1.470623e+04\n     160  -1.470563e+04\n     170  -1.470513e+04\n     180  -1.470469e+04\n     190  -1.470432e+04\n     200  -1.470400e+04\n     210  -1.470372e+04\n     220  -1.470347e+04\n     230  -1.470326e+04\n     240  -1.470307e+04\n     250  -1.470290e+04\n     260  -1.470275e+04\n     270  -1.470262e+04\n     280  -1.470250e+04\n     290  -1.470239e+04\n     300  -1.470229e+04\n     310  -1.470220e+04\n     320  -1.470213e+04\n     330  -1.470205e+04\n     340  -1.470199e+04\n     350  -1.470193e+04\n     360  -1.470187e+04\n     370  -1.470182e+04\n     380  -1.470177e+04\n     390  -1.470173e+04\n     400  -1.470169e+04\n     410  -1.470165e+04\n     420  -1.470162e+04\n     430  -1.470159e+04\n     440  -1.470156e+04\n     450  -1.470153e+04\n     460  -1.470150e+04\n     470  -1.470148e+04\n     480  -1.470146e+04\n     490  -1.470143e+04\n     500  -1.470141e+04\n     510  -1.470140e+04\n     520  -1.470138e+04\n     530  -1.470136e+04\n     540  -1.470134e+04\n     550  -1.470133e+04\n     560  -1.470132e+04\n     570  -1.470130e+04\n     580  -1.470129e+04\n     590  -1.470128e+04\n     600  -1.470127e+04\n     610  -1.470125e+04\n     620  -1.470124e+04\n     630  -1.470123e+04\n     640  -1.470122e+04\n     650  -1.470122e+04\n     660  -1.470121e+04\n     670  -1.470120e+04\n     680  -1.470119e+04\n     690  -1.470118e+04\n     700  -1.470118e+04\n     710  -1.470117e+04\n     720  -1.470116e+04\n     730  -1.470116e+04\n     740  -1.470115e+04\n     750  -1.470114e+04\n     760  -1.470114e+04\n     770  -1.470113e+04\n     780  -1.470113e+04\n     790  -1.470112e+04\n     800  -1.470112e+04\n     810  -1.470111e+04\n     820  -1.470111e+04\n     830  -1.470111e+04\n     840  -1.470110e+04\n     850  -1.470110e+04\n     860  -1.470109e+04\n     870  -1.470109e+04\n     880  -1.470109e+04\n     890  -1.470108e+04\n     900  -1.470108e+04\n     910  -1.470108e+04\n     920  -1.470108e+04\n     930  -1.470107e+04\n     940  -1.470107e+04\n     950  -1.470107e+04\n     960  -1.470106e+04\n     970  -1.470106e+04\n     980  -1.470106e+04\n     990  -1.470106e+04\n    1000  -1.470106e+04\n    1010  -1.470105e+04\n    1020  -1.470105e+04\n    1030  -1.470105e+04\n    1040  -1.470105e+04\n    1050  -1.470105e+04\n    1060  -1.470104e+04\n    1070  -1.470104e+04\n    1080  -1.470104e+04\n    1090  -1.470104e+04\n    1100  -1.470104e+04\n    1110  -1.470104e+04\n\n  9.687002 seconds (224.30 M allocations: 5.566 GB, 13.29% gc time)\n\n\n\n\n\nVarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(0x3 Array{Float64,2},(\n3x3 Array{Float64,2}:\n 0.281188  0.280032  0.232439\n 0.280032  0.284979  0.220432\n 0.232439  0.220432  0.212922,\n\n3x3 Array{Float64,2}:\n 0.71685   0.661232  0.67397 \n 0.661232  0.71452   0.581287\n 0.67397   0.581287  0.784092),0x0 Array{Float64,2},Char[],Float64[],-Inf,Inf)\n\n\n\n\n\nHeritability from 3-variate estimate and their standard errors.\n\n\nh\n,\n \nhse\n \n=\n \nheritability\n(\ntrait57_model\n.\n\u03a3\n,\n \n\u03a3cov\n)\n\n\n[\nh\n;\n \nhse\n]\n\n\n\n\n\n\n2x3 Array{Float64,2}:\n 0.281741   0.285122   0.21356  \n 0.0778033  0.0773313  0.0841103\n\n\n\n\n\n\n\nSave analysis results\n\n\n#using JLD\n\n\n#@save \ncopd.jld\n\n\n#whos()", 
            "title": "Heritability"
        }, 
        {
            "location": "/man/heritability/#heritability-analysis", 
            "text": "As an application of the variance component model, this note demonstrates the workflow for heritability analysis in genetics, using a sample data set  cg10k  with  6,670  individuals and  630,860  SNPs. Person IDs and phenotype names are masked for privacy.  cg10k.bed ,  cg10k.bim , and  cg10k.fam  is a set of Plink files in binary format.  cg10k_traits.txt  contains 13 phenotypes of the 6,670 individuals.  ; ls   cg10k *.*   cg10k.bed\ncg10k.bim\ncg10k.fam\ncg10k_traits.txt  Machine information:  versioninfo ()   Julia Version 0.4.6\nCommit 2e358ce (2016-06-19 17:16 UTC)\nPlatform Info:\n  System: Darwin (x86_64-apple-darwin13.4.0)\n  CPU: Intel(R) Core(TM) i7-3720QM CPU @ 2.60GHz\n  WORD_SIZE: 64\n  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Sandybridge)\n  LAPACK: libopenblas64_\n  LIBM: libopenlibm\n  LLVM: libLLVM-3.3", 
            "title": "Heritability Analysis"
        }, 
        {
            "location": "/man/heritability/#read-in-binary-snp-data", 
            "text": "We will use the  SnpArrays.jl  package to read in binary SNP data and compute the empirical kinship matrix. Issue  Pkg.clone(\"git@github.com:OpenMendel/SnpArrays.jl.git\")  within  Julia  to install the  SnpArrays  package.  #Pkg.clone( git@github.com:OpenMendel/SnpArrays.jl.git )  using   SnpArrays   # read in genotype data from Plink binary file (~50 secs on my laptop)  @ time   cg10k   =   SnpArray ( cg10k )    55.188439 seconds (514.43 k allocations: 1.003 GB, 0.02% gc time)\n\n\n\n\n\n6670x630860 SnpArrays.SnpArray{2}:\n (false,true)   (false,true)   (true,true)   \u2026  (true,true)    (true,true) \n (true,true)    (true,true)    (false,true)     (false,true)   (true,false)\n (true,true)    (true,true)    (false,true)     (true,true)    (true,true) \n (true,true)    (true,true)    (true,true)      (false,true)   (true,true) \n (true,true)    (true,true)    (true,true)      (true,true)    (false,true)\n (false,true)   (false,true)   (true,true)   \u2026  (true,true)    (true,true) \n (false,false)  (false,false)  (true,true)      (true,true)    (true,true) \n (true,true)    (true,true)    (true,true)      (true,true)    (false,true)\n (true,true)    (true,true)    (false,true)     (true,true)    (true,true) \n (true,true)    (true,true)    (true,true)      (false,true)   (true,true) \n (true,true)    (true,true)    (false,true)  \u2026  (true,true)    (true,true) \n (false,true)   (false,true)   (true,true)      (true,true)    (false,true)\n (true,true)    (true,true)    (true,true)      (true,true)    (false,true)\n \u22ee                                           \u22f1                             \n (false,true)   (false,true)   (true,true)      (false,true)   (false,true)\n (false,true)   (false,true)   (false,true)     (false,true)   (true,true) \n (true,true)    (true,true)    (false,true)  \u2026  (false,true)   (true,true) \n (false,true)   (false,true)   (true,true)      (true,true)    (false,true)\n (true,true)    (true,true)    (true,true)      (false,true)   (true,true) \n (true,true)    (true,true)    (true,false)     (false,false)  (false,true)\n (true,true)    (true,true)    (true,true)      (true,true)    (false,true)\n (true,true)    (true,true)    (false,true)  \u2026  (true,true)    (true,true) \n (true,true)    (true,true)    (true,true)      (false,true)   (true,true) \n (true,true)    (true,true)    (true,true)      (true,true)    (false,true)\n (false,true)   (false,true)   (true,true)      (true,true)    (true,true) \n (true,true)    (true,true)    (true,true)      (true,true)    (true,true)", 
            "title": "Read in binary SNP data"
        }, 
        {
            "location": "/man/heritability/#summary-statistics-of-snp-data", 
            "text": "people ,   snps   =   size ( cg10k )   (6670,630860)  # summary statistics (~50 secs on my laptop)  @ time   maf ,   _ ,   missings_by_snp ,   =   summarize ( cg10k );    38.734869 seconds (21 allocations: 9.753 MB, 0.01% gc time)  # 5 number summary and average MAF (minor allele frequencies)  quantile ( maf ,   [ 0.0   . 25   . 5   . 75   1.0 ]),   mean ( maf )   (\n1x5 Array{Float64,2}:\n 0.00841726  0.124063  0.236953  0.364253  0.5,\n\n0.24536516625042462)  using   Plots  pyplot ()  histogram ( maf ,   xlab   =   Minor Allele Frequency (MAF) ,   label   =   MAF )    # proportion of missing genotypes  sum ( missings_by_snp )   /   length ( cg10k )   0.0013128198764010824  # proportion of rare SNPs with maf   0.05  countnz ( maf   .   0.05 )   /   length ( maf )   0.07228069619249913", 
            "title": "Summary statistics of SNP data"
        }, 
        {
            "location": "/man/heritability/#empirical-kinship-matrix", 
            "text": "We estimate empirical kinship based on all SNPs by the genetic relation matrix (GRM). Missing genotypes are imputed on the fly by drawing according to the minor allele frequencies.  # GRM using all SNPs (~10 mins on my laptop)  srand ( 123 )  @ time   \u03a6grm   =   grm ( cg10k ;   method   =   : GRM )   567.048450 seconds (4.21 G allocations: 64.513 GB, 1.11% gc time)\n\n\n\n\n\n6670x6670 Array{Float64,2}:\n  0.502916      0.00329978   -0.000116213  \u2026  -6.46286e-5   -0.00281229 \n  0.00329978    0.49892      -0.00201992       0.000909871   0.00345573 \n -0.000116213  -0.00201992    0.493632         0.000294565  -0.000349854\n  0.000933977  -0.00320391   -0.0018611       -0.00241682   -0.00127078 \n -7.75429e-5   -0.0036075     0.00181442       0.00213976   -0.00158382 \n  0.00200371    0.000577386   0.0025455    \u2026   0.000943753  -1.82994e-6 \n  0.000558503   0.00241421   -0.0018782        0.001217     -0.00123924 \n -0.000659495   0.00319987   -0.00101496       0.00353646   -0.00024093 \n -0.00102619   -0.00120448   -0.00055462       0.00175586    0.00181899 \n -0.00136838    0.00211996    0.000119128     -0.00147305   -0.00105239 \n -0.00206144    0.000148818  -0.000475177  \u2026  -0.000265522  -0.00106123 \n  0.000951016   0.00167042    0.00183545      -0.000703658  -0.00313334 \n  0.000330442  -0.000904147   0.00301478       0.000754772  -0.00127413 \n  \u22ee                                        \u22f1                            \n  0.00301137    0.00116042    0.00100426       6.67254e-6    0.00307069 \n -0.00214008    0.00270925   -0.00185054      -0.00109935    0.00366816 \n  0.000546739  -0.00242646   -0.00305264   \u2026  -0.000629014   0.00210779 \n -0.00422553   -0.0020713    -0.00109052      -0.000705804  -0.000508055\n -0.00318405   -0.00075385    0.00312377       0.00052883   -3.60969e-5 \n  0.000430196  -0.00197163    0.00268545      -0.00633175   -0.00520337 \n  0.00221429    0.000849792  -0.00101111      -0.000943129  -0.000624419\n -0.00229025   -0.000130598   0.000101853  \u2026   0.000840136  -0.00230224 \n -0.00202917    0.00233007   -0.00131006       0.00197798   -0.000513771\n -0.000964907  -0.000872326  -7.06722e-5       0.00124702   -0.00295844 \n -6.46286e-5    0.000909871   0.000294565      0.500983      0.000525615\n -0.00281229    0.00345573   -0.000349854      0.000525615   0.500792", 
            "title": "Empirical kinship matrix"
        }, 
        {
            "location": "/man/heritability/#phenotypes", 
            "text": "Read in the phenotype data and compute descriptive statistics.  using   DataFrames  cg10k_trait   =   readtable ( \n     cg10k_traits.txt ;  \n     separator   =     , \n     names   =   [: FID ;   : IID ;   : Trait1 ;   : Trait2 ;   : Trait3 ;   : Trait4 ;   : Trait5 ;   : Trait6 ;  \n              : Trait7 ;   : Trait8 ;   : Trait9 ;   : Trait10 ;   : Trait11 ;   : Trait12 ;   : Trait13 ],   \n     eltypes   =   [ UTF8String ;   UTF8String ;   Float64 ;   Float64 ;   Float64 ;   Float64 ;   Float64 ;  \n                Float64 ;   Float64 ;   Float64 ;   Float64 ;   Float64 ;   Float64 ;   Float64 ;   Float64 ] \n     )   FID IID Trait1 Trait2 Trait3 Trait4 Trait5 Trait6 Trait7 Trait8 Trait9 Trait10 Trait11 Trait12 Trait13 1 10002K 10002K -1.81573145026234 -0.94615046147283 1.11363077580442 -2.09867121119159 0.744416614111748 0.00139171884080131 0.934732480409667 -1.22677315418103 1.1160784277875 -0.4436280335029 0.824465656443384 -1.02852542216546 -0.394049201727681 2 10004O 10004O -1.24440094378729 0.109659992547179 0.467119394241789 -1.62131304097589 1.0566758355683 0.978946979419181 1.00014633946047 0.32487427140228 1.16232175219696 2.6922706948705 3.08263672461047 1.09064954786013 0.0256616415357438 3 10005Q 10005Q 1.45566914502305 1.53866932923243 1.09402959376555 0.586655272226893 -0.32796454430367 -0.30337709778827 -0.0334354881314741 -0.464463064285437 -0.3319396273436 -0.486839089635991 -1.10648681564373 -1.42015780427231 -0.687463456644413 4 10006S 10006S -0.768809276698548 0.513490885514249 0.244263028382142 -1.31740254475691 1.19393774326845 1.17344127734288 1.08737426675232 0.536022583732261 0.802759240762068 0.234159411749815 0.394174866891074 -0.767365892476029 0.0635385761884935 5 10009Y 10009Y -0.264415132547719 -0.348240421825694 -0.0239065083413606 0.00473915802244948 1.25619191712193 1.2038883667631 1.29800739042627 0.310113660247311 0.626159861059352 0.899289129831224 0.54996783350812 0.540687809542048 0.179675416046033 6 10010J 10010J -1.37617270917293 -1.47191967744564 0.291179894254146 -0.803110740704731 -0.264239977442213 -0.260573027836772 -0.165372266287781 -0.219257294118362 1.04702422290318 -0.0985815534616482 0.947393438068448 0.594014812031438 0.245407436348479 7 10011L 10011L 0.1009416296374 -0.191615722103455 -0.567421321596677 0.378571487240382 -0.246656179817904 -0.608810750053858 0.189081058215596 -1.27077787326519 -0.452476199143965 0.702562877297724 0.332636218957179 0.0026916503626181 0.317117176705358 8 10013P 10013P -0.319818276367464 1.35774480657283 0.818689545938528 -1.15565531644352 0.63448368102259 0.291461908634679 0.933323714954726 -0.741083289682492 0.647477683507572 -0.970877627077966 0.220861165411304 0.852512250237764 -0.225904624283945 9 10014R 10014R -0.288334173342032 0.566082538090752 0.254958336116175 -0.652578302869714 0.668921559277347 0.978309199170558 0.122862966041938 1.4790926378214 0.0672132424173449 0.0795903917527827 0.167532455243232 0.246915579442139 0.539932616458363 10 10015T 10015T -1.15759732583991 -0.781198583545165 -0.595807759833517 -1.00554980260402 0.789828885933321 0.571058413379044 0.951304176233755 -0.295962982984816 0.99042002479707 0.561309366988983 0.733100030623233 -1.73467772245684 -1.35278484330654 11 10017X 10017X 0.740569150459031 1.40873846755415 0.734689999440088 0.0208322841295094 -0.337440968561619 -0.458304040611395 -0.142582512772326 -0.580392297464107 -0.684684998101516 -0.00785381461893456 -0.712244337518008 -0.313345561230878 -0.345419463162219 12 10020M 10020M -0.675892486454995 0.279892613829682 0.267915996308248 -1.04103665392985 0.910741715645888 0.866027618513171 1.07414431702005 0.0381751003538302 0.766355377018601 -0.340118016143495 -0.809013958505059 0.548521663785885 -0.0201828675962336 13 10022Q 10022Q -0.795410435603455 -0.699989939762738 0.3991295030063 -0.510476261900736 1.51552245416844 1.28743032939467 1.53772393250903 0.133989160117702 1.02025736886037 0.499018733899186 -0.36948273277931 -1.10153460436318 -0.598132438886619 14 10023S 10023S -0.193483122930324 -0.286021160323518 -0.691494225262995 0.0131581678700699 1.52337470686782 1.4010638072262 1.53114620451896 0.333066483478075 1.04372480381099 0.163206783570466 -0.422883765001728 -0.383527976713573 -0.489221907788158 15 10028C 10028C 0.151246203379718 2.09185108993614 2.03800472474384 -1.12474717143531 1.66557024390713 1.62535675109576 1.58751070483655 0.635852186043776 0.842577784605979 0.450761870778952 -1.39479033623028 -0.560984107567768 0.289349776549287 16 10031R 10031R -0.464608740812712 0.36127694772303 1.2327673928287 -0.826033731086383 1.43475224709983 1.74451823818846 0.211096887484638 2.64816425140548 1.02511433146096 0.11975731603184 0.0596832073448267 -0.631231612661616 -0.207878671782927 17 10032T 10032T -0.732977488012215 -0.526223425889779 0.61657871336593 -0.55447974332593 0.947484859025104 0.936833214138173 0.972516806335524 0.290251013865227 1.01285359725723 0.516207422283291 -0.0300689171988194 0.8787322524583 0.450254629309513 18 10034X 10034X -0.167326459622119 0.175327165487237 0.287467725892572 -0.402652532084246 0.551181509418056 0.522204743290975 0.436837660094653 0.299564933845579 0.583109520896067 -0.704415820005353 -0.730810367994577 -1.95140580379896 -0.933504665700164 19 10035Z 10035Z 1.41159485787418 1.78722407901017 0.84397639585364 0.481278083772991 -0.0887673728508268 -0.49957757426858 0.304195897924847 -1.23884208383369 -0.153475724036624 -0.870486102788329 0.0955473331150403 -0.983708050882817 -0.3563445644514 20 10041U 10041U -1.42997091652825 -0.490147045034213 0.272730237607695 -1.61029992954153 0.990787817197748 0.711687532608184 1.1885836012715 -0.371229188075638 1.24703459239952 -0.0389162332271516 0.883495749072872 2.58988026321017 3.33539552370368 21 10047G 10047G -0.147247288176765 0.12328430415652 0.617549051912237 -0.18713077178262 0.256438107586694 0.17794983735083 0.412611806463263 -0.244809124559737 0.0947624806136492 0.723017223849532 -0.683948354633436 0.0873751276309269 -0.262209652750371 22 10051X 10051X -0.187112676773894 -0.270777264595619 -1.01556818551606 0.0602850568600233 0.272419757757978 0.869133161879197 -0.657519461414234 2.32388522018189 -0.999936011525034 1.44671844178306 0.971157886040772 -0.358747904241515 -0.439657942096136 23 10052Z 10052Z -1.82434047163768 -0.933480446068067 1.29474003766977 -1.94545221151036 0.33584651189654 0.359201654302844 0.513652924365886 -0.073197696696958 1.57139042812005 1.53329371326728 1.82076821859528 2.22740301867829 1.50063347195857 24 10056H 10056H -2.29344084351335 -2.49161842344418 0.40383988742336 -2.36488074752948 1.4105254831956 1.42244117147792 1.17024166272172 0.84476650176855 1.79026875432495 0.648181858970515 -0.0857231057403538 -1.02789535292617 0.491288088952859 25 10057J 10057J -0.434135932888305 0.740881989034652 0.699576357578518 -1.02405543187775 0.759529223983713 0.956656110895288 0.633299568656589 0.770733932268516 0.824988511714526 1.84287437634769 1.91045942063443 -0.502317207869366 0.132670133448219 26 10058L 10058L -2.1920969546557 -2.49465664272271 0.354854763893431 -1.93155848635714 0.941979400289938 0.978917101414106 0.894860097289736 0.463239402831873 1.12537133317163 1.70528446191955 0.717792714479123 0.645888049108261 0.783968250169388 27 10060Y 10060Y -1.46602269088422 -1.24921677101897 0.307977693653039 -1.55097364660989 0.618908494474798 0.662508171662042 0.475957173906078 0.484718674597707 0.401564892028249 0.55987973254026 -0.376938143754217 -0.933982629228218 0.390013151672955 28 10062C 10062C -1.83317744236881 -1.53268787828701 2.55674262685865 -1.51827745783835 0.789409601746455 0.908747799728588 0.649971922941479 0.668373649931667 1.20058303519903 0.277963256075637 1.2504953198275 3.31370445071638 2.22035828885342 29 10064G 10064G -0.784546628243178 0.276582579543931 3.01104958800057 -1.11978843206758 0.920823858422707 0.750217689886151 1.26153730009639 -0.403363882922417 0.400667296857811 -0.217597941303479 -0.724669537565068 -0.391945338467193 -0.650023936358253 30 10065I 10065I 0.464455916345135 1.3326356122229 -1.23059563374303 -0.357975958937414 1.18249746977104 1.54315938069757 -0.60339041154062 3.38308845958422 0.823740765148641 -0.129951318508883 -0.657979878422938 -0.499534924074273 -0.414476569095651  describe ( cg10k_trait )   FID\nLength  6670\nType    UTF8String\nNAs     0\nNA%     0.0%\nUnique  6670\n\nIID\nLength  6670\nType    UTF8String\nNAs     0\nNA%     0.0%\nUnique  6670\n\nTrait1\nMin      -3.2041280147118\n1st Qu.  -0.645770976594801\nMedian   0.12500996951180798\nMean     0.0022113846331389903\n3rd Qu.  0.723315489763611\nMax      3.47939787136478\nNAs      0\nNA%      0.0%\n\nTrait2\nMin      -3.51165862877157\n1st Qu.  -0.6426205239938769\nMedian   0.0335172506981786\nMean     0.0013525291443179934\n3rd Qu.  0.6574666174104795\nMax      4.91342267449592\nNAs      0\nNA%      0.0%\n\nTrait3\nMin      -3.93843646263987\n1st Qu.  -0.6409067201835313\nMedian   -0.000782161570259152\nMean     -0.0012959062525954158\n3rd Qu.  0.6371084235689337\nMax      7.91629946619107\nNAs      0\nNA%      0.0%\n\nTrait4\nMin      -3.60840330795393\n1st Qu.  -0.5460856267376792\nMedian   0.228165419346029\nMean     0.0023089259432067487\n3rd Qu.  0.7152907338009037\nMax      3.12768818152017\nNAs      0\nNA%      0.0%\n\nTrait5\nMin      -4.14874907974159\n1st Qu.  -0.6907651815712426\nMedian   0.03103429560265845\nMean     -0.0017903947913742396\n3rd Qu.  0.7349158784775833\nMax      2.71718436484651\nNAs      0\nNA%      0.0%\n\nTrait6\nMin      -3.82479174931095\n1st Qu.  -0.6627963069407601\nMedian   0.03624198629403995\nMean     -0.001195980597331062\n3rd Qu.  0.7411755243742835\nMax      2.58972802240228\nNAs      0\nNA%      0.0%\n\nTrait7\nMin      -4.27245540828955\n1st Qu.  -0.6389232588654877\nMedian   0.0698010018021233\nMean     -0.0019890555724116853\n3rd Qu.  0.7104228734967848\nMax      2.65377857124275\nNAs      0\nNA%      0.0%\n\nTrait8\nMin      -5.62548796912517\n1st Qu.  -0.6015747053036895\nMedian   -0.0386301401797661\nMean     0.0006140754882985941\n3rd Qu.  0.5273417705306229\nMax      5.8057022359485\nNAs      0\nNA%      0.0%\n\nTrait9\nMin      -5.38196778211456\n1st Qu.  -0.6014287731518224\nMedian   0.10657100636146799\nMean     -0.0018096522573535152\n3rd Qu.  0.6985667613073132\nMax      2.57193558386964\nNAs      0\nNA%      0.0%\n\nTrait10\nMin      -3.54850550601412\n1st Qu.  -0.6336406665339003\nMedian   -0.0966507436079331\nMean     -0.0004370294352533275\n3rd Qu.  0.49861036457390195\nMax      6.53782005410551\nNAs      0\nNA%      0.0%\n\nTrait11\nMin      -3.26491021902041\n1st Qu.  -0.6736846396608624\nMedian   -0.0680437088585371\nMean     -0.0006159181111862523\n3rd Qu.  0.6554864114250585\nMax      4.26240968462615\nNAs      0\nNA%      0.0%\n\nTrait12\nMin      -8.85190902714652\n1st Qu.  -0.5396855871831098\nMedian   -0.1410985990171995\nMean     -0.0005887830910961934\n3rd Qu.  0.35077884186653374\nMax      13.2114017261714\nNAs      0\nNA%      0.0%\n\nTrait13\nMin      -5.59210353493304\n1st Qu.  -0.49228904714392474\nMedian   -0.14102175804213551\nMean     -0.0001512383146454028\n3rd Qu.  0.32480412746681697\nMax      24.174436145414\nNAs      0\nNA%      0.0%  Y   =   convert ( Matrix { Float64 },   cg10k_trait [:,   3 : 15 ])  histogram ( Y ,   layout   =   13 )", 
            "title": "Phenotypes"
        }, 
        {
            "location": "/man/heritability/#pre-processing-data-for-heritability-analysis", 
            "text": "To prepare variance component model fitting, we form an instance of  VarianceComponentVariate . The two variance components are $(2\\Phi, I)$.  using   VarianceComponentModels  # form data as VarianceComponentVariate  cg10kdata   =   VarianceComponentVariate ( Y ,   ( 2 \u03a6grm ,   eye ( size ( Y ,   1 ))))  fieldnames ( cg10kdata )   3-element Array{Symbol,1}:\n :Y\n :X\n :V  cg10kdata   VarianceComponentModels.VarianceComponentVariate{Float64,2,Array{Float64,2},Array{Float64,2},Array{Float64,2}}(6670x13 Array{Float64,2}:\n -1.81573   -0.94615     1.11363    \u2026   0.824466  -1.02853     -0.394049 \n -1.2444     0.10966     0.467119       3.08264    1.09065      0.0256616\n  1.45567    1.53867     1.09403       -1.10649   -1.42016     -0.687463 \n -0.768809   0.513491    0.244263       0.394175  -0.767366     0.0635386\n -0.264415  -0.34824    -0.0239065      0.549968   0.540688     0.179675 \n -1.37617   -1.47192     0.29118    \u2026   0.947393   0.594015     0.245407 \n  0.100942  -0.191616   -0.567421       0.332636   0.00269165   0.317117 \n -0.319818   1.35774     0.81869        0.220861   0.852512    -0.225905 \n -0.288334   0.566083    0.254958       0.167532   0.246916     0.539933 \n -1.1576    -0.781199   -0.595808       0.7331    -1.73468     -1.35278  \n  0.740569   1.40874     0.73469    \u2026  -0.712244  -0.313346    -0.345419 \n -0.675892   0.279893    0.267916      -0.809014   0.548522    -0.0201829\n -0.79541   -0.69999     0.39913       -0.369483  -1.10153     -0.598132 \n  \u22ee                                 \u22f1   \u22ee                                \n -0.131005   0.425378   -1.09015        0.35674    0.456428     0.882577 \n -0.52427    1.04173     1.13749        0.366737   1.78286      1.90764  \n  1.32516    0.905899    0.84261    \u2026  -0.418756  -0.275519    -0.912778 \n -1.44368   -2.55708    -0.868193       1.31914   -1.44981     -1.77373  \n -1.8518    -1.25726     1.81724        0.770329  -0.0470789    1.50496  \n -0.810034   0.0896703   0.530939       0.757479   1.10001      1.29115  \n -1.22395   -1.48953    -2.95847        1.29209    0.697478     0.228819 \n -0.282847  -1.54129    -1.38819    \u2026   1.00973   -0.362158    -1.55022  \n  0.475008   1.46697     0.497403       0.141684   0.183218     0.122664 \n -0.408154  -0.325323    0.0850869     -0.2214    -0.575183     0.399583 \n  0.886626   0.487408   -0.0977307     -0.985545  -0.636874    -0.439825 \n -1.24394    0.213697    2.74965        1.39201    0.299931     0.392809 ,6670x0 Array{Float64,2},(\n6670x6670 Array{Float64,2}:\n  1.00583       0.00659955   -0.000232427  \u2026  -0.000129257  -0.00562459 \n  0.00659955    0.99784      -0.00403985       0.00181974    0.00691145 \n -0.000232427  -0.00403985    0.987264         0.00058913   -0.000699707\n  0.00186795   -0.00640781   -0.00372219      -0.00483365   -0.00254155 \n -0.000155086  -0.00721501    0.00362883       0.00427952   -0.00316764 \n  0.00400741    0.00115477    0.005091     \u2026   0.00188751   -3.65987e-6 \n  0.00111701    0.00482842   -0.00375641       0.00243399   -0.00247849 \n -0.00131899    0.00639975   -0.00202991       0.00707293   -0.00048186 \n -0.00205238   -0.00240896   -0.00110924       0.00351173    0.00363799 \n -0.00273677    0.00423992    0.000238256     -0.0029461    -0.00210478 \n -0.00412287    0.000297635  -0.000950353  \u2026  -0.000531045  -0.00212246 \n  0.00190203    0.00334083    0.0036709       -0.00140732   -0.00626668 \n  0.000660883  -0.00180829    0.00602955       0.00150954   -0.00254826 \n  \u22ee                                        \u22f1                            \n  0.00602273    0.00232083    0.00200852       1.33451e-5    0.00614137 \n -0.00428016    0.0054185    -0.00370108      -0.00219871    0.00733631 \n  0.00109348   -0.00485292   -0.00610528   \u2026  -0.00125803    0.00421559 \n -0.00845106   -0.00414261   -0.00218104      -0.00141161   -0.00101611 \n -0.00636811   -0.0015077     0.00624753       0.00105766   -7.21938e-5 \n  0.000860393  -0.00394326    0.0053709       -0.0126635    -0.0104067  \n  0.00442858    0.00169958   -0.00202223      -0.00188626   -0.00124884 \n -0.0045805    -0.000261196   0.000203706  \u2026   0.00168027   -0.00460447 \n -0.00405834    0.00466013   -0.00262013       0.00395595   -0.00102754 \n -0.00192981   -0.00174465   -0.000141344      0.00249404   -0.00591688 \n -0.000129257   0.00181974    0.00058913       1.00197       0.00105123 \n -0.00562459    0.00691145   -0.000699707      0.00105123    1.00158    ,\n\n6670x6670 Array{Float64,2}:\n 1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \u2026  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \u2026  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \u2026  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n \u22ee                        \u22ee              \u22f1            \u22ee                      \n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \u2026  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  1.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \u2026  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  1.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  1.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  1.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  1.0))  Before fitting the variance component model, we pre-compute the eigen-decomposition of $2\\Phi_{\\text{GRM}}$, the rotated responses, and the constant part in log-likelihood, and store them as a  TwoVarCompVariateRotate  instance, which is re-used in various variane component estimation procedures.  # pre-compute eigen-decomposition (~50 secs on my laptop)  @ time   cg10kdata_rotated   =   TwoVarCompVariateRotate ( cg10kdata )  fieldnames ( cg10kdata_rotated )    55.887248 seconds (1.06 M allocations: 1.043 GB, 0.28% gc time)\n\n\n\n\n\n4-element Array{Symbol,1}:\n :Yrot    \n :Xrot    \n :eigval  \n :logdetV2", 
            "title": "Pre-processing data for heritability analysis"
        }, 
        {
            "location": "/man/heritability/#save-intermediate-results", 
            "text": "We don't want to re-compute SnpArray and empirical kinship matrices again and again for heritibility analysis.  #using JLD  #@save  cg10k.jld  #whos()                    #210#wsession    280 bytes  JLD.JldWriteSession\n                 #212#wsession    280 bytes  JLD.JldWriteSession\n                          Base  34564 KB     Module\n                       BinDeps    207 KB     Module\n                         Blosc     37 KB     Module\n                    ColorTypes    311 KB     Module\n                        Colors    715 KB     Module\n                        Compat    323 KB     Module\n                         Conda     65 KB     Module\n                          Core   6836 KB     Module\n                    DataArrays    782 KB     Module\n                    DataFrames   1822 KB     Module\n                        Docile    414 KB     Module\n                        FileIO    536 KB     Module\n             FixedPointNumbers     32 KB     Module\n               FixedSizeArrays    157 KB     Module\n                          GZip    771 KB     Module\n                          HDF5   3209 KB     Module\n                        IJulia 2083312 KB     Module\n                IPythonDisplay     36 KB     Module\n                         Ipopt     26 KB     Module\n              IterativeSolvers    485 KB     Module\n                           JLD   1240 KB     Module\n                          JSON    239 KB     Module\n                        KNITRO    274 KB     Module\n                  LaTeXStrings   3108 bytes  Module\n                 LegacyStrings     12 KB     Module\n                    MacroTools    123 KB     Module\n                          Main 2145169 KB     Module\n                  MathProgBase    302 KB     Module\n                      Measures     15 KB     Module\n                        Nettle     58 KB     Module\n                     PlotUtils    441 KB     Module\n                         Plots   2721 KB     Module\n                        PyCall   1016 KB     Module\n                        PyPlot   1252 KB     Module\n                   RecipesBase    174 KB     Module\n                      Reexport   3648 bytes  Module\n                           SHA     50 KB     Module\n                     SnpArrays    439 KB     Module\n             SortingAlgorithms     39 KB     Module\n                     StatsBase    800 KB     Module\n                     StatsFuns    286 KB     Module\n                     URIParser    102 KB     Module\n       VarianceComponentModels    302 KB     Module\n                             Y    677 KB     6670x13 Array{Float64,2}\n                           ZMQ     81 KB     Module\n                             _     77 KB     630860-element BitArray{1}\n                         cg10k 1027303 KB     6670x630860 SnpArrays.SnpArray{2}\n                   cg10k_trait    978 KB     6670\u00d715 DataFrames.DataFrame\n                     cg10kdata 695816 KB     VarianceComponentModels.VarianceCo\u2026\n             cg10kdata_rotated    729 KB     VarianceComponentModels.TwoVarComp\u2026\n                           maf   4928 KB     630860-element Array{Float64,1}\n               missings_by_snp   4928 KB     630860-element Array{Int64,1}\n                        people      8 bytes  Int64\n                          snps      8 bytes  Int64\n                          \u03a6grm 347569 KB     6670x6670 Array{Float64,2}  To load workspace  #using SnpArrays, JLD, DataFrames, VarianceComponentModels, Plots  #pyplot()  #@load  cg10k.jld  #whos()", 
            "title": "Save intermediate results"
        }, 
        {
            "location": "/man/heritability/#heritability-of-single-traits", 
            "text": "We use Fisher scoring algorithm to fit variance component model for each single trait.  # heritability from single trait analysis  hST   =   zeros ( 13 )  # standard errors of estimated heritability  hST_se   =   zeros ( 13 )  # additive genetic effects  \u03c32a   =   zeros ( 13 )  # enviromental effects  \u03c32e   =   zeros ( 13 )  @ time   for   trait   in   1 : 13 \n     println ( names ( cg10k_trait )[ trait   +   2 ]) \n     # form data set for trait j \n     traitj_data   =   TwoVarCompVariateRotate ( cg10kdata_rotated . Yrot [:,   trait ],   cg10kdata_rotated . Xrot ,  \n         cg10kdata_rotated . eigval ,   cg10kdata_rotated . logdetV2 ) \n     # initialize model parameters \n     traitj_model   =   VarianceComponentModel ( traitj_data ) \n     # estimate variance components \n     _ ,   _ ,   _ ,   \u03a3cov ,   _ ,   _   =   mle_fs! ( traitj_model ,   traitj_data ;   solver = : Ipopt ,   verbose = false ) \n     \u03c32a [ trait ]   =   traitj_model . \u03a3 [ 1 ][ 1 ] \n     \u03c32e [ trait ]   =   traitj_model . \u03a3 [ 2 ][ 1 ] \n     @ show   \u03c32a [ trait ],   \u03c32e [ trait ] \n     h ,   hse   =   heritability ( traitj_model . \u03a3 ,   \u03a3cov ) \n     hST [ trait ]   =   h [ 1 ] \n     hST_se [ trait ]   =   hse [ 1 ]  end   Trait1\n(\u03c32a[trait],\u03c32e[trait]) = (0.26104123217397407,0.7356884432614137)\nTrait2\n(\u03c32a[trait],\u03c32e[trait]) = (0.1887414738028781,0.8106899991616237)\nTrait3\n(\u03c32a[trait],\u03c32e[trait]) = (0.31857192765473236,0.6801458862875933)\nTrait4\n(\u03c32a[trait],\u03c32e[trait]) = (0.26556901333953215,0.7303588364945378)\nTrait5\n(\u03c32a[trait],\u03c32e[trait]) = (0.28123321193920503,0.7167989047155238)\nTrait6\n(\u03c32a[trait],\u03c32e[trait]) = (0.2829461149704314,0.716562953439665)\nTrait7\n(\u03c32a[trait],\u03c32e[trait]) = (0.2154385640394616,0.7816211121586024)\nTrait8\n(\u03c32a[trait],\u03c32e[trait]) = (0.19412648732666243,0.8055277649986169)\nTrait9\n(\u03c32a[trait],\u03c32e[trait]) = (0.24789561127297127,0.7504615853619782)\nTrait10\n(\u03c32a[trait],\u03c32e[trait]) = (0.10007455815563934,0.8998152773605567)\nTrait11\n(\u03c32a[trait],\u03c32e[trait]) = (0.1648677816930128,0.8338002257315535)\nTrait12\n(\u03c32a[trait],\u03c32e[trait]) = (0.08298660416199151,0.9158035668415299)\nTrait13\n(\u03c32a[trait],\u03c32e[trait]) = (0.05684248094793726,0.942365338132603)\n  1.277847 seconds (27.43 M allocations: 449.203 MB, 6.96% gc time)  # heritability and standard errors  [ hST ;   hST_se ]   2x13 Array{Float64,2}:\n 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0", 
            "title": "Heritability of single traits"
        }, 
        {
            "location": "/man/heritability/#pairwise-traits", 
            "text": "Joint analysis of multiple traits is subject to intensive research recently. Following code snippet does joint analysis of all pairs of traits, a total of 78 bivariate variane component models.  # additive genetic effects (2x2 psd matrices) from bavariate trait analysis;  \u03a3a   =   Array { Matrix { Float64 }}( 13 ,   13 )  # environmental effects (2x2 psd matrices) from bavariate trait analysis;  \u03a3e   =   Array { Matrix { Float64 }}( 13 ,   13 )  @ time   for   i   in   1 : 13 \n     for   j   in   ( i + 1 ): 13 \n         println ( names ( cg10k_trait )[ i   +   2 ],   names ( cg10k_trait )[ j   +   2 ]) \n         # form data set for (trait1, trait2) \n         traitij_data   =   TwoVarCompVariateRotate ( cg10kdata_rotated . Yrot [:,   [ i ; j ]],   cg10kdata_rotated . Xrot ,  \n             cg10kdata_rotated . eigval ,   cg10kdata_rotated . logdetV2 ) \n         # initialize model parameters \n         traitij_model   =   VarianceComponentModel ( traitij_data ) \n         # estimate variance components \n         mle_fs! ( traitij_model ,   traitij_data ;   solver = : Ipopt ,   verbose = false ) \n         \u03a3a [ i ,   j ]   =   traitij_model . \u03a3 [ 1 ] \n         \u03a3e [ i ,   j ]   =   traitij_model . \u03a3 [ 2 ] \n         @ show   \u03a3a [ i ,   j ],   \u03a3e [ i ,   j ] \n     end  end   Trait1Trait2\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26011943486601186 0.1762158250617613\n 0.1762158250617613 0.18737615484007947],\n\n[0.7365894055260143 0.5838920954615305\n 0.5838920954615305 0.8120331390284958])\nTrait1Trait3\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2615639935561912 -0.013126818537540254\n -0.013126818537540254 0.3190566225472985],\n\n[0.7351802111599617 -0.12112674834388097\n -0.12112674834388097 0.6796789899243143])\nTrait1Trait4\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2608796031577277 0.22261440559416618\n 0.22261440559416618 0.2655808327606219],\n\n[0.735845998165887 0.5994353345883121\n 0.5994353345883121 0.7303474474501164])\nTrait1Trait5\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2607830377026644 -0.14701178378031446\n -0.14701178378031446 0.28187724546298826],\n\n[0.7359373011287004 -0.25458389055860414\n -0.25458389055860414 0.7161761242033678])\nTrait1Trait6\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2607070355193131 -0.12935642592773852\n -0.12935642592773852 0.28318838486253467],\n\n[0.7360128807197885 -0.231361283307625\n -0.231361283307625 0.716329432342681])\nTrait1Trait7\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26030750074784287 -0.1402575370655325\n -0.1402575370655325 0.2150805562425413],\n\n[0.7364055998763509 -0.19780547645064997\n -0.19780547645064997 0.7819851899285041])\nTrait1Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2610345999103056 -0.03352962807192369\n -0.03352962807192369 0.19414307314249296],\n\n[0.7356949687057843 -0.12627246367180997\n -0.12627246367180997 0.8055115370762379])\nTrait1Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2630163159971886 -0.20486492716336502\n -0.20486492716336502 0.24679565235659717],\n\n[0.7337944623091683 -0.30745013667607846\n -0.30745013667607846 0.7515442213452723])\nTrait1Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26089807908065815 -0.0998175618122165\n -0.0998175618122165 0.09702328543308451],\n\n[0.7358279769605037 -0.30360875962256173\n -0.30360875962256173 0.9028534651901434])\nTrait1Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2607397076711653 -0.13898341539579964\n -0.13898341539579964 0.1630626318546552],\n\n[0.735982002778579 -0.35917453215273204\n -0.35917453215273204 0.8355950431900447])\nTrait1Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26306860075660077 -0.14553553813998849\n -0.14553553813998849 0.08051357250838533],\n\n[0.7337809595143813 -0.04169751340916241\n -0.04169751340916241 0.9183594535088752])\nTrait1Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26234367607968223 -0.10889551714052524\n -0.10889551714052524 0.051294038316720095],\n\n[0.7344496461774143 -0.11399558206598119\n -0.11399558206598119 0.9479424008071721])\nTrait2Trait3\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18901532602813093 0.14615743012019033\n 0.14615743012019033 0.32052865893860505],\n\n[0.8104184413504798 0.09749923852684478\n 0.09749923852684478 0.6782713240483099])\nTrait2Trait4\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18839514990246123 0.07521464811372748\n 0.07521464811372748 0.2655584804130378],\n\n[0.811030102837779 0.2204948315759956\n 0.2204948315759956 0.7303691342564813])\nTrait2Trait5\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18871644001954374 -0.01131401822579143\n -0.01131401822579143 0.2812465335267498],\n\n[0.810714524791035 -0.037010470173424806\n -0.037010470173424806 0.7167859986688715])\nTrait2Trait6\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18877375983465075 -0.00310660369976054\n -0.00310660369976054 0.28301251325859456],\n\n[0.8106583657780116 -0.021182656859443615\n -0.021182656859443615 0.7164985874171053])\nTrait2Trait7\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.1883522257140152 -0.02995792853603445\n -0.02995792853603445 0.21518854248912628],\n\n[0.8110719442656862 -0.0013693865327215602\n -0.0013693865327215602 0.7818678818059402])\nTrait2Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18926168900120724 0.03314229844995283\n 0.03314229844995283 0.19466629556483447],\n\n[0.8101822287422975 -0.0326002707144356\n -0.0326002707144356 0.8050045055369501])\nTrait2Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18728489562655376 -0.08541458777339436\n -0.08541458777339436 0.24671880340597185],\n\n[0.8121330456004312 -0.08087908481059602\n -0.08087908481059602 0.7516171286974279])\nTrait2Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18896456296522746 -0.12531880400522133\n -0.12531880400522133 0.10012137187907984],\n\n[0.8104983819177826 -0.2710710218698844\n -0.2710710218698844 0.8998490679641975])\nTrait2Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18776200371864812 -0.1184792033068952\n -0.1184792033068952 0.16627341912779045],\n\n[0.8116528153526548 -0.2955489949517167\n -0.2955489949517167 0.832437271728203])\nTrait2Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.1881906352068438 -0.09053833116422316\n -0.09053833116422316 0.08226341390094308],\n\n[0.8112716597648593 0.04542203421425378\n 0.04542203421425378 0.9165863321461983])\nTrait2Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18826030571129157 -0.07070412373895248\n -0.07070412373895248 0.05472389417033724],\n\n[0.8112166105484152 0.07379770160245963\n 0.07379770160245963 0.944520839730775])\nTrait3Trait4\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.31852039539972626 -0.15433893723696576\n -0.15433893723696576 0.2647540990554418],\n\n[0.6801958865837233 -0.3034399519706689\n -0.3034399519706689 0.7311518515398231])\nTrait3Trait5\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.31896997787053516 0.18435446676116027\n 0.18435446676116027 0.28250017723831466],\n\n[0.6797599597910079 0.3364105248337092\n 0.3364105248337092 0.7155665412298342])\nTrait3Trait6\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.31956636442184144 0.16663988772517022\n 0.16663988772517022 0.28503131823058603],\n\n[0.6791832508344973 0.2976976595437346\n 0.2976976595437346 0.7145358500001604])\nTrait3Trait7\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.3185755051457358 0.16685216000502112\n 0.16685216000502112 0.21523224225933885],\n\n[0.6801424314858139 0.3471388423850005\n 0.3471388423850005 0.781823130995854])\nTrait3Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.3204992348069676 0.05753194037710734\n 0.05753194037710734 0.1972448985403006],\n\n[0.6782830498092438 0.04425974188550198\n 0.04425974188550198 0.802473783267546])\nTrait3Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.3187191200121132 0.13729240537787007\n 0.13729240537787007 0.24697586633850704],\n\n[0.6800039145599909 0.26710543782880997\n 0.26710543782880997 0.7513573840679394])\nTrait3Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.3189152132176088 -0.07863382344383743\n -0.07863382344383743 0.10110317193536325],\n\n[0.6798145588849664 -0.14078871656381564\n -0.14078871656381564 0.8987982713097735])\nTrait3Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.31782233045956043 -0.01798395917118423\n -0.01798395917118423 0.1647429211651019],\n\n[0.6808712744794143 -0.11416573111891\n -0.11416573111891 0.8339228729012033])\nTrait3Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.3208883401712095 0.08452483760012779\n 0.08452483760012779 0.0869867503137195],\n\n[0.6779139477283616 0.034013271781512075\n 0.034013271781512075 0.9118411342566285])\nTrait3Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.3230087933057131 0.11068106827250586\n 0.11068106827250586 0.06117389942330572],\n\n[0.6759011385391952 -0.007296623887800238\n -0.007296623887800238 0.9380722549963341])\nTrait4Trait5\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2656669903604965 -0.21584756082780146\n -0.21584756082780146 0.2829186620095413],\n\n[0.730254403023407 -0.3766752828931733\n -0.3766752828931733 0.7151643527059122])\nTrait4Trait6\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26614305300780366 -0.20063378204208704\n -0.20063378204208704 0.2844419499811047],\n\n[0.7297943215361493 -0.3468040727735064\n -0.3468040727735064 0.7151119490184537])\nTrait4Trait7\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26448980293893115 -0.18275157344067408\n -0.18275157344067408 0.2141168002370858],\n\n[0.7314145610176318 -0.32617199552839854\n -0.32617199552839854 0.7829351279943724])\nTrait4Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2666939542160246 -0.0976354011540246\n -0.0976354011540246 0.19612608720215985],\n\n[0.7292655955853755 -0.1503604822556339\n -0.1503604822556339 0.8035709853977226])\nTrait4Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.27003652025126973 -0.22740698731778375\n -0.22740698731778375 0.24804582217578136],\n\n[0.7260245141082378 -0.415601435658805\n -0.415601435658805 0.7502976667302643])\nTrait4Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26554294182732757 -0.03381072154054875\n -0.03381072154054875 0.09960982635744982],\n\n[0.7303952879672779 -0.22772490049245936\n -0.22772490049245936 0.9002752447796257])\nTrait4Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2656276022060441 -0.09674003324481623\n -0.09674003324481623 0.16327409085920214],\n\n[0.7303019079384457 -0.2726111957438671\n -0.2726111957438671 0.8353713025178962])\nTrait4Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2681636965467903 -0.14161261172764802\n -0.14161261172764802 0.08039677342809182],\n\n[0.7278825933087102 -0.08284654588272211\n -0.08284654588272211 0.918445560967837])\nTrait4Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2661712320522607 -0.0980730872961898\n -0.0980730872961898 0.05401019173275427],\n\n[0.729774933270783 -0.22505950767232102\n -0.22505950767232102 0.9452044744873448])\nTrait5Trait6\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28159165289454874 0.2808983718818519\n 0.2808983718818519 0.28229805042654726],\n\n[0.7164553609549211 0.6603676496785938\n 0.6603676496785938 0.717195064496623])\nTrait5Trait7\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28081437389240205 0.23209986889788878\n 0.23209986889788878 0.21166204275984282],\n\n[0.7172180317169196 0.6743038172587597\n 0.6743038172587597 0.7853426270989494])\nTrait5Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28134012176468737 0.16394787427626617\n 0.16394787427626617 0.19270331039605396],\n\n[0.7167009109174287 0.2210321091237623\n 0.2210321091237623 0.8069220956477239])\nTrait5Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2838778024838298 0.2445317256807396\n 0.2445317256807396 0.24129303734021107],\n\n[0.7142441395397906 0.5084169870307738\n 0.5084169870307738 0.7568942338389598])\nTrait5Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2818130149574279 -0.04621141466301363\n -0.04621141466301363 0.10148069053449221],\n\n[0.7162383352815093 -0.057211134789489596\n -0.057211134789489596 0.8984242888573427])\nTrait5Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2804235419822887 0.02024954557852043\n 0.02024954557852043 0.16400332024748288],\n\n[0.7175856258526226 -0.03524364741892967\n -0.03524364741892967 0.8346493308285122])\nTrait5Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28142706977012344 0.06161306621995005\n 0.06161306621995005 0.08271662802160216],\n\n[0.7166145561768477 0.0529286449372972\n 0.0529286449372972 0.9160739286176958])\nTrait5Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2822915336764342 0.0704220516897222\n 0.0704220516897222 0.05694630996696085],\n\n[0.7157823114676733 0.052837445512878035\n 0.052837445512878035 0.9422684292567837])\nTrait6Trait7\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2829610760516547 0.2206563210574195\n 0.2206563210574195 0.21385609770082856],\n\n[0.7165486719537999 0.5810829183833723\n 0.5810829183833723 0.7831785715716468])\nTrait6Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2829606227312136 0.18407962646923373\n 0.18407962646923373 0.19237902249802602],\n\n[0.7165491133467123 0.43659738936447606\n 0.43659738936447606 0.8072460050938695])\nTrait6Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28497844062058 0.23443573773381146\n 0.23443573773381146 0.2432071080956827],\n\n[0.7146005305265446 0.4768263391945174\n 0.4768263391945174 0.7550279957473227])\nTrait6Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28365475689672454 -0.04354848104335164\n -0.04354848104335164 0.10202532157941907],\n\n[0.7158768651032459 -0.05916812562776467\n -0.05916812562776467 0.8978859540391582])\nTrait6Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2815224136585793 0.027999198497751236\n 0.027999198497751236 0.16342991310056218],\n\n[0.7179464769867658 -0.05241060710545059\n -0.05241060710545059 0.8352130875914755])\nTrait6Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2831143444111233 0.05713989944443876\n 0.05713989944443876 0.08267893130031188],\n\n[0.7164030333442727 0.047919871306752966\n 0.047919871306752966 0.9161120298157116])\nTrait6Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28381996715653646 0.06112120329706666\n 0.06112120329706666 0.057081689702462565],\n\n[0.7157217792749953 0.05326983474671377\n 0.05326983474671377 0.942133354542685])\nTrait7Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.213856863605251 0.08845552117653824\n 0.08845552117653824 0.19237305507049685],\n\n[0.7831777634597645 -0.05683305954905118\n -0.05683305954905118 0.807251867488134])\nTrait7Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2187556960284994 0.21704186383100332\n 0.21704186383100332 0.24414386503619973],\n\n[0.7784327750440135 0.46290096824972443\n 0.46290096824972443 0.7541229287932897])\nTrait7Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2162729624537394 -0.04211457255557115\n -0.04211457255557115 0.10209048393658933],\n\n[0.7808073891161575 -0.08590745272581501\n -0.08590745272581501 0.8978220136457029])\nTrait7Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.21406877656928827 0.020696687538012654\n 0.020696687538012654 0.16347380945331402],\n\n[0.7829608191265603 -0.04814801124367421\n -0.04814801124367421 0.8351704867213441])\nTrait7Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.21493232506988705 0.07578743223300372\n 0.07578743223300372 0.08087309077189964],\n\n[0.7821316768251394 0.03469555448124276\n 0.03469555448124276 0.9179149818424026])\nTrait7Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.21595864338557708 0.07493726652342743\n 0.07493726652342743 0.05459341128356046],\n\n[0.7811387334979083 0.038905793649911785\n 0.038905793649911785 0.9446215738065965])\nTrait8Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.1945549993500238 0.11281615770315953\n 0.11281615770315953 0.24724415191290416],\n\n[0.8051240570336379 0.18477843243741904\n 0.18477843243741904 0.7510982278179416])\nTrait8Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.19444100261213867 -0.015634153642008396\n -0.015634153642008396 0.10042647889284885],\n\n[0.8052215712386805 0.011982589661319697\n 0.011982589661319697 0.8994678453453964])\nTrait8Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.1938531643383019 0.02253246401818133\n 0.02253246401818133 0.1646685438304724],\n\n[0.8057962945716937 -0.02727473686745877\n -0.02727473686745877 0.8339969682996413])\nTrait8Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.19395121849291824 -0.0028760121862793694\n -0.0028760121862793694 0.08285727475931896],\n\n[0.8056997963655848 0.03361278793070539\n 0.03361278793070539 0.9159318672878024])\nTrait8Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.19397976155497032 0.00407866657222457\n 0.00407866657222457 0.0569071232157577],\n\n[0.8056716012394011 0.03788170752125487\n 0.03788170752125487 0.9423010776566965])\nTrait9Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.24729383232785143 -0.0023083632331894533\n -0.0023083632331894533 0.09982638783372684],\n\n[0.7510505981833204 0.07407294365773788\n 0.07407294365773788 0.9000613327603086])\nTrait9Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.24782344372317563 0.031823502985820915\n 0.031823502985820915 0.1648904641109765],\n\n[0.7505321390736757 0.15228537870002187\n 0.15228537870002187 0.83377795534806])\nTrait9Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.25033469514724843 0.08457136153430893\n 0.08457136153430893 0.08875872340836785],\n\n[0.7480909649333196 0.10775632151728669\n 0.10775632151728669 0.910108091343637])\nTrait9Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.24944189418598844 0.09348451303745715\n 0.09348451303745715 0.05793201493993036],\n\n[0.7489745640206875 0.09821909822628513\n 0.09821909822628513 0.9413348855487351])\nTrait10Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.09313966827485977 0.10003371877328632\n 0.10003371877328632 0.16495492788178234],\n\n[0.906703444773408 0.4744266593662351\n 0.4744266593662351 0.8337151519529007])\nTrait10Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.09672471643798064 0.05640434659756219\n 0.05640434659756219 0.07945282707191781],\n\n[0.9031497841220121 0.08532319187443138\n 0.08532319187443138 0.9193343434315169])\nTrait10Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.10098492171842248 -0.027991587712823545\n -0.027991587712823545 0.0578369411328611],\n\n[0.8989368215861225 0.16605077488864645\n 0.16605077488864645 0.9413901799271158])\nTrait11Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.16384057742532637 0.05703178017185482\n 0.05703178017185482 0.07921436807488584],\n\n[0.8348140972542764 0.14559650974208901\n 0.14559650974208901 0.9195521322078624])\nTrait11Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.1648829333720086 -0.0015841372105068166\n -0.0015841372105068166 0.05749684374690435],\n\n[0.8337979488921528 0.20061222835020495\n 0.20061222835020495 0.9417152321030534])\nTrait12Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.08459459620614283 0.06850521854233418\n 0.06850521854233418 0.05547594264883066],\n\n[0.9142140604502765 0.573152408940862\n 0.573152408940862 0.9437349886346289])\n 98.060194 seconds (2.33 G allocations: 35.661 GB, 7.59% gc time)", 
            "title": "Pairwise traits"
        }, 
        {
            "location": "/man/heritability/#3-trait-analysis", 
            "text": "Researchers want to jointly analyze traits 5-7. Our strategy is to try both Fisher scoring and MM algorithm with different starting point, and choose the best local optimum. We first form the data set and run Fisher scoring, which yields a final objective value -1.4700991+04.  traitidx   =   5 : 7  # form data set  trait57_data   =   TwoVarCompVariateRotate ( cg10kdata_rotated . Yrot [:,   traitidx ],   cg10kdata_rotated . Xrot ,  \n     cg10kdata_rotated . eigval ,   cg10kdata_rotated . logdetV2 )  # initialize model parameters  trait57_model   =   VarianceComponentModel ( trait57_data )  # estimate variance components  @ time   mle_fs! ( trait57_model ,   trait57_data ;   solver = : Ipopt ,   verbose = true )  trait57_model   This is Ipopt version 3.12.4, running with linear solver mumps.\nNOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n\nNumber of nonzeros in equality constraint Jacobian...:        0\nNumber of nonzeros in inequality constraint Jacobian.:        0\nNumber of nonzeros in Lagrangian Hessian.............:       78\n\nTotal number of variables............................:       12\n                     variables with only lower bounds:        0\n                variables with lower and upper bounds:        0\n                     variables with only upper bounds:        0\nTotal number of equality constraints.................:        0\nTotal number of inequality constraints...............:        0\n        inequality constraints with only lower bounds:        0\n   inequality constraints with lower and upper bounds:        0\n        inequality constraints with only upper bounds:        0\n\niter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n   0  3.0247512e+04 0.00e+00 1.00e+02   0.0 0.00e+00    -  0.00e+00 0.00e+00   0 \n   5  1.6834796e+04 0.00e+00 4.07e+02 -11.0 3.66e-01    -  1.00e+00 1.00e+00f  1 MaxS\n  10  1.4744497e+04 0.00e+00 1.12e+02 -11.0 2.45e-01    -  1.00e+00 1.00e+00f  1 MaxS\n  15  1.4701497e+04 0.00e+00 1.30e+01 -11.0 1.15e-01  -4.5 1.00e+00 1.00e+00f  1 MaxS\n  20  1.4700992e+04 0.00e+00 6.65e-01 -11.0 1.74e-04  -6.9 1.00e+00 1.00e+00f  1 MaxS\n  25  1.4700991e+04 0.00e+00 2.77e-02 -11.0 7.36e-06  -9.2 1.00e+00 1.00e+00f  1 MaxS\n  30  1.4700991e+04 0.00e+00 1.15e-03 -11.0 3.06e-07 -11.6 1.00e+00 1.00e+00f  1 MaxS\n  35  1.4700991e+04 0.00e+00 4.76e-05 -11.0 1.27e-08 -14.0 1.00e+00 1.00e+00h  1 MaxS\n  40  1.4700991e+04 0.00e+00 1.97e-06 -11.0 5.26e-10 -16.4 1.00e+00 1.00e+00h  1 MaxSA\n  45  1.4700991e+04 0.00e+00 8.17e-08 -11.0 2.18e-11 -18.8 1.00e+00 1.00e+00h  1 MaxSA\niter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n\nNumber of Iterations....: 49\n\n                                   (scaled)                 (unscaled)\nObjective...............:   4.4724330090668150e+02    1.4700991028593420e+04\nDual infeasibility......:   6.4551211049368979e-09    2.1218132783605816e-07\nConstraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\nComplementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00\nOverall NLP error.......:   6.4551211049368979e-09    2.1218132783605816e-07\n\n\nNumber of objective function evaluations             = 50\nNumber of objective gradient evaluations             = 50\nNumber of equality constraint evaluations            = 0\nNumber of inequality constraint evaluations          = 0\nNumber of equality constraint Jacobian evaluations   = 0\nNumber of inequality constraint Jacobian evaluations = 0\nNumber of Lagrangian Hessian evaluations             = 49\nTotal CPU secs in IPOPT (w/o function evaluations)   =      0.022\nTotal CPU secs in NLP function evaluations           =      3.613\n\nEXIT: Optimal Solution Found.\n  3.714206 seconds (93.11 M allocations: 1.410 GB, 7.39% gc time)\n\n\n\n\n\nVarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(0x3 Array{Float64,2},(\n3x3 Array{Float64,2}:\n 0.281163  0.280014  0.232384\n 0.280014  0.284899  0.220285\n 0.232384  0.220285  0.212687,\n\n3x3 Array{Float64,2}:\n 0.716875  0.66125   0.674025\n 0.66125   0.714602  0.581433\n 0.674025  0.581433  0.784324),0x0 Array{Float64,2},Char[],Float64[],-Inf,Inf)  We then run the MM algorithm, starting from the Fisher scoring answer. MM finds an improved solution with objective value 8.955397e+03.  # trait59_model contains the fitted model by Fisher scoring now  @ time   mle_mm! ( trait57_model ,   trait57_data ;   verbose = true )  trait57_model        MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0  -1.470099e+04\n       1  -1.470099e+04\n\n  0.083887 seconds (2.06 M allocations: 35.243 MB, 5.32% gc time)\n\n\n\n\n\nVarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(0x3 Array{Float64,2},(\n3x3 Array{Float64,2}:\n 0.281163  0.280014  0.232384\n 0.280014  0.284899  0.220285\n 0.232384  0.220285  0.212687,\n\n3x3 Array{Float64,2}:\n 0.716875  0.66125   0.674025\n 0.66125   0.714602  0.581433\n 0.674025  0.581433  0.784324),0x0 Array{Float64,2},Char[],Float64[],-Inf,Inf)  Do another run of MM algorithm from default starting point. It leads to a slightly better local optimum -1.470104e+04, slighly worse than the Fisher scoring result. Follow up anlaysis should use the Fisher scoring result.  # default starting point  trait57_model   =   VarianceComponentModel ( trait57_data )  @ time   _ ,   _ ,   _ ,   \u03a3cov ,   =   mle_mm! ( trait57_model ,   trait57_data ;   verbose = true )  trait57_model        MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0  -3.024751e+04\n       1  -2.040338e+04\n       2  -1.656127e+04\n       3  -1.528591e+04\n       4  -1.491049e+04\n       5  -1.480699e+04\n       6  -1.477870e+04\n       7  -1.477026e+04\n       8  -1.476696e+04\n       9  -1.476499e+04\n      10  -1.476339e+04\n      20  -1.475040e+04\n      30  -1.474042e+04\n      40  -1.473272e+04\n      50  -1.472677e+04\n      60  -1.472215e+04\n      70  -1.471852e+04\n      80  -1.471565e+04\n      90  -1.471336e+04\n     100  -1.471152e+04\n     110  -1.471002e+04\n     120  -1.470879e+04\n     130  -1.470778e+04\n     140  -1.470694e+04\n     150  -1.470623e+04\n     160  -1.470563e+04\n     170  -1.470513e+04\n     180  -1.470469e+04\n     190  -1.470432e+04\n     200  -1.470400e+04\n     210  -1.470372e+04\n     220  -1.470347e+04\n     230  -1.470326e+04\n     240  -1.470307e+04\n     250  -1.470290e+04\n     260  -1.470275e+04\n     270  -1.470262e+04\n     280  -1.470250e+04\n     290  -1.470239e+04\n     300  -1.470229e+04\n     310  -1.470220e+04\n     320  -1.470213e+04\n     330  -1.470205e+04\n     340  -1.470199e+04\n     350  -1.470193e+04\n     360  -1.470187e+04\n     370  -1.470182e+04\n     380  -1.470177e+04\n     390  -1.470173e+04\n     400  -1.470169e+04\n     410  -1.470165e+04\n     420  -1.470162e+04\n     430  -1.470159e+04\n     440  -1.470156e+04\n     450  -1.470153e+04\n     460  -1.470150e+04\n     470  -1.470148e+04\n     480  -1.470146e+04\n     490  -1.470143e+04\n     500  -1.470141e+04\n     510  -1.470140e+04\n     520  -1.470138e+04\n     530  -1.470136e+04\n     540  -1.470134e+04\n     550  -1.470133e+04\n     560  -1.470132e+04\n     570  -1.470130e+04\n     580  -1.470129e+04\n     590  -1.470128e+04\n     600  -1.470127e+04\n     610  -1.470125e+04\n     620  -1.470124e+04\n     630  -1.470123e+04\n     640  -1.470122e+04\n     650  -1.470122e+04\n     660  -1.470121e+04\n     670  -1.470120e+04\n     680  -1.470119e+04\n     690  -1.470118e+04\n     700  -1.470118e+04\n     710  -1.470117e+04\n     720  -1.470116e+04\n     730  -1.470116e+04\n     740  -1.470115e+04\n     750  -1.470114e+04\n     760  -1.470114e+04\n     770  -1.470113e+04\n     780  -1.470113e+04\n     790  -1.470112e+04\n     800  -1.470112e+04\n     810  -1.470111e+04\n     820  -1.470111e+04\n     830  -1.470111e+04\n     840  -1.470110e+04\n     850  -1.470110e+04\n     860  -1.470109e+04\n     870  -1.470109e+04\n     880  -1.470109e+04\n     890  -1.470108e+04\n     900  -1.470108e+04\n     910  -1.470108e+04\n     920  -1.470108e+04\n     930  -1.470107e+04\n     940  -1.470107e+04\n     950  -1.470107e+04\n     960  -1.470106e+04\n     970  -1.470106e+04\n     980  -1.470106e+04\n     990  -1.470106e+04\n    1000  -1.470106e+04\n    1010  -1.470105e+04\n    1020  -1.470105e+04\n    1030  -1.470105e+04\n    1040  -1.470105e+04\n    1050  -1.470105e+04\n    1060  -1.470104e+04\n    1070  -1.470104e+04\n    1080  -1.470104e+04\n    1090  -1.470104e+04\n    1100  -1.470104e+04\n    1110  -1.470104e+04\n\n  9.687002 seconds (224.30 M allocations: 5.566 GB, 13.29% gc time)\n\n\n\n\n\nVarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(0x3 Array{Float64,2},(\n3x3 Array{Float64,2}:\n 0.281188  0.280032  0.232439\n 0.280032  0.284979  0.220432\n 0.232439  0.220432  0.212922,\n\n3x3 Array{Float64,2}:\n 0.71685   0.661232  0.67397 \n 0.661232  0.71452   0.581287\n 0.67397   0.581287  0.784092),0x0 Array{Float64,2},Char[],Float64[],-Inf,Inf)  Heritability from 3-variate estimate and their standard errors.  h ,   hse   =   heritability ( trait57_model . \u03a3 ,   \u03a3cov )  [ h ;   hse ]   2x3 Array{Float64,2}:\n 0.281741   0.285122   0.21356  \n 0.0778033  0.0773313  0.0841103", 
            "title": "3-trait analysis"
        }, 
        {
            "location": "/man/heritability/#save-analysis-results", 
            "text": "#using JLD  #@save  copd.jld  #whos()", 
            "title": "Save analysis results"
        }, 
        {
            "location": "/man/api/", 
            "text": "API\n\n\nDocumentation for \nVarianceComponentModels.jl\n's types and methods.\n\n\n\n\nIndex\n\n\n\n\nVarianceComponentModels.TwoVarCompModelRotate\n\n\nVarianceComponentModels.TwoVarCompVariateRotate\n\n\nVarianceComponentModels.VarianceComponentModel\n\n\nVarianceComponentModels.VarianceComponentVariate\n\n\nVarianceComponentModels.fit_mle!\n\n\nVarianceComponentModels.fit_reml!\n\n\nVarianceComponentModels.mle_fs!\n\n\nVarianceComponentModels.mle_mm!\n\n\n\n\n\n\nTypes\n\n\n#\n\n\nVarianceComponentModels.VarianceComponentModel\n \n \nType\n.\n\n\nVarianceComponentModel\n stores the model parameters of a variance component model.\n\n\nFields\n\n\n\n\nB\n: \np x d\n mean parameters\n\n\n\u03a3\n: tuple of \nd x d\n variance component parameters\n\n\nA\n: constraint matrix for \nvec(B)\n\n\nsense\n: vector of characters \n'='\n, \n'\n'\n or \n'\n'\n\n\nb\n: constraint vector for \nvec(B)\n\n\nlb\n: lower bounds for \nvec(B)\n\n\nub\n: upper bounds for \nvec(B)\n\n\n\n\nVarianceComponentModel(B, \u03a3)\nVarianceComponentModel(B, \u03a3, A, sense, b, lb, ub)\n\n\n\n\n\nDefault constructor of \nVarianceComponentModel\n type.\n\n\nVarianceComponentModel(\u03a3)\n\n\n\n\n\nConstruct \nVarianceComponentModel\n from \n\u03a3\n alone. \nB\n is treated empty.\n\n\nVarianceComponentModel(vcobs)\n\n\n\n\n\nConstruct a \nVarianceComponentModel\n instance from a \nVarianceComponentVariate\n instance. \nB\n is initialized to zero; \n\u03a3\n is initialized to a tupe of identity matrices.\n\n\nVarianceComponentModel(vcobsrot)\n\n\n\n\n\nConstruct \nVarianceComponentModel\n instance from a \nTwoVarCompVariateRotate\n instance.\n\n\n#\n\n\nVarianceComponentModels.VarianceComponentVariate\n \n \nType\n.\n\n\nVarianceComponentVariate\n stores the data of a variance component model.\n\n\nFeilds\n\n\n\n\nY\n: \nn x d\n responses\n\n\nX\n: \nn x p\n predictors\n\n\nV\n: tuple of \nn x n\n covariance matrices\n\n\n\n\nVarianceComponentVariate(Y, X, V)\n\n\n\n\n\nDefault constructor of \nVarianceComponentVariate\n type.\n\n\nVarianceComponentVariate(Y, V)\n\n\nConstructor of a \nVarianceComponentVariate\n instance from \nY\n and \nV\n alone. \nX\n is created empty.\n\n\n#\n\n\nVarianceComponentModels.TwoVarCompModelRotate\n \n \nType\n.\n\n\nTwoVarCompModelRotate\n stores the rotated two variance component model.\n\n\nFields\n\n\n\n\nBrot\n: rotated mean parameters \nB * eigvec\n\n\neigval\n: eigenvalues of \neig(\u03a3[1], \u03a3[2])\n\n\neigvec\n: eigenvectors of \neig(\u03a3[1], \u03a3[2])\n\n\nlogdet\u03a32\n: log-determinant of \n\u03a3[2]\n\n\n\n\nTwoVarCompModelRotate(Brot, eigval, eigvec, logdet\u03a32)\n\n\n\n\n\nDefault constructor of \nTwoVarCompModelRotate\n type.\n\n\nTwoVarCompModelRotate(vcmodel)\n\n\n\n\n\nConstructor of a \nTwoVarCompModelRotate\n instance from a \nVarianceComponentModel\n instance.\n\n\n#\n\n\nVarianceComponentModels.TwoVarCompVariateRotate\n \n \nType\n.\n\n\nTwoVarCompVariateRotate\n stores the rotated two variance component data.\n\n\nFields\n\n\n\n\nYrot\n: rotated responses \neigvec * Y\n\n\nXrot\n: rotated covariates \neigvec * X\n\n\neigval\n: eigenvalues of \neig(V[1], V[2])\n\n\neigvec\n: eigenvectors of \neig(V[1], V[2])\n\n\nlogdetV2\n: log-determinant of \nV[2]\n\n\n\n\nTwoVarCompVariateRotate(Yrot, Xrot, eigval, logdetV2)\n\n\n\n\n\nDefault constructor of a \nTwoVarCompVariateRotate\n instance.\n\n\nTwoVarCompVariateRotate(vcobs)\n\n\n\n\n\nConstructor of a \nTwoVarCompVariateRotate\n instance from a \nVarianceComponentVariate\n instance.\n\n\n\n\nFunctions\n\n\n#\n\n\nVarianceComponentModels.mle_fs!\n \n \nFunction\n.\n\n\nmle_fs!(vcmodel, vcdatarot; maxiter, solver, qpsolver, verbose)\n\n\n\n\n\nFind MLE by Fisher scoring algorithm.\n\n\nInput\n\n\n\n\nvcmodel\n: two variane component model \nVarianceComponentModel\n, with  \nvcmodel.B\n and \nvcmodel.\u03a3\n used as starting point\n\n\nvcdatarot\n: rotated two varianec component data \nTwoVarCompVariateRotate\n\n\n\n\nKeyword\n\n\n\n\nmaxiter::Int\n: maximum number of iterations, default is 1000\n\n\nsolver::Symbol\n: backend nonlinear programming solver, \n:Ipopt\n (default) or \n:Knitro\n\n\nqpsolver::Symbol\n: backend quadratic programming solver, \n:Ipopt\n (default) or \n:Gurobi\n or \nMosek\n\n\nverbose::Bool\n: display information\n\n\n\n\nOutput\n\n\n\n\nmaxlogl\n: log-likelihood at solution\n\n\nvcmodel\n: \nVarianceComponentModel\n with updated model parameters\n\n\n\u03a3se=(\u03a3se[1],\u03a3se[2])\n: standard errors of estimate \n\u03a3=(\u03a3[1],\u03a3[2])\n\n\n\u03a3cov\n: covariance matrix of estimate \n\u03a3=(\u03a3[1],\u03a3[2])\n\n\nBse\n: standard errors of estimate \nB\n\n\nBcov\n: covariance of estimate \nB\n\n\n\n\n#\n\n\nVarianceComponentModels.mle_mm!\n \n \nFunction\n.\n\n\nmle_mm!(vcmodel, vcdatarot; maxiter, qpsolver, verbose)\n\n\n\n\n\nFind MLE by minorization-maximization (MM) algorithm.\n\n\nInput\n\n\n\n\nvcmodel\n: two variane component model \nVarianceComponentModel\n, with  \nvcmodel.B\n and \nvcmodel.\u03a3\n used as starting point\n\n\nvcdatarot\n: rotated two varianec component data \nTwoVarCompVariateRotate\n\n\n\n\nKeyword\n\n\n\n\nmaxiter::Int\n: maximum number of iterations, default is 1000\n\n\nqpsolver::Symbol\n: backend quadratic programming solver, \n:Ipopt\n (default) or \n:Gurobi\n or \nMosek\n\n\nverbose::Bool\n: display information\n\n\n\n\nOutput\n\n\n\n\nmaxlogl\n: log-likelihood at solution\n\n\nvcmodel\n: \nVarianceComponentModel\n with updated model parameters\n\n\n\u03a3se=(\u03a3se[1],\u03a3se[2])\n: standard errors of estimate \n\u03a3=(\u03a3[1],\u03a3[2])\n\n\n\u03a3cov\n: covariance matrix of estimate \n\u03a3=(\u03a3[1],\u03a3[2])\n\n\nBse\n: standard errors of estimate \nB\n\n\nBcov\n: covariance of estimate \nB\n\n\n\n\nReference\n\n\n\n\nH. Zhou, L. Hu, J. Zhou, and K. Lange (2015)   MM algorithms for variance components models.   \nhttp://arxiv.org/abs/1509.07426\n\n\n\n\n#\n\n\nVarianceComponentModels.fit_mle!\n \n \nFunction\n.\n\n\nfit_mle!(vcmodel, vcdata; algo)\n\n\n\n\n\nFind MLE of variane component model.\n\n\nInput\n\n\n\n\nvcmodel\n: two variane component model \nVarianceComponentModel\n, with  \nvcmodel.B\n and \nvcmodel.\u03a3\n used as starting point\n\n\nvcdata\n: two varianec component data \nVarianceComponentVariate\n\n\n\n\nKeyword\n\n\n\n\nalgo::Symbol\n: algorithm, \n:FS\n (Fisher scoring) for \n:MM\n (minorization-maximization algorithm)\n\n\n\n\nOutput\n\n\n\n\nmaxlogl\n: log-likelihood at solution\n\n\nvcmodel\n: \nVarianceComponentModel\n with updated model parameters\n\n\n\u03a3se=(\u03a3se[1],\u03a3se[2])\n: standard errors of estimate \n\u03a3=(\u03a3[1],\u03a3[2])\n\n\n\u03a3cov\n: covariance matrix of estimate \n\u03a3=(\u03a3[1],\u03a3[2])\n\n\nBse\n: standard errors of estimate \nB\n\n\nBcov\n: covariance of estimate \nB\n\n\n\n\n#\n\n\nVarianceComponentModels.fit_reml!\n \n \nFunction\n.\n\n\nfit_reml!(vcmodel, vcdata; algo)\n\n\n\n\n\nFind restricted MLE (REML) of variane component model.\n\n\nInput\n\n\n\n\nvcmodel\n: two variane component model \nVarianceComponentModel\n, with  \nvcmodel.B\n and \nvcmodel.\u03a3\n used as starting point\n\n\nvcdata\n: two varianec component data \nVarianceComponentVariate\n\n\n\n\nKeyword\n\n\n\n\nalgo::Symbol\n: algorithm, \n:FS\n (Fisher scoring) for \n:MM\n (minorization-maximization algorithm)\n\n\n\n\nOutput\n\n\n\n\nmaxlogl\n: log-likelihood at solution\n\n\nvcmodel\n: \nVarianceComponentModel\n with updated model parameters\n\n\n\u03a3se=(\u03a3se[1],\u03a3se[2])\n: standard errors of estimate \n\u03a3=(\u03a3[1],\u03a3[2])\n\n\n\u03a3cov\n: covariance matrix of estimate \n\u03a3=(\u03a3[1],\u03a3[2])\n\n\nBse\n: standard errors of estimate \nB\n\n\nBcov\n: covariance of estimate \nB", 
            "title": "API"
        }, 
        {
            "location": "/man/api/#api", 
            "text": "Documentation for  VarianceComponentModels.jl 's types and methods.", 
            "title": "API"
        }, 
        {
            "location": "/man/api/#index", 
            "text": "VarianceComponentModels.TwoVarCompModelRotate  VarianceComponentModels.TwoVarCompVariateRotate  VarianceComponentModels.VarianceComponentModel  VarianceComponentModels.VarianceComponentVariate  VarianceComponentModels.fit_mle!  VarianceComponentModels.fit_reml!  VarianceComponentModels.mle_fs!  VarianceComponentModels.mle_mm!", 
            "title": "Index"
        }, 
        {
            "location": "/man/api/#types", 
            "text": "#  VarianceComponentModels.VarianceComponentModel     Type .  VarianceComponentModel  stores the model parameters of a variance component model.  Fields   B :  p x d  mean parameters  \u03a3 : tuple of  d x d  variance component parameters  A : constraint matrix for  vec(B)  sense : vector of characters  '=' ,  ' '  or  ' '  b : constraint vector for  vec(B)  lb : lower bounds for  vec(B)  ub : upper bounds for  vec(B)   VarianceComponentModel(B, \u03a3)\nVarianceComponentModel(B, \u03a3, A, sense, b, lb, ub)  Default constructor of  VarianceComponentModel  type.  VarianceComponentModel(\u03a3)  Construct  VarianceComponentModel  from  \u03a3  alone.  B  is treated empty.  VarianceComponentModel(vcobs)  Construct a  VarianceComponentModel  instance from a  VarianceComponentVariate  instance.  B  is initialized to zero;  \u03a3  is initialized to a tupe of identity matrices.  VarianceComponentModel(vcobsrot)  Construct  VarianceComponentModel  instance from a  TwoVarCompVariateRotate  instance.  #  VarianceComponentModels.VarianceComponentVariate     Type .  VarianceComponentVariate  stores the data of a variance component model.  Feilds   Y :  n x d  responses  X :  n x p  predictors  V : tuple of  n x n  covariance matrices   VarianceComponentVariate(Y, X, V)  Default constructor of  VarianceComponentVariate  type.  VarianceComponentVariate(Y, V)  Constructor of a  VarianceComponentVariate  instance from  Y  and  V  alone.  X  is created empty.  #  VarianceComponentModels.TwoVarCompModelRotate     Type .  TwoVarCompModelRotate  stores the rotated two variance component model.  Fields   Brot : rotated mean parameters  B * eigvec  eigval : eigenvalues of  eig(\u03a3[1], \u03a3[2])  eigvec : eigenvectors of  eig(\u03a3[1], \u03a3[2])  logdet\u03a32 : log-determinant of  \u03a3[2]   TwoVarCompModelRotate(Brot, eigval, eigvec, logdet\u03a32)  Default constructor of  TwoVarCompModelRotate  type.  TwoVarCompModelRotate(vcmodel)  Constructor of a  TwoVarCompModelRotate  instance from a  VarianceComponentModel  instance.  #  VarianceComponentModels.TwoVarCompVariateRotate     Type .  TwoVarCompVariateRotate  stores the rotated two variance component data.  Fields   Yrot : rotated responses  eigvec * Y  Xrot : rotated covariates  eigvec * X  eigval : eigenvalues of  eig(V[1], V[2])  eigvec : eigenvectors of  eig(V[1], V[2])  logdetV2 : log-determinant of  V[2]   TwoVarCompVariateRotate(Yrot, Xrot, eigval, logdetV2)  Default constructor of a  TwoVarCompVariateRotate  instance.  TwoVarCompVariateRotate(vcobs)  Constructor of a  TwoVarCompVariateRotate  instance from a  VarianceComponentVariate  instance.", 
            "title": "Types"
        }, 
        {
            "location": "/man/api/#functions", 
            "text": "#  VarianceComponentModels.mle_fs!     Function .  mle_fs!(vcmodel, vcdatarot; maxiter, solver, qpsolver, verbose)  Find MLE by Fisher scoring algorithm.  Input   vcmodel : two variane component model  VarianceComponentModel , with   vcmodel.B  and  vcmodel.\u03a3  used as starting point  vcdatarot : rotated two varianec component data  TwoVarCompVariateRotate   Keyword   maxiter::Int : maximum number of iterations, default is 1000  solver::Symbol : backend nonlinear programming solver,  :Ipopt  (default) or  :Knitro  qpsolver::Symbol : backend quadratic programming solver,  :Ipopt  (default) or  :Gurobi  or  Mosek  verbose::Bool : display information   Output   maxlogl : log-likelihood at solution  vcmodel :  VarianceComponentModel  with updated model parameters  \u03a3se=(\u03a3se[1],\u03a3se[2]) : standard errors of estimate  \u03a3=(\u03a3[1],\u03a3[2])  \u03a3cov : covariance matrix of estimate  \u03a3=(\u03a3[1],\u03a3[2])  Bse : standard errors of estimate  B  Bcov : covariance of estimate  B   #  VarianceComponentModels.mle_mm!     Function .  mle_mm!(vcmodel, vcdatarot; maxiter, qpsolver, verbose)  Find MLE by minorization-maximization (MM) algorithm.  Input   vcmodel : two variane component model  VarianceComponentModel , with   vcmodel.B  and  vcmodel.\u03a3  used as starting point  vcdatarot : rotated two varianec component data  TwoVarCompVariateRotate   Keyword   maxiter::Int : maximum number of iterations, default is 1000  qpsolver::Symbol : backend quadratic programming solver,  :Ipopt  (default) or  :Gurobi  or  Mosek  verbose::Bool : display information   Output   maxlogl : log-likelihood at solution  vcmodel :  VarianceComponentModel  with updated model parameters  \u03a3se=(\u03a3se[1],\u03a3se[2]) : standard errors of estimate  \u03a3=(\u03a3[1],\u03a3[2])  \u03a3cov : covariance matrix of estimate  \u03a3=(\u03a3[1],\u03a3[2])  Bse : standard errors of estimate  B  Bcov : covariance of estimate  B   Reference   H. Zhou, L. Hu, J. Zhou, and K. Lange (2015)   MM algorithms for variance components models.    http://arxiv.org/abs/1509.07426   #  VarianceComponentModels.fit_mle!     Function .  fit_mle!(vcmodel, vcdata; algo)  Find MLE of variane component model.  Input   vcmodel : two variane component model  VarianceComponentModel , with   vcmodel.B  and  vcmodel.\u03a3  used as starting point  vcdata : two varianec component data  VarianceComponentVariate   Keyword   algo::Symbol : algorithm,  :FS  (Fisher scoring) for  :MM  (minorization-maximization algorithm)   Output   maxlogl : log-likelihood at solution  vcmodel :  VarianceComponentModel  with updated model parameters  \u03a3se=(\u03a3se[1],\u03a3se[2]) : standard errors of estimate  \u03a3=(\u03a3[1],\u03a3[2])  \u03a3cov : covariance matrix of estimate  \u03a3=(\u03a3[1],\u03a3[2])  Bse : standard errors of estimate  B  Bcov : covariance of estimate  B   #  VarianceComponentModels.fit_reml!     Function .  fit_reml!(vcmodel, vcdata; algo)  Find restricted MLE (REML) of variane component model.  Input   vcmodel : two variane component model  VarianceComponentModel , with   vcmodel.B  and  vcmodel.\u03a3  used as starting point  vcdata : two varianec component data  VarianceComponentVariate   Keyword   algo::Symbol : algorithm,  :FS  (Fisher scoring) for  :MM  (minorization-maximization algorithm)   Output   maxlogl : log-likelihood at solution  vcmodel :  VarianceComponentModel  with updated model parameters  \u03a3se=(\u03a3se[1],\u03a3se[2]) : standard errors of estimate  \u03a3=(\u03a3[1],\u03a3[2])  \u03a3cov : covariance matrix of estimate  \u03a3=(\u03a3[1],\u03a3[2])  Bse : standard errors of estimate  B  Bcov : covariance of estimate  B", 
            "title": "Functions"
        }
    ]
}