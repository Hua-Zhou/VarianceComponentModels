{
    "docs": [
        {
            "location": "/", 
            "text": "VarianceComponentModels.jl\n\n\nUtilities for fitting and testing variance component models\n\n\nVarianceComponentModels.jl implements computation routines for fitting and testing variance component model of form\n\n\n$\\text{vec}(Y) \\sim \\text{Nomral}(X B, \\Sigma_1 \\otimes V_1 + \\cdots + \\Sigma_m \\otimes V_m),$\n\n\nwhere $\\otimes$ is the \nKronecker product\n.\n\n\nIn this model, \ndata\n is represented by  \n\n\n\n\nY\n: \nn x d\n response matrix  \n\n\nX\n: \nn x p\n covariate matrix  \n\n\nV=(V1,...,Vm)\n: a tuple \nm\n \nn x n\n covariance matrices  \n\n\n\n\nand \nparameters\n are  \n\n\n\n\nB\n: \np x d\n mean parameter matrix  \n\n\n\u03a3=(\u03a31,...,\u03a3m)\n: a tuple of \nm\n \nd x d\n variance components  \n\n\n\n\n\n\nPackage Features\n\n\n\n\nMaximum likelihood estimation (MLE) and restricted maximum likelihood estimation (REML) of mean parameters \nB\n and variance component parameters \n\u03a3\n   \n\n\nAllow constrains in the mean parameters \nB\n  \n\n\nChoice of optimization algorithms: \nFisher scoring\n and \nminorization-maximization algorithm\n  \n\n\nHeritability\n analysis in genetics  \n\n\n\n\n\n\nInstallation\n\n\nUse the Julia package manager to install VarianceComponentModels.jl.\n\n\nPkg\n.\nclone\n(\ngit@github.com:OpenMendel/VarianceComponentModels.jl.git\n)\n\n\n\n\n\n\nThis package supports Julia \n0.4\n.\n\n\n\n\nManual Outline\n\n\n\n\nMLE and REML\n\n\nDemo data\n\n\nMaximum likelihood estimation (MLE)\n\n\nRestricted maximum likelihood estimation (REML)\n\n\nOptimization algorithms\n\n\nStarting point\n\n\nConstrained estimation of \nB\n\n\n\n\n\n\nHeritability Analysis\n\n\nRead in binary SNP data\n\n\nSummary statistics of SNP data\n\n\nEmpirical kinship matrix\n\n\nPhenotypes\n\n\nPre-processing data for heritability analysis\n\n\nSave intermediate results\n\n\nHeritability of single traits\n\n\nPairwise traits\n\n\n5-trait analysis\n\n\n13-trait analysis\n\n\nSave analysis results", 
            "title": "Home"
        }, 
        {
            "location": "/#variancecomponentmodelsjl", 
            "text": "Utilities for fitting and testing variance component models  VarianceComponentModels.jl implements computation routines for fitting and testing variance component model of form  $\\text{vec}(Y) \\sim \\text{Nomral}(X B, \\Sigma_1 \\otimes V_1 + \\cdots + \\Sigma_m \\otimes V_m),$  where $\\otimes$ is the  Kronecker product .  In this model,  data  is represented by     Y :  n x d  response matrix    X :  n x p  covariate matrix    V=(V1,...,Vm) : a tuple  m   n x n  covariance matrices     and  parameters  are     B :  p x d  mean parameter matrix    \u03a3=(\u03a31,...,\u03a3m) : a tuple of  m   d x d  variance components", 
            "title": "VarianceComponentModels.jl"
        }, 
        {
            "location": "/#package-features", 
            "text": "Maximum likelihood estimation (MLE) and restricted maximum likelihood estimation (REML) of mean parameters  B  and variance component parameters  \u03a3      Allow constrains in the mean parameters  B     Choice of optimization algorithms:  Fisher scoring  and  minorization-maximization algorithm     Heritability  analysis in genetics", 
            "title": "Package Features"
        }, 
        {
            "location": "/#installation", 
            "text": "Use the Julia package manager to install VarianceComponentModels.jl.  Pkg . clone ( git@github.com:OpenMendel/VarianceComponentModels.jl.git )   This package supports Julia  0.4 .", 
            "title": "Installation"
        }, 
        {
            "location": "/#manual-outline", 
            "text": "MLE and REML  Demo data  Maximum likelihood estimation (MLE)  Restricted maximum likelihood estimation (REML)  Optimization algorithms  Starting point  Constrained estimation of  B    Heritability Analysis  Read in binary SNP data  Summary statistics of SNP data  Empirical kinship matrix  Phenotypes  Pre-processing data for heritability analysis  Save intermediate results  Heritability of single traits  Pairwise traits  5-trait analysis  13-trait analysis  Save analysis results", 
            "title": "Manual Outline"
        }, 
        {
            "location": "/man/mle_reml/", 
            "text": "MLE and REML\n\n\n\n\nDemo data\n\n\nFor demonstration, we generate a random data set.\n\n\n# generate data from a d-variate response variane component model\n\n\nsrand\n(\n123\n)\n\n\nn\n \n=\n \n1000\n   \n# no. observations\n\n\nd\n \n=\n \n2\n      \n# dimension of responses\n\n\nm\n \n=\n \n2\n      \n# no. variance components\n\n\np\n \n=\n \n2\n      \n# no. covariates\n\n\n# n-by-p design matrix\n\n\nX\n \n=\n \nrandn\n(\nn\n,\n \np\n)\n\n\n# p-by-d mean component regression coefficient\n\n\nB\n \n=\n \nones\n(\np\n,\n \nd\n)\n  \n\n# a tuple of m covariance matrices\n\n\nV\n \n=\n \nntuple\n(\nx\n \n-\n \nzeros\n(\nn\n,\n \nn\n),\n \nm\n)\n \n\nfor\n \ni\n \n=\n \n1\n:\nm\n-\n1\n\n  \nVi\n \n=\n \nrandn\n(\nn\n,\n \n50\n)\n\n  \ncopy!\n(\nV\n[\ni\n],\n \nVi\n \n*\n \nVi\n)\n\n\nend\n\n\ncopy!\n(\nV\n[\nm\n],\n \neye\n(\nn\n))\n \n# last covarianec matrix is idendity\n\n\n# a tuple of m d-by-d variance component parameters\n\n\n\u03a3\n \n=\n \nntuple\n(\nx\n \n-\n \nzeros\n(\nd\n,\n \nd\n),\n \nm\n)\n \n\nfor\n \ni\n \nin\n \n1\n:\nm\n\n  \n\u03a3i\n \n=\n \nrandn\n(\nd\n,\n \nd\n)\n\n  \ncopy!\n(\n\u03a3\n[\ni\n],\n \n\u03a3i\n \n*\n \n\u03a3i\n)\n\n\nend\n\n\n# form overall nd-by-nd covariance matrix \u03a9\n\n\n\u03a9\n \n=\n \nzeros\n(\nn\n \n*\n \nd\n,\n \nn\n \n*\n \nd\n)\n\n\nfor\n \ni\n \n=\n \n1\n:\nm\n\n  \n\u03a9\n \n+=\n \nkron\n(\n\u03a3\n[\ni\n],\n \nV\n[\ni\n])\n\n\nend\n\n\n\u03a9chol\n \n=\n \ncholfact\n(\n\u03a9\n)\n\n\n# n-by-d responses\n\n\nY\n \n=\n \nX\n \n*\n \nB\n \n+\n \nreshape\n(\n\u03a9chol\n[:\nL\n]\n \n*\n \nrandn\n(\nn\n*\nd\n),\n \nn\n,\n \nd\n);\n\n\n\n\n\n\n\n\nMaximum likelihood estimation (MLE)\n\n\nTo find the MLE of parameters $(B,\\Sigma_1,\\ldots,\\Sigma_m)$, we take 3 steps:   \nStep 1 (Construct data)\n. Construct an instance of \nVarianceComponentVariate\n, which consists of the responses $Y$, the covariate matrix $X$, and a tuple of covariance matrices $V$. The last covariance matrix must be positive definite and usually is the identity matrix. In the absence of covariates $X$, we can simply initialize by \nvcdata = VarianceComponentVariate(Y, V)\n.\n\n\nusing\n \nVarianceComponentModels\n\n\nvcdata\n \n=\n \nVarianceComponentVariate\n(\nY\n,\n \nX\n,\n \nV\n)\n\n\nfieldnames\n(\nvcdata\n)\n\n\n\n\n\n\n3-element Array{Symbol,1}:\n :Y\n :X\n :V\n\n\n\n\n\nStep 2 (Construct a model)\n. Construct an instance of \nVarianceComponentModel\n. The fields \nB\n and \n\u03a3\n are mean and variane component parameters respectively. When constructed from a \nVarianceComponentVariate\n instance, the mean parameters $B$ are initialized to be zero and the tuple of variance component parameters $\\Sigma$ to be \n(eye(d),...,eye(d))\n.\n\n\nThe remaining fields \nA\n, \nsense\n, \nb\n, \nlb\n, \nub\n specify (optional) constraints on the mean parameters \nB\n:\n\n\n$A * \\text{vec}(B) =\\ge\\le b$\n\n\n$lb \\le \\text{vec}(B) \\le ub$\n\n\nA\n is an \nm x pd\n constraint matrix, \nsense\n is a \nm\n vector of charaters taking values \n, \n=\n, or \n, and \nlb\n and \nub\n are the lower and upper bounds for \nvec(B)\n. By default, \nA\n, \nsense\n, \nb\n are empty, \nlb\n is \n-Inf\n, and \nub\n is \nInf\n. If any constraits are non-trivial, final estimates of \nB\n are enforced to satisfy them.\n\n\nvcmodel\n \n=\n \nVarianceComponentModel\n(\nvcdata\n)\n\n\nfieldnames\n(\nvcmodel\n)\n\n\n\n\n\n\n7-element Array{Symbol,1}:\n :B    \n :\u03a3    \n :A    \n :sense\n :b    \n :lb   \n :ub\n\n\n\n\n\nvcmodel\n\n\n\n\n\n\nVarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(2x2 Array{Float64,2}:\n 0.0  0.0\n 0.0  0.0,(\n2x2 Array{Float64,2}:\n 1.0  0.0\n 0.0  1.0,\n\n2x2 Array{Float64,2}:\n 1.0  0.0\n 0.0  1.0),0x4 Array{Float64,2},Char[],Float64[],-Inf,Inf)\n\n\n\n\n\nWhen a better initial guess is available, we can initialize by calling \nvcmodel=VarianceComponentModel(B0, \u03a30)\n directly.\n\n\nStep 3 (Fit model)\n. Call optmization routine \nfit_mle!\n. The keywork \nalgo\n dictates the optimization algorithm: \n:MM\n (minorization-maximization algorithm) or \n:FS\n (Fisher scoring algorithm).\n\n\nvcmodel_mle\n \n=\n \ndeepcopy\n(\nvcmodel\n)\n\n\n@\ntime\n \nlogl\n,\n \nvcmodel_mle\n,\n \n\u03a3se\n,\n \n\u03a3cov\n,\n \nBse\n,\n \nBcov\n \n=\n \nfit_mle!\n(\nvcmodel_mle\n,\n \nvcdata\n;\n \nalgo\n \n=\n \n:\nMM\n);\n\n\n\n\n\n\n     MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0  -7.348297e+03\n       1  -4.102367e+03\n       2  -3.745567e+03\n       3  -3.652392e+03\n       4  -3.627744e+03\n       5  -3.621170e+03\n       6  -3.619381e+03\n       7  -3.618878e+03\n       8  -3.618730e+03\n       9  -3.618684e+03\n      10  -3.618670e+03\n\n  6.187559 seconds (11.40 M allocations: 481.014 MB, 1.48% gc time)\n\n\n\n\n\nThe output of \nfit_mle!\n contains  \n\n\n\n\nfinal log-likelihood  \n\n\n\n\nlogl\n\n\n\n\n\n\n-3618.661776037447\n\n\n\n\n\n\n\nfitted model\n\n\n\n\nfieldnames\n(\nvcmodel_mle\n)\n\n\n\n\n\n\n7-element Array{Symbol,1}:\n :B    \n :\u03a3    \n :A    \n :sense\n :b    \n :lb   \n :ub\n\n\n\n\n\nvcmodel_mle\n\n\n\n\n\n\nVarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(2x2 Array{Float64,2}:\n 1.14929   1.00139\n 0.924768  1.02485,(\n2x2 Array{Float64,2}:\n  0.302279  -0.478398\n -0.478398   0.803237,\n\n2x2 Array{Float64,2}:\n  5.86133   -0.586939\n -0.586939   0.586382),0x4 Array{Float64,2},Char[],Float64[],-Inf,Inf)\n\n\n\n\n\n\n\nstandard errors of the estimated varianec component parameters\n\n\n\n\n\u03a3se\n\n\n\n\n\n\n(\n2x2 Array{Float64,2}:\n 0.06167    0.0995727\n 0.0995727  0.16077  ,\n\n2x2 Array{Float64,2}:\n 0.268915  0.085063\n 0.085063  0.026905)\n\n\n\n\n\n\n\ncovariance matrix of the variance component parameters estimates\n\n\n\n\n\u03a3cov\n\n\n\n\n\n\n8x8 Array{Float64,2}:\n  0.00380319  -0.00590812  -0.00590812  \u2026   7.45979e-6   -7.52483e-7 \n -0.00590812   0.00991472   0.00917805     -7.52483e-7    7.55745e-7 \n -0.00590812   0.00917805   0.00991472     -7.49213e-6    7.55745e-7 \n  0.00917805  -0.0154021   -0.0154021       7.55745e-7   -7.59023e-7 \n -7.39532e-5   7.45979e-6   7.45979e-6     -0.00724213    0.000725236\n  7.45979e-6  -7.49213e-6  -7.52483e-7  \u2026   0.000725236  -0.000724568\n  7.45979e-6  -7.52483e-7  -7.49213e-6      0.00723572   -0.000724568\n -7.52483e-7   7.55745e-7   7.55745e-7     -0.000724568   0.000723881\n\n\n\n\n\n\n\nstandard errors of the estimated mean parameters\n\n\n\n\nBse\n\n\n\n\n\n\n2x2 Array{Float64,2}:\n 0.0760538  0.0251806\n 0.0769259  0.0252831\n\n\n\n\n\n\n\ncovariance matrix of the mean parameter estimates\n\n\n\n\nBcov\n\n\n\n\n\n\n4x4 Array{Float64,2}:\n  0.00578418  -6.1406e-5    -0.00061133    3.61347e-6 \n -6.1406e-5    0.00591759    3.61347e-6   -0.000619951\n -0.00061133   3.61347e-6    0.000634064  -1.76949e-6 \n  3.61347e-6  -0.000619951  -1.76949e-6    0.000639237\n\n\n\n\n\n\n\nRestricted maximum likelihood estimation (REML)\n\n\nREML (restricted maximum likelihood estimation)\n is a popular alternative to the MLE. To find the REML of a variane component model, we replace the above step 3 by  \n\n\nStep 3\n. Call optmization routine \nfit_reml!\n.\n\n\nvcmodel_reml\n \n=\n \ndeepcopy\n(\nvcmodel\n)\n\n\n@\ntime\n \nlogl\n,\n \nvcmodel_reml\n,\n \n\u03a3se\n,\n \n\u03a3cov\n,\n \nBse\n,\n \nBcov\n \n=\n \nfit_reml!\n(\nvcmodel_reml\n,\n \nvcdata\n;\n \nalgo\n \n=\n \n:\nMM\n);\n\n\n\n\n\n\n     MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0  -5.297304e+03\n       1  -3.954293e+03\n       2  -3.715870e+03\n       3  -3.663101e+03\n       4  -3.650121e+03\n       5  -3.646663e+03\n       6  -3.645672e+03\n       7  -3.645367e+03\n       8  -3.645268e+03\n       9  -3.645233e+03\n      10  -3.645221e+03\n\n  0.462098 seconds (730.53 k allocations: 42.706 MB, 0.77% gc time)\n\n\n\n\n\nThe output of \nfit_reml!\n contains\n\n\n\n\nthe final log-likelihood at REML estimate\n\n\n\n\nlogl\n\n\n\n\n\n\n-3622.050155483128\n\n\n\n\n\n\n\nREML estimates\n\n\n\n\nfieldnames\n(\nvcmodel_reml\n)\n\n\n\n\n\n\n7-element Array{Symbol,1}:\n :B    \n :\u03a3    \n :A    \n :sense\n :b    \n :lb   \n :ub\n\n\n\n\n\nvcmodel_reml\n\n\n\n\n\n\nVarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(2x2 Array{Float64,2}:\n 1.08201  1.05525\n 0.90694  1.00679,(\n2x2 Array{Float64,2}:\n  0.301641  -0.477617\n -0.477617   0.802105,\n\n2x2 Array{Float64,2}:\n  5.88057   -0.610115\n -0.610115   0.61958 ),0x4 Array{Float64,2},Char[],Float64[],-Inf,Inf)\n\n\n\n\n\n\n\nstandard errors of the estimated varianec component parameters\n\n\n\n\n\u03a3se\n\n\n\n\n\n\n(\n2x2 Array{Float64,2}:\n 0.0615463  0.0994049\n 0.0994049  0.160551 ,\n\n2x2 Array{Float64,2}:\n 0.269798   0.0875812\n 0.0875812  0.0284283)\n\n\n\n\n\n\n\ncovariance matrix of the variance component parameters estimates\n\n\n\n\n\u03a3cov\n\n\n\n\n\n\n8x8 Array{Float64,2}:\n  0.00378795  -0.00588696  -0.00588696  \u2026   7.78026e-6   -8.13244e-7 \n -0.00588696   0.00988133   0.00914906     -8.13244e-7    8.30149e-7 \n -0.00588696   0.00914906   0.00988133     -7.94198e-6    8.30149e-7 \n  0.00914906  -0.0153568   -0.0153568       8.30149e-7   -8.47406e-7 \n -7.44333e-5   7.78026e-6   7.78026e-6     -0.00755281    0.000783641\n  7.78026e-6  -7.94198e-6  -8.13244e-7  \u2026   0.000783641  -0.00079582 \n  7.78026e-6  -8.13244e-7  -7.94198e-6      0.00767047   -0.00079582 \n -8.13244e-7   8.30149e-7   8.30149e-7     -0.00079582    0.000808168\n\n\n\n\n\n\n\nstandard errors of the estimated mean parameters\n\n\n\n\nBse\n\n\n\n\n\n\n2x2 Array{Float64,2}:\n 0.0615457  0.0994049\n 0.0994049  0.160551\n\n\n\n\n\n\n\ncovariance matrix of the mean parameter estimates\n\n\n\n\nBcov\n\n\n\n\n\n\n4x4 Array{Float64,2}:\n  0.00378788  -0.00588695  -0.00588695   0.00914906\n -0.00588695   0.00988132   0.00914906  -0.0153568 \n -0.00588695   0.00914906   0.00988132  -0.0153568 \n  0.00914906  -0.0153568   -0.0153568    0.0257766\n\n\n\n\n\n\n\nOptimization algorithms\n\n\nFinding the MLE or REML of variance component models is a non-trivial nonlinear optimization problem. The main complications are the non-convexity of objective function and the positive semi-definiteness constraint of variane component parameters $\\Sigma_1,\\ldots,\\Sigma_m$. Here are some tips for efficient computation. \n\n\nIn general the optimization algorithm needs to invert the $nd$ by $nd$ overall covariance matrix $\\Omega = \\Sigma_1 \\otimes V_1 + \\cdots + \\Sigma_m \\otimes V_m$ in each iteration. Inverting a matrix is an expensive operation with $O(n^3 d^3)$ floating operations. When there are only \ntwo\n varianec components ($m=2$), this tedious task can be avoided by taking one (generalized) eigendecomposion of $(V_1, V_2)$ and rotating data $(Y, X)$ by the eigen-vectors. \n\n\nvcdatarot\n \n=\n \nTwoVarCompVariateRotate\n(\nvcdata\n)\n\n\nfieldnames\n(\nvcdatarot\n)\n\n\n\n\n\n\n4-element Array{Symbol,1}:\n :Yrot    \n :Xrot    \n :eigval  \n :logdetV2\n\n\n\n\n\nTwo optimization algorithms are implemented: Fisher scoring (\nmle_fs!\n) and the \nminorization-maximization (MM) algorithm\n (\nmle_mm!\n). Both take the rotated data as input. These two functions give finer control of the optimization algorithms. Generally speaking, MM algorithm is more stable while Fisher scoring (if it converges) yields more accurate answer.\n\n\nvcmodel_mm\n \n=\n \ndeepcopy\n(\nvcmodel\n)\n\n\n@\ntime\n \nmle_mm!\n(\nvcmodel_mm\n,\n \nvcdatarot\n;\n \nmaxiter\n=\n10000\n,\n \nfuntol\n=\n1e-8\n,\n \nverbose\n \n=\n \ntrue\n);\n\n\n\n\n\n\n     MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0  -7.348297e+03\n       1  -4.102367e+03\n       2  -3.745567e+03\n       3  -3.652392e+03\n       4  -3.627744e+03\n       5  -3.621170e+03\n       6  -3.619381e+03\n       7  -3.618878e+03\n       8  -3.618730e+03\n       9  -3.618684e+03\n      10  -3.618670e+03\n\n  0.166114 seconds (750.53 k allocations: 28.531 MB, 2.44% gc time)\n\n\n\n\n\n# MM estimates\n\n\nvcmodel_mm\n.\nB\n\n\n\n\n\n\n2x2 Array{Float64,2}:\n 1.14929   1.00139\n 0.924768  1.02485\n\n\n\n\n\n# MM estimates\n\n\nvcmodel_mm\n.\n\u03a3\n\n\n\n\n\n\n(\n2x2 Array{Float64,2}:\n  0.302279  -0.478398\n -0.478398   0.803237,\n\n2x2 Array{Float64,2}:\n  5.86133   -0.586939\n -0.586939   0.586382)\n\n\n\n\n\nFisher scoring (\nmle_fs!\n) uses either \nIpopt.jl\n (keyword \nsolver=:Ipopt\n) or \nKNITRO.jl\n (keyword \nsolver=:Knitro\n) as the backend solver. Ipopt is open source and installation of \nIpopt.jl\n package alone is sufficient. However Knitro is a commercial software and users need to follow instructions at \nKNITRO.jl\n for proper functioning.\n\n\n# Fisher scoring using Ipopt\n\n\nvcmodel_ipopt\n \n=\n \ndeepcopy\n(\nvcmodel\n)\n\n\n@\ntime\n \nmle_fs!\n(\nvcmodel_ipopt\n,\n \nvcdatarot\n;\n \nsolver\n=\n:\nIpopt\n,\n \nmaxiter\n=\n1000\n,\n \nverbose\n=\ntrue\n);\n\n\n\n\n\n\n******************************************************************************\nThis program contains Ipopt, a library for large-scale nonlinear optimization.\n Ipopt is released as open source code under the Eclipse Public License (EPL).\n         For more information visit http://projects.coin-or.org/Ipopt\n******************************************************************************\n\nThis is Ipopt version 3.12.4, running with linear solver mumps.\nNOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n\nNumber of nonzeros in equality constraint Jacobian...:        0\nNumber of nonzeros in inequality constraint Jacobian.:        0\nNumber of nonzeros in Lagrangian Hessian.............:       21\n\nTotal number of variables............................:        6\n                     variables with only lower bounds:        4\n                variables with lower and upper bounds:        0\n                     variables with only upper bounds:        0\nTotal number of equality constraints.................:        0\nTotal number of inequality constraints...............:        0\n        inequality constraints with only lower bounds:        0\n   inequality constraints with lower and upper bounds:        0\n        inequality constraints with only upper bounds:        0\n\niter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n   0  6.8183666e+03 0.00e+00 9.89e+00   0.0 0.00e+00    -  0.00e+00 0.00e+00   0 \n   5  3.7059581e+03 0.00e+00 5.96e+00  -4.4 7.13e-01    -  1.00e+00 1.00e+00f  1  sigma=8.40e-03MaxS\n  10  3.6256399e+03 0.00e+00 2.71e+00 -11.0 1.04e-01    -  1.00e+00 1.00e+00f  1  sigma=3.37e-03MaxS\n  15  3.6186620e+03 0.00e+00 2.77e-02 -11.0 1.51e-03    -  1.00e+00 1.00e+00f  1  sigma=5.30e-09MaxS\n  20  3.6186618e+03 0.00e+00 5.95e-05 -11.0 3.16e-06    -  1.00e+00 1.00e+00f  1  sigma=5.41e-17MaxS\n  25  3.6186618e+03 0.00e+00 1.27e-07 -11.0 6.76e-09    -  1.00e+00 1.00e+00f  1  sigma=5.35e-25MaxSA\n\nNumber of Iterations....: 28\n\n                                   (scaled)                 (unscaled)\nObjective...............:   7.8367920603164933e+01    3.6186617667669216e+03\nDual infeasibility......:   3.1921838841006262e-09    1.4740002905497475e-07\nConstraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\nComplementarity.........:   1.0000000000010052e-11    4.6175293907497364e-10\nOverall NLP error.......:   3.1921838841006262e-09    1.4740002905497475e-07\n\n\nNumber of objective function evaluations             = 29\nNumber of objective gradient evaluations             = 29\nNumber of equality constraint evaluations            = 0\nNumber of inequality constraint evaluations          = 0\nNumber of equality constraint Jacobian evaluations   = 0\nNumber of inequality constraint Jacobian evaluations = 0\nNumber of Lagrangian Hessian evaluations             = 28\nTotal CPU secs in IPOPT (w/o function evaluations)   =      2.334\nTotal CPU secs in NLP function evaluations           =      0.244\n\nEXIT: Optimal Solution Found.\n  2.987685 seconds (8.12 M allocations: 292.023 MB, 2.09% gc time)\n\n\n\n\n\n# Ipopt estimates\n\n\nvcmodel_ipopt\n.\nB\n\n\n\n\n\n\n2x2 Array{Float64,2}:\n 1.14928   1.00139\n 0.924761  1.02485\n\n\n\n\n\n# Ipopt estimates\n\n\nvcmodel_ipopt\n.\n\u03a3\n\n\n\n\n\n\n(\n2x2 Array{Float64,2}:\n  0.30227   -0.478407\n -0.478407   0.803239,\n\n2x2 Array{Float64,2}:\n  5.86164   -0.586964\n -0.586964   0.586375)\n\n\n\n\n\n# Fisher scoring using Knitro\n\n\nvcmodel_knitro\n \n=\n \ndeepcopy\n(\nvcmodel\n)\n\n\n@\ntime\n \nmle_fs!\n(\nvcmodel_knitro\n,\n \nvcdatarot\n;\n \nsolver\n=\n:\nKnitro\n,\n \nmaxiter\n=\n1000\n,\n \nverbose\n=\ntrue\n);\n\n\n\n\n\n\nKnitro 10.1.0 STUDENT LICENSE (problem size limit = 300)\n\n=======================================\n            Student License\n       (NOT FOR COMMERCIAL USE)\n         Artelys Knitro 10.1.0\n=======================================\n\nKnitro presolve eliminated 0 variables and 0 constraints.\n\nalgorithm:            1\nThe problem is identified as bound constrained only.\nKnitro changing bar_initpt from AUTO to 3.\nKnitro changing bar_murule from AUTO to 4.\nKnitro changing bar_penaltycons from AUTO to 1.\nKnitro changing bar_penaltyrule from AUTO to 2.\nKnitro changing bar_switchrule from AUTO to 1.\nKnitro changing linsolver from AUTO to 2.\n\nProblem Characteristics                    ( Presolved)\n-----------------------\nObjective goal:  Maximize\nNumber of variables:                     6 (         6)\n    bounded below:                       4 (         4)\n    bounded above:                       0 (         0)\n    bounded below and above:             0 (         0)\n    fixed:                               0 (         0)\n    free:                                2 (         2)\nNumber of constraints:                   0 (         0)\n    linear equalities:                   0 (         0)\n    nonlinear equalities:                0 (         0)\n    linear inequalities:                 0 (         0)\n    nonlinear inequalities:              0 (         0)\n    range:                               0 (         0)\nNumber of nonzeros in Jacobian:          0 (         0)\nNumber of nonzeros in Hessian:          21 (        21)\n\n  Iter      Objective      FeasError   OptError    ||Step||    CGits \n--------  --------------  ----------  ----------  ----------  -------\n       0   -5.272317e+03   0.000e+00\n      10   -3.618665e+03   0.000e+00   1.050e-01   6.061e-03        0\n      20   -3.618662e+03   0.000e+00   4.786e-07   2.620e-08        0\n\nEXIT: Locally optimal solution found.\n\nFinal Statistics\n----------------\nFinal objective value               =  -3.61866176676693e+03\nFinal feasibility error (abs / rel) =   0.00e+00 / 0.00e+00\nFinal optimality error  (abs / rel) =   4.79e-07 / 4.79e-07\n# of iterations                     =         20 \n# of CG iterations                  =          0 \n# of function evaluations           =         22\n# of gradient evaluations           =         22\n# of Hessian evaluations            =         20\nTotal program time (secs)           =       0.17739 (     0.177 CPU time)\nTime spent in evaluations (secs)    =       0.11814\n\n===============================================================================\n\n  0.550156 seconds (2.93 M allocations: 71.557 MB, 1.60% gc time)\n\n\n### Could not find a valid license.\n    Your machine ID is 1f-aa-f6-5b-46.\n    Please contact licensing@artelys.com or your local distributor to obtain a license.\n    If you already have a license, please execute `get_machine_ID -v` and send the output to support.\n\n\n\n\n\n# Knitro estimates\n\n\nvcmodel_knitro\n.\nB\n\n\n\n\n\n\n2x2 Array{Float64,2}:\n 1.14928   1.00139\n 0.924761  1.02485\n\n\n\n\n\n# Knitro estimates\n\n\nvcmodel_knitro\n.\n\u03a3\n\n\n\n\n\n\n(\n2x2 Array{Float64,2}:\n  0.30227   -0.478407\n -0.478407   0.803239,\n\n2x2 Array{Float64,2}:\n  5.86164   -0.586964\n -0.586964   0.586375)\n\n\n\n\n\n\n\nStarting point\n\n\nHere are a few strategies for successful optimization. \n\n\n\n\nFor $d\n1$ (multivariate response), initialize $B, \\Sigma$ from univariate estimates.  \n\n\nUse REML estimate as starting point for MLE.  \n\n\nWhen there are only $m=2$ variance components, pre-compute \nTwoVarCompVariateRotate\n and use it for optimization.\n\n\n\n\n\n\nConstrained estimation of \nB\n\n\nMany applications invoke constraints on the mean parameters \nB\n. For demonstration, we enforce \nB[1,1]=B[1,2]\n and all entries of \nB\n are within [0, 2].\n\n\n# set up constraints on B\n\n\nvcmodel_constr\n \n=\n \ndeepcopy\n(\nvcmodel\n)\n\n\nvcmodel_constr\n.\nA\n \n=\n \n[\n1.0\n \n0.0\n \n-\n1.0\n \n0.0\n]\n\n\nvcmodel_constr\n.\nsense\n \n=\n \n=\n\n\nvcmodel_constr\n.\nb\n \n=\n \n0.0\n\n\nvcmodel_constr\n.\nlb\n \n=\n \n0.0\n\n\nvcmodel_constr\n.\nub\n \n=\n \n2.0\n\n\nvcmodel_constr\n\n\n\n\n\n\nVarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(2x2 Array{Float64,2}:\n 0.0  0.0\n 0.0  0.0,(\n2x2 Array{Float64,2}:\n 1.0  0.0\n 0.0  1.0,\n\n2x2 Array{Float64,2}:\n 1.0  0.0\n 0.0  1.0),1x4 Array{Float64,2}:\n 1.0  0.0  -1.0  0.0,\n=\n,0.0,0.0,2.0)\n\n\n\n\n\nWe first try the MM algorithm.\n\n\n# MM algorithm for constrained estimation of B\n\n\n@\ntime\n \nmle_mm!\n(\nvcmodel_constr\n,\n \nvcdatarot\n;\n \nmaxiter\n=\n10000\n,\n \nfuntol\n=\n1e-8\n,\n \nverbose\n \n=\n \ntrue\n);\n\n\n\n\n\n\n     MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0  -7.348297e+03\n       1  -4.105736e+03\n       2  -3.747828e+03\n       3  -3.654068e+03\n       4  -3.629236e+03\n       5  -3.622605e+03\n       6  -3.620799e+03\n       7  -3.620290e+03\n       8  -3.620140e+03\n       9  -3.620094e+03\n      10  -3.620079e+03\n\n  0.407094 seconds (618.18 k allocations: 20.440 MB)\n\n\n\n\n\nfieldnames\n(\nvcmodel_constr\n)\n\n\n\n\n\n\n7-element Array{Symbol,1}:\n :B    \n :\u03a3    \n :A    \n :sense\n :b    \n :lb   \n :ub\n\n\n\n\n\nvcmodel_constr\n.\nB\n\n\n\n\n\n\n2x2 Array{Float64,2}:\n 1.02428   1.02428\n 0.925434  1.02474\n\n\n\n\n\nvcmodel_constr\n.\n\u03a3\n\n\n\n\n\n\n(\n2x2 Array{Float64,2}:\n  0.301672  -0.478044\n -0.478044   0.803126,\n\n2x2 Array{Float64,2}:\n  5.88053   -0.590251\n -0.590251   0.58695 )\n\n\n\n\n\nNow let's try Fisher scoring.\n\n\n# Fisher scoring using Ipopt for constrained estimation of B\n\n\nvcmodel_constr\n \n=\n \ndeepcopy\n(\nvcmodel\n)\n\n\nvcmodel_constr\n.\nA\n \n=\n \n[\n1.0\n \n0.0\n \n-\n1.0\n \n0.0\n]\n\n\nvcmodel_constr\n.\nsense\n \n=\n \n=\n\n\nvcmodel_constr\n.\nb\n \n=\n \n0.0\n\n\nvcmodel_constr\n.\nlb\n \n=\n \n0.0\n\n\nvcmodel_constr\n.\nub\n \n=\n \n2.0\n\n\nvcmodel_constr\n\n\n@\ntime\n \nmle_fs!\n(\nvcmodel_constr\n,\n \nvcdatarot\n;\n \nsolver\n=\n:\nIpopt\n,\n \nmaxiter\n=\n1000\n,\n \nverbose\n=\ntrue\n);\n\n\n\n\n\n\nThis is Ipopt version 3.12.4, running with linear solver mumps.\nNOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n\nNumber of nonzeros in equality constraint Jacobian...:        0\nNumber of nonzeros in inequality constraint Jacobian.:        0\nNumber of nonzeros in Lagrangian Hessian.............:       21\n\nTotal number of variables............................:        6\n                     variables with only lower bounds:        4\n                variables with lower and upper bounds:        0\n                     variables with only upper bounds:        0\nTotal number of equality constraints.................:        0\nTotal number of inequality constraints...............:        0\n        inequality constraints with only lower bounds:        0\n   inequality constraints with lower and upper bounds:        0\n        inequality constraints with only upper bounds:        0\n\niter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n   0  6.8184296e+03 0.00e+00 9.89e+00   0.0 0.00e+00    -  0.00e+00 0.00e+00   0 \n   5  3.7077312e+03 0.00e+00 5.97e+00  -4.4 7.13e-01    -  1.00e+00 1.00e+00f  1  sigma=8.41e-03MaxS\n  10  3.6271375e+03 0.00e+00 2.72e+00 -11.0 1.04e-01    -  1.00e+00 1.00e+00f  1  sigma=3.39e-03MaxS\n  15  3.6200706e+03 0.00e+00 2.76e-02 -11.0 1.51e-03    -  1.00e+00 1.00e+00f  1  sigma=5.40e-09MaxS\n  20  3.6200704e+03 0.00e+00 5.77e-05 -11.0 3.08e-06    -  1.00e+00 1.00e+00f  1  sigma=5.11e-17MaxS\n  25  3.6200704e+03 0.00e+00 1.21e-07 -11.0 6.43e-09    -  1.00e+00 1.00e+00f  1  sigma=4.70e-25MaxSA\n\nNumber of Iterations....: 28\n\n                                   (scaled)                 (unscaled)\nObjective...............:   7.8291178537553890e+01    3.6200703544238395e+03\nDual infeasibility......:   2.9789254301703743e-09    1.3774118411854456e-07\nConstraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\nComplementarity.........:   1.0000000000009410e-11    4.6238547203511678e-10\nOverall NLP error.......:   2.9789254301703743e-09    1.3774118411854456e-07\n\n\nNumber of objective function evaluations             = 29\nNumber of objective gradient evaluations             = 29\nNumber of equality constraint evaluations            = 0\nNumber of inequality constraint evaluations          = 0\nNumber of equality constraint Jacobian evaluations   = 0\nNumber of inequality constraint Jacobian evaluations = 0\nNumber of Lagrangian Hessian evaluations             = 28\nTotal CPU secs in IPOPT (w/o function evaluations)   =      0.018\nTotal CPU secs in NLP function evaluations           =      0.463\n\nEXIT: Optimal Solution Found.\n  0.522384 seconds (3.67 M allocations: 70.253 MB, 9.65% gc time)\n\n\n\n\n\nvcmodel_constr\n.\nB\n\n\n\n\n\n\n2x2 Array{Float64,2}:\n 1.02427   1.02427\n 0.925427  1.02474\n\n\n\n\n\nvcmodel_constr\n.\n\u03a3\n\n\n\n\n\n\n(\n2x2 Array{Float64,2}:\n  0.301662  -0.478052\n -0.478052   0.803128,\n\n2x2 Array{Float64,2}:\n  5.88085   -0.590275\n -0.590275   0.586943)", 
            "title": "MLE/REML"
        }, 
        {
            "location": "/man/mle_reml/#mle-and-reml", 
            "text": "", 
            "title": "MLE and REML"
        }, 
        {
            "location": "/man/mle_reml/#demo-data", 
            "text": "For demonstration, we generate a random data set.  # generate data from a d-variate response variane component model  srand ( 123 )  n   =   1000     # no. observations  d   =   2        # dimension of responses  m   =   2        # no. variance components  p   =   2        # no. covariates  # n-by-p design matrix  X   =   randn ( n ,   p )  # p-by-d mean component regression coefficient  B   =   ones ( p ,   d )    # a tuple of m covariance matrices  V   =   ntuple ( x   -   zeros ( n ,   n ),   m )   for   i   =   1 : m - 1 \n   Vi   =   randn ( n ,   50 ) \n   copy! ( V [ i ],   Vi   *   Vi )  end  copy! ( V [ m ],   eye ( n ))   # last covarianec matrix is idendity  # a tuple of m d-by-d variance component parameters  \u03a3   =   ntuple ( x   -   zeros ( d ,   d ),   m )   for   i   in   1 : m \n   \u03a3i   =   randn ( d ,   d ) \n   copy! ( \u03a3 [ i ],   \u03a3i   *   \u03a3i )  end  # form overall nd-by-nd covariance matrix \u03a9  \u03a9   =   zeros ( n   *   d ,   n   *   d )  for   i   =   1 : m \n   \u03a9   +=   kron ( \u03a3 [ i ],   V [ i ])  end  \u03a9chol   =   cholfact ( \u03a9 )  # n-by-d responses  Y   =   X   *   B   +   reshape ( \u03a9chol [: L ]   *   randn ( n * d ),   n ,   d );", 
            "title": "Demo data"
        }, 
        {
            "location": "/man/mle_reml/#maximum-likelihood-estimation-mle", 
            "text": "To find the MLE of parameters $(B,\\Sigma_1,\\ldots,\\Sigma_m)$, we take 3 steps:    Step 1 (Construct data) . Construct an instance of  VarianceComponentVariate , which consists of the responses $Y$, the covariate matrix $X$, and a tuple of covariance matrices $V$. The last covariance matrix must be positive definite and usually is the identity matrix. In the absence of covariates $X$, we can simply initialize by  vcdata = VarianceComponentVariate(Y, V) .  using   VarianceComponentModels  vcdata   =   VarianceComponentVariate ( Y ,   X ,   V )  fieldnames ( vcdata )   3-element Array{Symbol,1}:\n :Y\n :X\n :V  Step 2 (Construct a model) . Construct an instance of  VarianceComponentModel . The fields  B  and  \u03a3  are mean and variane component parameters respectively. When constructed from a  VarianceComponentVariate  instance, the mean parameters $B$ are initialized to be zero and the tuple of variance component parameters $\\Sigma$ to be  (eye(d),...,eye(d)) .  The remaining fields  A ,  sense ,  b ,  lb ,  ub  specify (optional) constraints on the mean parameters  B :  $A * \\text{vec}(B) =\\ge\\le b$  $lb \\le \\text{vec}(B) \\le ub$  A  is an  m x pd  constraint matrix,  sense  is a  m  vector of charaters taking values  ,  = , or  , and  lb  and  ub  are the lower and upper bounds for  vec(B) . By default,  A ,  sense ,  b  are empty,  lb  is  -Inf , and  ub  is  Inf . If any constraits are non-trivial, final estimates of  B  are enforced to satisfy them.  vcmodel   =   VarianceComponentModel ( vcdata )  fieldnames ( vcmodel )   7-element Array{Symbol,1}:\n :B    \n :\u03a3    \n :A    \n :sense\n :b    \n :lb   \n :ub  vcmodel   VarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(2x2 Array{Float64,2}:\n 0.0  0.0\n 0.0  0.0,(\n2x2 Array{Float64,2}:\n 1.0  0.0\n 0.0  1.0,\n\n2x2 Array{Float64,2}:\n 1.0  0.0\n 0.0  1.0),0x4 Array{Float64,2},Char[],Float64[],-Inf,Inf)  When a better initial guess is available, we can initialize by calling  vcmodel=VarianceComponentModel(B0, \u03a30)  directly.  Step 3 (Fit model) . Call optmization routine  fit_mle! . The keywork  algo  dictates the optimization algorithm:  :MM  (minorization-maximization algorithm) or  :FS  (Fisher scoring algorithm).  vcmodel_mle   =   deepcopy ( vcmodel )  @ time   logl ,   vcmodel_mle ,   \u03a3se ,   \u03a3cov ,   Bse ,   Bcov   =   fit_mle! ( vcmodel_mle ,   vcdata ;   algo   =   : MM );        MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0  -7.348297e+03\n       1  -4.102367e+03\n       2  -3.745567e+03\n       3  -3.652392e+03\n       4  -3.627744e+03\n       5  -3.621170e+03\n       6  -3.619381e+03\n       7  -3.618878e+03\n       8  -3.618730e+03\n       9  -3.618684e+03\n      10  -3.618670e+03\n\n  6.187559 seconds (11.40 M allocations: 481.014 MB, 1.48% gc time)  The output of  fit_mle!  contains     final log-likelihood     logl   -3618.661776037447   fitted model   fieldnames ( vcmodel_mle )   7-element Array{Symbol,1}:\n :B    \n :\u03a3    \n :A    \n :sense\n :b    \n :lb   \n :ub  vcmodel_mle   VarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(2x2 Array{Float64,2}:\n 1.14929   1.00139\n 0.924768  1.02485,(\n2x2 Array{Float64,2}:\n  0.302279  -0.478398\n -0.478398   0.803237,\n\n2x2 Array{Float64,2}:\n  5.86133   -0.586939\n -0.586939   0.586382),0x4 Array{Float64,2},Char[],Float64[],-Inf,Inf)   standard errors of the estimated varianec component parameters   \u03a3se   (\n2x2 Array{Float64,2}:\n 0.06167    0.0995727\n 0.0995727  0.16077  ,\n\n2x2 Array{Float64,2}:\n 0.268915  0.085063\n 0.085063  0.026905)   covariance matrix of the variance component parameters estimates   \u03a3cov   8x8 Array{Float64,2}:\n  0.00380319  -0.00590812  -0.00590812  \u2026   7.45979e-6   -7.52483e-7 \n -0.00590812   0.00991472   0.00917805     -7.52483e-7    7.55745e-7 \n -0.00590812   0.00917805   0.00991472     -7.49213e-6    7.55745e-7 \n  0.00917805  -0.0154021   -0.0154021       7.55745e-7   -7.59023e-7 \n -7.39532e-5   7.45979e-6   7.45979e-6     -0.00724213    0.000725236\n  7.45979e-6  -7.49213e-6  -7.52483e-7  \u2026   0.000725236  -0.000724568\n  7.45979e-6  -7.52483e-7  -7.49213e-6      0.00723572   -0.000724568\n -7.52483e-7   7.55745e-7   7.55745e-7     -0.000724568   0.000723881   standard errors of the estimated mean parameters   Bse   2x2 Array{Float64,2}:\n 0.0760538  0.0251806\n 0.0769259  0.0252831   covariance matrix of the mean parameter estimates   Bcov   4x4 Array{Float64,2}:\n  0.00578418  -6.1406e-5    -0.00061133    3.61347e-6 \n -6.1406e-5    0.00591759    3.61347e-6   -0.000619951\n -0.00061133   3.61347e-6    0.000634064  -1.76949e-6 \n  3.61347e-6  -0.000619951  -1.76949e-6    0.000639237", 
            "title": "Maximum likelihood estimation (MLE)"
        }, 
        {
            "location": "/man/mle_reml/#restricted-maximum-likelihood-estimation-reml", 
            "text": "REML (restricted maximum likelihood estimation)  is a popular alternative to the MLE. To find the REML of a variane component model, we replace the above step 3 by    Step 3 . Call optmization routine  fit_reml! .  vcmodel_reml   =   deepcopy ( vcmodel )  @ time   logl ,   vcmodel_reml ,   \u03a3se ,   \u03a3cov ,   Bse ,   Bcov   =   fit_reml! ( vcmodel_reml ,   vcdata ;   algo   =   : MM );        MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0  -5.297304e+03\n       1  -3.954293e+03\n       2  -3.715870e+03\n       3  -3.663101e+03\n       4  -3.650121e+03\n       5  -3.646663e+03\n       6  -3.645672e+03\n       7  -3.645367e+03\n       8  -3.645268e+03\n       9  -3.645233e+03\n      10  -3.645221e+03\n\n  0.462098 seconds (730.53 k allocations: 42.706 MB, 0.77% gc time)  The output of  fit_reml!  contains   the final log-likelihood at REML estimate   logl   -3622.050155483128   REML estimates   fieldnames ( vcmodel_reml )   7-element Array{Symbol,1}:\n :B    \n :\u03a3    \n :A    \n :sense\n :b    \n :lb   \n :ub  vcmodel_reml   VarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(2x2 Array{Float64,2}:\n 1.08201  1.05525\n 0.90694  1.00679,(\n2x2 Array{Float64,2}:\n  0.301641  -0.477617\n -0.477617   0.802105,\n\n2x2 Array{Float64,2}:\n  5.88057   -0.610115\n -0.610115   0.61958 ),0x4 Array{Float64,2},Char[],Float64[],-Inf,Inf)   standard errors of the estimated varianec component parameters   \u03a3se   (\n2x2 Array{Float64,2}:\n 0.0615463  0.0994049\n 0.0994049  0.160551 ,\n\n2x2 Array{Float64,2}:\n 0.269798   0.0875812\n 0.0875812  0.0284283)   covariance matrix of the variance component parameters estimates   \u03a3cov   8x8 Array{Float64,2}:\n  0.00378795  -0.00588696  -0.00588696  \u2026   7.78026e-6   -8.13244e-7 \n -0.00588696   0.00988133   0.00914906     -8.13244e-7    8.30149e-7 \n -0.00588696   0.00914906   0.00988133     -7.94198e-6    8.30149e-7 \n  0.00914906  -0.0153568   -0.0153568       8.30149e-7   -8.47406e-7 \n -7.44333e-5   7.78026e-6   7.78026e-6     -0.00755281    0.000783641\n  7.78026e-6  -7.94198e-6  -8.13244e-7  \u2026   0.000783641  -0.00079582 \n  7.78026e-6  -8.13244e-7  -7.94198e-6      0.00767047   -0.00079582 \n -8.13244e-7   8.30149e-7   8.30149e-7     -0.00079582    0.000808168   standard errors of the estimated mean parameters   Bse   2x2 Array{Float64,2}:\n 0.0615457  0.0994049\n 0.0994049  0.160551   covariance matrix of the mean parameter estimates   Bcov   4x4 Array{Float64,2}:\n  0.00378788  -0.00588695  -0.00588695   0.00914906\n -0.00588695   0.00988132   0.00914906  -0.0153568 \n -0.00588695   0.00914906   0.00988132  -0.0153568 \n  0.00914906  -0.0153568   -0.0153568    0.0257766", 
            "title": "Restricted maximum likelihood estimation (REML)"
        }, 
        {
            "location": "/man/mle_reml/#optimization-algorithms", 
            "text": "Finding the MLE or REML of variance component models is a non-trivial nonlinear optimization problem. The main complications are the non-convexity of objective function and the positive semi-definiteness constraint of variane component parameters $\\Sigma_1,\\ldots,\\Sigma_m$. Here are some tips for efficient computation.   In general the optimization algorithm needs to invert the $nd$ by $nd$ overall covariance matrix $\\Omega = \\Sigma_1 \\otimes V_1 + \\cdots + \\Sigma_m \\otimes V_m$ in each iteration. Inverting a matrix is an expensive operation with $O(n^3 d^3)$ floating operations. When there are only  two  varianec components ($m=2$), this tedious task can be avoided by taking one (generalized) eigendecomposion of $(V_1, V_2)$ and rotating data $(Y, X)$ by the eigen-vectors.   vcdatarot   =   TwoVarCompVariateRotate ( vcdata )  fieldnames ( vcdatarot )   4-element Array{Symbol,1}:\n :Yrot    \n :Xrot    \n :eigval  \n :logdetV2  Two optimization algorithms are implemented: Fisher scoring ( mle_fs! ) and the  minorization-maximization (MM) algorithm  ( mle_mm! ). Both take the rotated data as input. These two functions give finer control of the optimization algorithms. Generally speaking, MM algorithm is more stable while Fisher scoring (if it converges) yields more accurate answer.  vcmodel_mm   =   deepcopy ( vcmodel )  @ time   mle_mm! ( vcmodel_mm ,   vcdatarot ;   maxiter = 10000 ,   funtol = 1e-8 ,   verbose   =   true );        MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0  -7.348297e+03\n       1  -4.102367e+03\n       2  -3.745567e+03\n       3  -3.652392e+03\n       4  -3.627744e+03\n       5  -3.621170e+03\n       6  -3.619381e+03\n       7  -3.618878e+03\n       8  -3.618730e+03\n       9  -3.618684e+03\n      10  -3.618670e+03\n\n  0.166114 seconds (750.53 k allocations: 28.531 MB, 2.44% gc time)  # MM estimates  vcmodel_mm . B   2x2 Array{Float64,2}:\n 1.14929   1.00139\n 0.924768  1.02485  # MM estimates  vcmodel_mm . \u03a3   (\n2x2 Array{Float64,2}:\n  0.302279  -0.478398\n -0.478398   0.803237,\n\n2x2 Array{Float64,2}:\n  5.86133   -0.586939\n -0.586939   0.586382)  Fisher scoring ( mle_fs! ) uses either  Ipopt.jl  (keyword  solver=:Ipopt ) or  KNITRO.jl  (keyword  solver=:Knitro ) as the backend solver. Ipopt is open source and installation of  Ipopt.jl  package alone is sufficient. However Knitro is a commercial software and users need to follow instructions at  KNITRO.jl  for proper functioning.  # Fisher scoring using Ipopt  vcmodel_ipopt   =   deepcopy ( vcmodel )  @ time   mle_fs! ( vcmodel_ipopt ,   vcdatarot ;   solver = : Ipopt ,   maxiter = 1000 ,   verbose = true );   ******************************************************************************\nThis program contains Ipopt, a library for large-scale nonlinear optimization.\n Ipopt is released as open source code under the Eclipse Public License (EPL).\n         For more information visit http://projects.coin-or.org/Ipopt\n******************************************************************************\n\nThis is Ipopt version 3.12.4, running with linear solver mumps.\nNOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n\nNumber of nonzeros in equality constraint Jacobian...:        0\nNumber of nonzeros in inequality constraint Jacobian.:        0\nNumber of nonzeros in Lagrangian Hessian.............:       21\n\nTotal number of variables............................:        6\n                     variables with only lower bounds:        4\n                variables with lower and upper bounds:        0\n                     variables with only upper bounds:        0\nTotal number of equality constraints.................:        0\nTotal number of inequality constraints...............:        0\n        inequality constraints with only lower bounds:        0\n   inequality constraints with lower and upper bounds:        0\n        inequality constraints with only upper bounds:        0\n\niter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n   0  6.8183666e+03 0.00e+00 9.89e+00   0.0 0.00e+00    -  0.00e+00 0.00e+00   0 \n   5  3.7059581e+03 0.00e+00 5.96e+00  -4.4 7.13e-01    -  1.00e+00 1.00e+00f  1  sigma=8.40e-03MaxS\n  10  3.6256399e+03 0.00e+00 2.71e+00 -11.0 1.04e-01    -  1.00e+00 1.00e+00f  1  sigma=3.37e-03MaxS\n  15  3.6186620e+03 0.00e+00 2.77e-02 -11.0 1.51e-03    -  1.00e+00 1.00e+00f  1  sigma=5.30e-09MaxS\n  20  3.6186618e+03 0.00e+00 5.95e-05 -11.0 3.16e-06    -  1.00e+00 1.00e+00f  1  sigma=5.41e-17MaxS\n  25  3.6186618e+03 0.00e+00 1.27e-07 -11.0 6.76e-09    -  1.00e+00 1.00e+00f  1  sigma=5.35e-25MaxSA\n\nNumber of Iterations....: 28\n\n                                   (scaled)                 (unscaled)\nObjective...............:   7.8367920603164933e+01    3.6186617667669216e+03\nDual infeasibility......:   3.1921838841006262e-09    1.4740002905497475e-07\nConstraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\nComplementarity.........:   1.0000000000010052e-11    4.6175293907497364e-10\nOverall NLP error.......:   3.1921838841006262e-09    1.4740002905497475e-07\n\n\nNumber of objective function evaluations             = 29\nNumber of objective gradient evaluations             = 29\nNumber of equality constraint evaluations            = 0\nNumber of inequality constraint evaluations          = 0\nNumber of equality constraint Jacobian evaluations   = 0\nNumber of inequality constraint Jacobian evaluations = 0\nNumber of Lagrangian Hessian evaluations             = 28\nTotal CPU secs in IPOPT (w/o function evaluations)   =      2.334\nTotal CPU secs in NLP function evaluations           =      0.244\n\nEXIT: Optimal Solution Found.\n  2.987685 seconds (8.12 M allocations: 292.023 MB, 2.09% gc time)  # Ipopt estimates  vcmodel_ipopt . B   2x2 Array{Float64,2}:\n 1.14928   1.00139\n 0.924761  1.02485  # Ipopt estimates  vcmodel_ipopt . \u03a3   (\n2x2 Array{Float64,2}:\n  0.30227   -0.478407\n -0.478407   0.803239,\n\n2x2 Array{Float64,2}:\n  5.86164   -0.586964\n -0.586964   0.586375)  # Fisher scoring using Knitro  vcmodel_knitro   =   deepcopy ( vcmodel )  @ time   mle_fs! ( vcmodel_knitro ,   vcdatarot ;   solver = : Knitro ,   maxiter = 1000 ,   verbose = true );   Knitro 10.1.0 STUDENT LICENSE (problem size limit = 300)\n\n=======================================\n            Student License\n       (NOT FOR COMMERCIAL USE)\n         Artelys Knitro 10.1.0\n=======================================\n\nKnitro presolve eliminated 0 variables and 0 constraints.\n\nalgorithm:            1\nThe problem is identified as bound constrained only.\nKnitro changing bar_initpt from AUTO to 3.\nKnitro changing bar_murule from AUTO to 4.\nKnitro changing bar_penaltycons from AUTO to 1.\nKnitro changing bar_penaltyrule from AUTO to 2.\nKnitro changing bar_switchrule from AUTO to 1.\nKnitro changing linsolver from AUTO to 2.\n\nProblem Characteristics                    ( Presolved)\n-----------------------\nObjective goal:  Maximize\nNumber of variables:                     6 (         6)\n    bounded below:                       4 (         4)\n    bounded above:                       0 (         0)\n    bounded below and above:             0 (         0)\n    fixed:                               0 (         0)\n    free:                                2 (         2)\nNumber of constraints:                   0 (         0)\n    linear equalities:                   0 (         0)\n    nonlinear equalities:                0 (         0)\n    linear inequalities:                 0 (         0)\n    nonlinear inequalities:              0 (         0)\n    range:                               0 (         0)\nNumber of nonzeros in Jacobian:          0 (         0)\nNumber of nonzeros in Hessian:          21 (        21)\n\n  Iter      Objective      FeasError   OptError    ||Step||    CGits \n--------  --------------  ----------  ----------  ----------  -------\n       0   -5.272317e+03   0.000e+00\n      10   -3.618665e+03   0.000e+00   1.050e-01   6.061e-03        0\n      20   -3.618662e+03   0.000e+00   4.786e-07   2.620e-08        0\n\nEXIT: Locally optimal solution found.\n\nFinal Statistics\n----------------\nFinal objective value               =  -3.61866176676693e+03\nFinal feasibility error (abs / rel) =   0.00e+00 / 0.00e+00\nFinal optimality error  (abs / rel) =   4.79e-07 / 4.79e-07\n# of iterations                     =         20 \n# of CG iterations                  =          0 \n# of function evaluations           =         22\n# of gradient evaluations           =         22\n# of Hessian evaluations            =         20\nTotal program time (secs)           =       0.17739 (     0.177 CPU time)\nTime spent in evaluations (secs)    =       0.11814\n\n===============================================================================\n\n  0.550156 seconds (2.93 M allocations: 71.557 MB, 1.60% gc time)\n\n\n### Could not find a valid license.\n    Your machine ID is 1f-aa-f6-5b-46.\n    Please contact licensing@artelys.com or your local distributor to obtain a license.\n    If you already have a license, please execute `get_machine_ID -v` and send the output to support.  # Knitro estimates  vcmodel_knitro . B   2x2 Array{Float64,2}:\n 1.14928   1.00139\n 0.924761  1.02485  # Knitro estimates  vcmodel_knitro . \u03a3   (\n2x2 Array{Float64,2}:\n  0.30227   -0.478407\n -0.478407   0.803239,\n\n2x2 Array{Float64,2}:\n  5.86164   -0.586964\n -0.586964   0.586375)", 
            "title": "Optimization algorithms"
        }, 
        {
            "location": "/man/mle_reml/#starting-point", 
            "text": "Here are a few strategies for successful optimization.    For $d 1$ (multivariate response), initialize $B, \\Sigma$ from univariate estimates.    Use REML estimate as starting point for MLE.    When there are only $m=2$ variance components, pre-compute  TwoVarCompVariateRotate  and use it for optimization.", 
            "title": "Starting point"
        }, 
        {
            "location": "/man/mle_reml/#constrained-estimation-of-b", 
            "text": "Many applications invoke constraints on the mean parameters  B . For demonstration, we enforce  B[1,1]=B[1,2]  and all entries of  B  are within [0, 2].  # set up constraints on B  vcmodel_constr   =   deepcopy ( vcmodel )  vcmodel_constr . A   =   [ 1.0   0.0   - 1.0   0.0 ]  vcmodel_constr . sense   =   =  vcmodel_constr . b   =   0.0  vcmodel_constr . lb   =   0.0  vcmodel_constr . ub   =   2.0  vcmodel_constr   VarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(2x2 Array{Float64,2}:\n 0.0  0.0\n 0.0  0.0,(\n2x2 Array{Float64,2}:\n 1.0  0.0\n 0.0  1.0,\n\n2x2 Array{Float64,2}:\n 1.0  0.0\n 0.0  1.0),1x4 Array{Float64,2}:\n 1.0  0.0  -1.0  0.0, = ,0.0,0.0,2.0)  We first try the MM algorithm.  # MM algorithm for constrained estimation of B  @ time   mle_mm! ( vcmodel_constr ,   vcdatarot ;   maxiter = 10000 ,   funtol = 1e-8 ,   verbose   =   true );        MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0  -7.348297e+03\n       1  -4.105736e+03\n       2  -3.747828e+03\n       3  -3.654068e+03\n       4  -3.629236e+03\n       5  -3.622605e+03\n       6  -3.620799e+03\n       7  -3.620290e+03\n       8  -3.620140e+03\n       9  -3.620094e+03\n      10  -3.620079e+03\n\n  0.407094 seconds (618.18 k allocations: 20.440 MB)  fieldnames ( vcmodel_constr )   7-element Array{Symbol,1}:\n :B    \n :\u03a3    \n :A    \n :sense\n :b    \n :lb   \n :ub  vcmodel_constr . B   2x2 Array{Float64,2}:\n 1.02428   1.02428\n 0.925434  1.02474  vcmodel_constr . \u03a3   (\n2x2 Array{Float64,2}:\n  0.301672  -0.478044\n -0.478044   0.803126,\n\n2x2 Array{Float64,2}:\n  5.88053   -0.590251\n -0.590251   0.58695 )  Now let's try Fisher scoring.  # Fisher scoring using Ipopt for constrained estimation of B  vcmodel_constr   =   deepcopy ( vcmodel )  vcmodel_constr . A   =   [ 1.0   0.0   - 1.0   0.0 ]  vcmodel_constr . sense   =   =  vcmodel_constr . b   =   0.0  vcmodel_constr . lb   =   0.0  vcmodel_constr . ub   =   2.0  vcmodel_constr  @ time   mle_fs! ( vcmodel_constr ,   vcdatarot ;   solver = : Ipopt ,   maxiter = 1000 ,   verbose = true );   This is Ipopt version 3.12.4, running with linear solver mumps.\nNOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n\nNumber of nonzeros in equality constraint Jacobian...:        0\nNumber of nonzeros in inequality constraint Jacobian.:        0\nNumber of nonzeros in Lagrangian Hessian.............:       21\n\nTotal number of variables............................:        6\n                     variables with only lower bounds:        4\n                variables with lower and upper bounds:        0\n                     variables with only upper bounds:        0\nTotal number of equality constraints.................:        0\nTotal number of inequality constraints...............:        0\n        inequality constraints with only lower bounds:        0\n   inequality constraints with lower and upper bounds:        0\n        inequality constraints with only upper bounds:        0\n\niter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n   0  6.8184296e+03 0.00e+00 9.89e+00   0.0 0.00e+00    -  0.00e+00 0.00e+00   0 \n   5  3.7077312e+03 0.00e+00 5.97e+00  -4.4 7.13e-01    -  1.00e+00 1.00e+00f  1  sigma=8.41e-03MaxS\n  10  3.6271375e+03 0.00e+00 2.72e+00 -11.0 1.04e-01    -  1.00e+00 1.00e+00f  1  sigma=3.39e-03MaxS\n  15  3.6200706e+03 0.00e+00 2.76e-02 -11.0 1.51e-03    -  1.00e+00 1.00e+00f  1  sigma=5.40e-09MaxS\n  20  3.6200704e+03 0.00e+00 5.77e-05 -11.0 3.08e-06    -  1.00e+00 1.00e+00f  1  sigma=5.11e-17MaxS\n  25  3.6200704e+03 0.00e+00 1.21e-07 -11.0 6.43e-09    -  1.00e+00 1.00e+00f  1  sigma=4.70e-25MaxSA\n\nNumber of Iterations....: 28\n\n                                   (scaled)                 (unscaled)\nObjective...............:   7.8291178537553890e+01    3.6200703544238395e+03\nDual infeasibility......:   2.9789254301703743e-09    1.3774118411854456e-07\nConstraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\nComplementarity.........:   1.0000000000009410e-11    4.6238547203511678e-10\nOverall NLP error.......:   2.9789254301703743e-09    1.3774118411854456e-07\n\n\nNumber of objective function evaluations             = 29\nNumber of objective gradient evaluations             = 29\nNumber of equality constraint evaluations            = 0\nNumber of inequality constraint evaluations          = 0\nNumber of equality constraint Jacobian evaluations   = 0\nNumber of inequality constraint Jacobian evaluations = 0\nNumber of Lagrangian Hessian evaluations             = 28\nTotal CPU secs in IPOPT (w/o function evaluations)   =      0.018\nTotal CPU secs in NLP function evaluations           =      0.463\n\nEXIT: Optimal Solution Found.\n  0.522384 seconds (3.67 M allocations: 70.253 MB, 9.65% gc time)  vcmodel_constr . B   2x2 Array{Float64,2}:\n 1.02427   1.02427\n 0.925427  1.02474  vcmodel_constr . \u03a3   (\n2x2 Array{Float64,2}:\n  0.301662  -0.478052\n -0.478052   0.803128,\n\n2x2 Array{Float64,2}:\n  5.88085   -0.590275\n -0.590275   0.586943)", 
            "title": "Constrained estimation of B"
        }, 
        {
            "location": "/man/heritability/", 
            "text": "Heritability Analysis\n\n\nThis note demonstrates the workflow for a typical heritability analysis in genetics, using a sample data set \ncg10k\n with \n6,670\n individuals and \n630,860\n SNPs. Person IDs and phenotype names are masked for privacy. Here \ncg10k.bed\n, \ncg10k.bim\n, and \ncg10k.fam\n is a set of Plink files in binary format. \ncg10k_traits.txt\n contains the phenotype data of 6,670 individuals.\n\n\n;\nls\n \ncg10k\n*.*\n\n\n\n\n\n\ncg10k.bed\ncg10k.bim\ncg10k.fam\ncg10k.ipynb\ncg10k.jld\ncg10k_traits.txt\n\n\n\n\n\nMachine information:\n\n\nversioninfo\n()\n\n\n\n\n\n\nJulia Version 0.4.6\nCommit 2e358ce (2016-06-19 17:16 UTC)\nPlatform Info:\n  System: Darwin (x86_64-apple-darwin13.4.0)\n  CPU: Intel(R) Core(TM) i7-4790K CPU @ 4.00GHz\n  WORD_SIZE: 64\n  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Haswell)\n  LAPACK: libopenblas64_\n  LIBM: libopenlibm\n  LLVM: libLLVM-3.3\n\n\n\n\n\n\n\nRead in binary SNP data\n\n\nWe will use the \nSnpArrays\n package to read in binary SNP data and compute the empirical kinship matrix. Issue \nPkg.clone(\"git@github.com:Hua-Zhou/SnpArrays.jl.git\")\n within \nJulia\n to install the \nSnpArrays\n package.\n\n\n#Pkg.clone(\ngit@github.com:OpenMendel/SnpArrays.jl.git\n)\n\n\nusing\n \nSnpArrays\n\n\n\n\n\n\n# read in genotype data from Plink binary file (~50 secs on my laptop)\n\n\n@\ntime\n \ncg10k\n \n=\n \nSnpArray\n(\ncg10k\n)\n\n\n\n\n\n\n 33.409278 seconds (4.58 k allocations: 1003.520 MB, 0.07% gc time)\n\n\n\n\n\n6670x630860 SnpArrays.SnpArray{2}:\n (false,true)   (false,true)   (true,true)   \u2026  (true,true)    (true,true) \n (true,true)    (true,true)    (false,true)     (false,true)   (true,false)\n (true,true)    (true,true)    (false,true)     (true,true)    (true,true) \n (true,true)    (true,true)    (true,true)      (false,true)   (true,true) \n (true,true)    (true,true)    (true,true)      (true,true)    (false,true)\n (false,true)   (false,true)   (true,true)   \u2026  (true,true)    (true,true) \n (false,false)  (false,false)  (true,true)      (true,true)    (true,true) \n (true,true)    (true,true)    (true,true)      (true,true)    (false,true)\n (true,true)    (true,true)    (false,true)     (true,true)    (true,true) \n (true,true)    (true,true)    (true,true)      (false,true)   (true,true) \n (true,true)    (true,true)    (false,true)  \u2026  (true,true)    (true,true) \n (false,true)   (false,true)   (true,true)      (true,true)    (false,true)\n (true,true)    (true,true)    (true,true)      (true,true)    (false,true)\n \u22ee                                           \u22f1                             \n (false,true)   (false,true)   (true,true)      (false,true)   (false,true)\n (false,true)   (false,true)   (false,true)     (false,true)   (true,true) \n (true,true)    (true,true)    (false,true)  \u2026  (false,true)   (true,true) \n (false,true)   (false,true)   (true,true)      (true,true)    (false,true)\n (true,true)    (true,true)    (true,true)      (false,true)   (true,true) \n (true,true)    (true,true)    (true,false)     (false,false)  (false,true)\n (true,true)    (true,true)    (true,true)      (true,true)    (false,true)\n (true,true)    (true,true)    (false,true)  \u2026  (true,true)    (true,true) \n (true,true)    (true,true)    (true,true)      (false,true)   (true,true) \n (true,true)    (true,true)    (true,true)      (true,true)    (false,true)\n (false,true)   (false,true)   (true,true)      (true,true)    (true,true) \n (true,true)    (true,true)    (true,true)      (true,true)    (true,true)\n\n\n\n\n\n\n\nSummary statistics of SNP data\n\n\npeople\n,\n \nsnps\n \n=\n \nsize\n(\ncg10k\n)\n\n\n\n\n\n\n(6670,630860)\n\n\n\n\n\n# summary statistics (~50 secs on my laptop)\n\n\n@\ntime\n \nmaf\n,\n \nminor_allele\n,\n \nmissings_by_snp\n,\n \nmissings_by_person\n \n=\n \nsummarize\n(\ncg10k\n)\n\n\n\n\n\n\n 28.517763 seconds (20 allocations: 9.753 MB)\n\n\n\n\n\n([0.169916,0.17099,0.114026,0.268694,0.219265,0.23935,0.190612,0.20201,0.0271609,0.299714  \u2026  0.207996,0.448012,0.295465,0.142654,0.170915,0.281428,0.0611354,0.0524738,0.13931,0.132413],Bool[true,true,true,true,true,true,true,true,true,true  \u2026  true,true,true,true,true,true,true,true,true,true],[2,0,132,77,0,27,2,2,6,27  \u2026  4,5,11,0,0,4,29,0,5,43],[364,1087,1846,1724,1540,248,215,273,273,224  \u2026  1353,692,901,1039,685,304,223,1578,2059,1029])\n\n\n\n\n\n# 5 number summary and average MAF (minor allele frequencies)\n\n\nquantile\n(\nmaf\n,\n \n[\n0.0\n \n.\n25\n \n.\n5\n \n.\n75\n \n1.0\n]),\n \nmean\n(\nmaf\n)\n\n\n\n\n\n\n(\n1x5 Array{Float64,2}:\n 0.00841726  0.124063  0.236953  0.364253  0.5,\n\n0.24536516625042462)\n\n\n\n\n\nusing\n \nPlots\n\n\npyplot\n()\n\n\n#gr()\n\n\n\nhistogram\n(\nmaf\n,\n \nxlab\n \n=\n \nMinor Allele Frequency (MAF)\n,\n \nlabel\n \n=\n \nMAF\n)\n\n\n\n\n\n\n\n\n# proportion of missing genotypes\n\n\nsum\n(\nmissings_by_snp\n)\n \n/\n \nlength\n(\ncg10k\n)\n\n\n\n\n\n\n0.0013128198764010824\n\n\n\n\n\n# proportion of rare SNPs with maf \n 0.05\n\n\ncountnz\n(\nmaf\n \n.\n \n0.05\n)\n \n/\n \nlength\n(\nmaf\n)\n\n\n\n\n\n\n0.07228069619249913\n\n\n\n\n\n\n\nEmpirical kinship matrix\n\n\nWe estimate empirical kinship based on all SNPs by the genetic relation matrix (GRM). Missing genotypes are imputed on the fly by drawing according to the minor allele frequencies.\n\n\n# GRM using all SNPs (~10 mins on my laptop)\n\n\nsrand\n(\n123\n)\n\n\n@\ntime\n \n\u03a6grm\n \n=\n \ngrm\n(\ncg10k\n;\n \nmethod\n \n=\n \n:\nGRM\n)\n\n\n\n\n\n\n343.981385 seconds (4.21 G allocations: 64.468 GB, 2.25% gc time)\n\n\n\n\n\n6670x6670 Array{Float64,2}:\n  0.502916      0.00329978   -0.000116213  \u2026  -6.46286e-5   -0.00281229 \n  0.00329978    0.49892      -0.00201992       0.000909871   0.00345573 \n -0.000116213  -0.00201992    0.493632         0.000294565  -0.000349854\n  0.000933977  -0.00320391   -0.0018611       -0.00241682   -0.00127078 \n -7.75429e-5   -0.0036075     0.00181442       0.00213976   -0.00158382 \n  0.00200371    0.000577386   0.0025455    \u2026   0.000943753  -1.82994e-6 \n  0.000558503   0.00241421   -0.0018782        0.001217     -0.00123924 \n -0.000659495   0.00319987   -0.00101496       0.00353646   -0.00024093 \n -0.00102619   -0.00120448   -0.00055462       0.00175586    0.00181899 \n -0.00136838    0.00211996    0.000119128     -0.00147305   -0.00105239 \n -0.00206144    0.000148818  -0.000475177  \u2026  -0.000265522  -0.00106123 \n  0.000951016   0.00167042    0.00183545      -0.000703658  -0.00313334 \n  0.000330442  -0.000904147   0.00301478       0.000754772  -0.00127413 \n  \u22ee                                        \u22f1                            \n  0.00301137    0.00116042    0.00100426       6.67254e-6    0.00307069 \n -0.00214008    0.00270925   -0.00185054      -0.00109935    0.00366816 \n  0.000546739  -0.00242646   -0.00305264   \u2026  -0.000629014   0.00210779 \n -0.00422553   -0.0020713    -0.00109052      -0.000705804  -0.000508055\n -0.00318405   -0.00075385    0.00312377       0.00052883   -3.60969e-5 \n  0.000430196  -0.00197163    0.00268545      -0.00633175   -0.00520337 \n  0.00221429    0.000849792  -0.00101111      -0.000943129  -0.000624419\n -0.00229025   -0.000130598   0.000101853  \u2026   0.000840136  -0.00230224 \n -0.00202917    0.00233007   -0.00131006       0.00197798   -0.000513771\n -0.000964907  -0.000872326  -7.06722e-5       0.00124702   -0.00295844 \n -6.46286e-5    0.000909871   0.000294565      0.500983      0.000525615\n -0.00281229    0.00345573   -0.000349854      0.000525615   0.500792\n\n\n\n\n\n\n\nPhenotypes\n\n\nRead in the phenotype data and compute descriptive statistics.\n\n\nusing\n \nDataFrames\n\n\n\ncg10k_trait\n \n=\n \nreadtable\n(\ncg10k_traits.txt\n;\n \n    \nseparator\n \n=\n \n \n,\n\n    \nnames\n \n=\n \n[:\nFID\n;\n \n:\nIID\n;\n \n:\nTrait1\n;\n \n:\nTrait2\n;\n \n:\nTrait3\n;\n \n:\nTrait4\n;\n \n:\nTrait5\n;\n \n:\nTrait6\n;\n \n             \n:\nTrait7\n;\n \n:\nTrait8\n;\n \n:\nTrait9\n;\n \n:\nTrait10\n;\n \n:\nTrait11\n;\n \n:\nTrait12\n;\n \n:\nTrait13\n],\n  \n    \neltypes\n \n=\n \n[\nUTF8String\n;\n \nUTF8String\n;\n \nFloat64\n;\n \nFloat64\n;\n \nFloat64\n;\n \nFloat64\n;\n \nFloat64\n;\n \n               \nFloat64\n;\n \nFloat64\n;\n \nFloat64\n;\n \nFloat64\n;\n \nFloat64\n;\n \nFloat64\n;\n \nFloat64\n;\n \nFloat64\n])\n\n\n\n\n\n\nFID\nIID\nTrait1\nTrait2\nTrait3\nTrait4\nTrait5\nTrait6\nTrait7\nTrait8\nTrait9\nTrait10\nTrait11\nTrait12\nTrait13\n1\n10002K\n10002K\n-1.81573145026234\n-0.94615046147283\n1.11363077580442\n-2.09867121119159\n0.744416614111748\n0.00139171884080131\n0.934732480409667\n-1.22677315418103\n1.1160784277875\n-0.4436280335029\n0.824465656443384\n-1.02852542216546\n-0.394049201727681\n2\n10004O\n10004O\n-1.24440094378729\n0.109659992547179\n0.467119394241789\n-1.62131304097589\n1.0566758355683\n0.978946979419181\n1.00014633946047\n0.32487427140228\n1.16232175219696\n2.6922706948705\n3.08263672461047\n1.09064954786013\n0.0256616415357438\n3\n10005Q\n10005Q\n1.45566914502305\n1.53866932923243\n1.09402959376555\n0.586655272226893\n-0.32796454430367\n-0.30337709778827\n-0.0334354881314741\n-0.464463064285437\n-0.3319396273436\n-0.486839089635991\n-1.10648681564373\n-1.42015780427231\n-0.687463456644413\n4\n10006S\n10006S\n-0.768809276698548\n0.513490885514249\n0.244263028382142\n-1.31740254475691\n1.19393774326845\n1.17344127734288\n1.08737426675232\n0.536022583732261\n0.802759240762068\n0.234159411749815\n0.394174866891074\n-0.767365892476029\n0.0635385761884935\n5\n10009Y\n10009Y\n-0.264415132547719\n-0.348240421825694\n-0.0239065083413606\n0.00473915802244948\n1.25619191712193\n1.2038883667631\n1.29800739042627\n0.310113660247311\n0.626159861059352\n0.899289129831224\n0.54996783350812\n0.540687809542048\n0.179675416046033\n6\n10010J\n10010J\n-1.37617270917293\n-1.47191967744564\n0.291179894254146\n-0.803110740704731\n-0.264239977442213\n-0.260573027836772\n-0.165372266287781\n-0.219257294118362\n1.04702422290318\n-0.0985815534616482\n0.947393438068448\n0.594014812031438\n0.245407436348479\n7\n10011L\n10011L\n0.1009416296374\n-0.191615722103455\n-0.567421321596677\n0.378571487240382\n-0.246656179817904\n-0.608810750053858\n0.189081058215596\n-1.27077787326519\n-0.452476199143965\n0.702562877297724\n0.332636218957179\n0.0026916503626181\n0.317117176705358\n8\n10013P\n10013P\n-0.319818276367464\n1.35774480657283\n0.818689545938528\n-1.15565531644352\n0.63448368102259\n0.291461908634679\n0.933323714954726\n-0.741083289682492\n0.647477683507572\n-0.970877627077966\n0.220861165411304\n0.852512250237764\n-0.225904624283945\n9\n10014R\n10014R\n-0.288334173342032\n0.566082538090752\n0.254958336116175\n-0.652578302869714\n0.668921559277347\n0.978309199170558\n0.122862966041938\n1.4790926378214\n0.0672132424173449\n0.0795903917527827\n0.167532455243232\n0.246915579442139\n0.539932616458363\n10\n10015T\n10015T\n-1.15759732583991\n-0.781198583545165\n-0.595807759833517\n-1.00554980260402\n0.789828885933321\n0.571058413379044\n0.951304176233755\n-0.295962982984816\n0.99042002479707\n0.561309366988983\n0.733100030623233\n-1.73467772245684\n-1.35278484330654\n11\n10017X\n10017X\n0.740569150459031\n1.40873846755415\n0.734689999440088\n0.0208322841295094\n-0.337440968561619\n-0.458304040611395\n-0.142582512772326\n-0.580392297464107\n-0.684684998101516\n-0.00785381461893456\n-0.712244337518008\n-0.313345561230878\n-0.345419463162219\n12\n10020M\n10020M\n-0.675892486454995\n0.279892613829682\n0.267915996308248\n-1.04103665392985\n0.910741715645888\n0.866027618513171\n1.07414431702005\n0.0381751003538302\n0.766355377018601\n-0.340118016143495\n-0.809013958505059\n0.548521663785885\n-0.0201828675962336\n13\n10022Q\n10022Q\n-0.795410435603455\n-0.699989939762738\n0.3991295030063\n-0.510476261900736\n1.51552245416844\n1.28743032939467\n1.53772393250903\n0.133989160117702\n1.02025736886037\n0.499018733899186\n-0.36948273277931\n-1.10153460436318\n-0.598132438886619\n14\n10023S\n10023S\n-0.193483122930324\n-0.286021160323518\n-0.691494225262995\n0.0131581678700699\n1.52337470686782\n1.4010638072262\n1.53114620451896\n0.333066483478075\n1.04372480381099\n0.163206783570466\n-0.422883765001728\n-0.383527976713573\n-0.489221907788158\n15\n10028C\n10028C\n0.151246203379718\n2.09185108993614\n2.03800472474384\n-1.12474717143531\n1.66557024390713\n1.62535675109576\n1.58751070483655\n0.635852186043776\n0.842577784605979\n0.450761870778952\n-1.39479033623028\n-0.560984107567768\n0.289349776549287\n16\n10031R\n10031R\n-0.464608740812712\n0.36127694772303\n1.2327673928287\n-0.826033731086383\n1.43475224709983\n1.74451823818846\n0.211096887484638\n2.64816425140548\n1.02511433146096\n0.11975731603184\n0.0596832073448267\n-0.631231612661616\n-0.207878671782927\n17\n10032T\n10032T\n-0.732977488012215\n-0.526223425889779\n0.61657871336593\n-0.55447974332593\n0.947484859025104\n0.936833214138173\n0.972516806335524\n0.290251013865227\n1.01285359725723\n0.516207422283291\n-0.0300689171988194\n0.8787322524583\n0.450254629309513\n18\n10034X\n10034X\n-0.167326459622119\n0.175327165487237\n0.287467725892572\n-0.402652532084246\n0.551181509418056\n0.522204743290975\n0.436837660094653\n0.299564933845579\n0.583109520896067\n-0.704415820005353\n-0.730810367994577\n-1.95140580379896\n-0.933504665700164\n19\n10035Z\n10035Z\n1.41159485787418\n1.78722407901017\n0.84397639585364\n0.481278083772991\n-0.0887673728508268\n-0.49957757426858\n0.304195897924847\n-1.23884208383369\n-0.153475724036624\n-0.870486102788329\n0.0955473331150403\n-0.983708050882817\n-0.3563445644514\n20\n10041U\n10041U\n-1.42997091652825\n-0.490147045034213\n0.272730237607695\n-1.61029992954153\n0.990787817197748\n0.711687532608184\n1.1885836012715\n-0.371229188075638\n1.24703459239952\n-0.0389162332271516\n0.883495749072872\n2.58988026321017\n3.33539552370368\n21\n10047G\n10047G\n-0.147247288176765\n0.12328430415652\n0.617549051912237\n-0.18713077178262\n0.256438107586694\n0.17794983735083\n0.412611806463263\n-0.244809124559737\n0.0947624806136492\n0.723017223849532\n-0.683948354633436\n0.0873751276309269\n-0.262209652750371\n22\n10051X\n10051X\n-0.187112676773894\n-0.270777264595619\n-1.01556818551606\n0.0602850568600233\n0.272419757757978\n0.869133161879197\n-0.657519461414234\n2.32388522018189\n-0.999936011525034\n1.44671844178306\n0.971157886040772\n-0.358747904241515\n-0.439657942096136\n23\n10052Z\n10052Z\n-1.82434047163768\n-0.933480446068067\n1.29474003766977\n-1.94545221151036\n0.33584651189654\n0.359201654302844\n0.513652924365886\n-0.073197696696958\n1.57139042812005\n1.53329371326728\n1.82076821859528\n2.22740301867829\n1.50063347195857\n24\n10056H\n10056H\n-2.29344084351335\n-2.49161842344418\n0.40383988742336\n-2.36488074752948\n1.4105254831956\n1.42244117147792\n1.17024166272172\n0.84476650176855\n1.79026875432495\n0.648181858970515\n-0.0857231057403538\n-1.02789535292617\n0.491288088952859\n25\n10057J\n10057J\n-0.434135932888305\n0.740881989034652\n0.699576357578518\n-1.02405543187775\n0.759529223983713\n0.956656110895288\n0.633299568656589\n0.770733932268516\n0.824988511714526\n1.84287437634769\n1.91045942063443\n-0.502317207869366\n0.132670133448219\n26\n10058L\n10058L\n-2.1920969546557\n-2.49465664272271\n0.354854763893431\n-1.93155848635714\n0.941979400289938\n0.978917101414106\n0.894860097289736\n0.463239402831873\n1.12537133317163\n1.70528446191955\n0.717792714479123\n0.645888049108261\n0.783968250169388\n27\n10060Y\n10060Y\n-1.46602269088422\n-1.24921677101897\n0.307977693653039\n-1.55097364660989\n0.618908494474798\n0.662508171662042\n0.475957173906078\n0.484718674597707\n0.401564892028249\n0.55987973254026\n-0.376938143754217\n-0.933982629228218\n0.390013151672955\n28\n10062C\n10062C\n-1.83317744236881\n-1.53268787828701\n2.55674262685865\n-1.51827745783835\n0.789409601746455\n0.908747799728588\n0.649971922941479\n0.668373649931667\n1.20058303519903\n0.277963256075637\n1.2504953198275\n3.31370445071638\n2.22035828885342\n29\n10064G\n10064G\n-0.784546628243178\n0.276582579543931\n3.01104958800057\n-1.11978843206758\n0.920823858422707\n0.750217689886151\n1.26153730009639\n-0.403363882922417\n0.400667296857811\n-0.217597941303479\n-0.724669537565068\n-0.391945338467193\n-0.650023936358253\n30\n10065I\n10065I\n0.464455916345135\n1.3326356122229\n-1.23059563374303\n-0.357975958937414\n1.18249746977104\n1.54315938069757\n-0.60339041154062\n3.38308845958422\n0.823740765148641\n-0.129951318508883\n-0.657979878422938\n-0.499534924074273\n-0.414476569095651\n\n\n\n#describe(cg10k_trait)\n\n\n\n\n\n\nY\n \n=\n \nconvert\n(\nMatrix\n{\nFloat64\n},\n \ncg10k_trait\n[:,\n \n3\n:\n15\n])\n\n\nhistogram\n(\nY\n,\n \nlayout\n \n=\n \n13\n)\n\n\n\n\n\n\n\n\n\n\nPre-processing data for heritability analysis\n\n\nTo prepare variance component model fitting, we form an instance of \nVarianceComponentVariate\n. The two variance components are $(2\\Phi, I)$.\n\n\nusing\n \nVarianceComponentModels\n\n\n\n# form data as VarianceComponentVariate\n\n\ncg10kdata\n \n=\n \nVarianceComponentVariate\n(\nY\n,\n \n(\n2\n\u03a6grm\n,\n \neye\n(\nsize\n(\nY\n,\n \n1\n))))\n\n\nfieldnames\n(\ncg10kdata\n)\n\n\n\n\n\n\n3-element Array{Symbol,1}:\n :Y\n :X\n :V\n\n\n\n\n\ncg10kdata\n\n\n\n\n\n\nVarianceComponentModels.VarianceComponentVariate{Float64,2,Array{Float64,2},Array{Float64,2},Array{Float64,2}}(6670x13 Array{Float64,2}:\n -1.81573   -0.94615     1.11363    \u2026   0.824466  -1.02853     -0.394049 \n -1.2444     0.10966     0.467119       3.08264    1.09065      0.0256616\n  1.45567    1.53867     1.09403       -1.10649   -1.42016     -0.687463 \n -0.768809   0.513491    0.244263       0.394175  -0.767366     0.0635386\n -0.264415  -0.34824    -0.0239065      0.549968   0.540688     0.179675 \n -1.37617   -1.47192     0.29118    \u2026   0.947393   0.594015     0.245407 \n  0.100942  -0.191616   -0.567421       0.332636   0.00269165   0.317117 \n -0.319818   1.35774     0.81869        0.220861   0.852512    -0.225905 \n -0.288334   0.566083    0.254958       0.167532   0.246916     0.539933 \n -1.1576    -0.781199   -0.595808       0.7331    -1.73468     -1.35278  \n  0.740569   1.40874     0.73469    \u2026  -0.712244  -0.313346    -0.345419 \n -0.675892   0.279893    0.267916      -0.809014   0.548522    -0.0201829\n -0.79541   -0.69999     0.39913       -0.369483  -1.10153     -0.598132 \n  \u22ee                                 \u22f1   \u22ee                                \n -0.131005   0.425378   -1.09015        0.35674    0.456428     0.882577 \n -0.52427    1.04173     1.13749        0.366737   1.78286      1.90764  \n  1.32516    0.905899    0.84261    \u2026  -0.418756  -0.275519    -0.912778 \n -1.44368   -2.55708    -0.868193       1.31914   -1.44981     -1.77373  \n -1.8518    -1.25726     1.81724        0.770329  -0.0470789    1.50496  \n -0.810034   0.0896703   0.530939       0.757479   1.10001      1.29115  \n -1.22395   -1.48953    -2.95847        1.29209    0.697478     0.228819 \n -0.282847  -1.54129    -1.38819    \u2026   1.00973   -0.362158    -1.55022  \n  0.475008   1.46697     0.497403       0.141684   0.183218     0.122664 \n -0.408154  -0.325323    0.0850869     -0.2214    -0.575183     0.399583 \n  0.886626   0.487408   -0.0977307     -0.985545  -0.636874    -0.439825 \n -1.24394    0.213697    2.74965        1.39201    0.299931     0.392809 ,6670x0 Array{Float64,2},(\n6670x6670 Array{Float64,2}:\n  1.00583       0.00659955   -0.000232427  \u2026  -0.000129257  -0.00562459 \n  0.00659955    0.99784      -0.00403985       0.00181974    0.00691145 \n -0.000232427  -0.00403985    0.987264         0.00058913   -0.000699707\n  0.00186795   -0.00640781   -0.00372219      -0.00483365   -0.00254155 \n -0.000155086  -0.00721501    0.00362883       0.00427952   -0.00316764 \n  0.00400741    0.00115477    0.005091     \u2026   0.00188751   -3.65987e-6 \n  0.00111701    0.00482842   -0.00375641       0.00243399   -0.00247849 \n -0.00131899    0.00639975   -0.00202991       0.00707293   -0.00048186 \n -0.00205238   -0.00240896   -0.00110924       0.00351173    0.00363799 \n -0.00273677    0.00423992    0.000238256     -0.0029461    -0.00210478 \n -0.00412287    0.000297635  -0.000950353  \u2026  -0.000531045  -0.00212246 \n  0.00190203    0.00334083    0.0036709       -0.00140732   -0.00626668 \n  0.000660883  -0.00180829    0.00602955       0.00150954   -0.00254826 \n  \u22ee                                        \u22f1                            \n  0.00602273    0.00232083    0.00200852       1.33451e-5    0.00614137 \n -0.00428016    0.0054185    -0.00370108      -0.00219871    0.00733631 \n  0.00109348   -0.00485292   -0.00610528   \u2026  -0.00125803    0.00421559 \n -0.00845106   -0.00414261   -0.00218104      -0.00141161   -0.00101611 \n -0.00636811   -0.0015077     0.00624753       0.00105766   -7.21938e-5 \n  0.000860393  -0.00394326    0.0053709       -0.0126635    -0.0104067  \n  0.00442858    0.00169958   -0.00202223      -0.00188626   -0.00124884 \n -0.0045805    -0.000261196   0.000203706  \u2026   0.00168027   -0.00460447 \n -0.00405834    0.00466013   -0.00262013       0.00395595   -0.00102754 \n -0.00192981   -0.00174465   -0.000141344      0.00249404   -0.00591688 \n -0.000129257   0.00181974    0.00058913       1.00197       0.00105123 \n -0.00562459    0.00691145   -0.000699707      0.00105123    1.00158    ,\n\n6670x6670 Array{Float64,2}:\n 1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \u2026  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \u2026  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \u2026  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n \u22ee                        \u22ee              \u22f1            \u22ee                      \n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \u2026  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  1.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \u2026  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  1.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  1.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  1.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  1.0))\n\n\n\n\n\nBefore fitting the variance component model, we pre-compute the eigen-decomposition of $2\\Phi_{\\text{GRM}}$, the rotated responses, and the constant part in log-likelihood, and store them as a \nTwoVarCompVariateRotate\n instance, which is re-used in various variane component estimation procedures.\n\n\n# pre-compute eigen-decomposition (~50 secs on my laptop)\n\n\n@\ntime\n \ncg10kdata_rotated\n \n=\n \nTwoVarCompVariateRotate\n(\ncg10kdata\n)\n\n\nfieldnames\n(\ncg10kdata_rotated\n)\n\n\n\n\n\n\n 51.297311 seconds (957.07 k allocations: 1.038 GB, 0.32% gc time)\n\n\n\n\n\n4-element Array{Symbol,1}:\n :Yrot    \n :Xrot    \n :eigval  \n :logdetV2\n\n\n\n\n\n\n\nSave intermediate results\n\n\nWe don't want to re-compute SnpArray and empirical kinship matrices again and again for heritibility analysis.\n\n\n#using JLD\n\n\n#@save \ncg10k.jld\n\n\n#whos()\n\n\n\n\n\n\nTo load workspace\n\n\n#using SnpArrays, JLD, DataFrames, VarianceComponentModels, Plots\n\n\n#gr()\n\n\n#@load \ncg10k.jld\n\n\n#whos()\n\n\n\n\n\n\n\n\nHeritability of single traits\n\n\nWe use Fisher scoring algorithm to fit variance component model for each single trait.\n\n\n# heritability from single trait analysis\n\n\nhST\n \n=\n \nzeros\n(\n13\n)\n\n\n# standard errors of estimated heritability\n\n\nhST_se\n \n=\n \nzeros\n(\n13\n)\n\n\n# additive genetic effects\n\n\n\u03c32a\n \n=\n \nzeros\n(\n13\n)\n\n\n# enviromental effects\n\n\n\u03c32e\n \n=\n \nzeros\n(\n13\n)\n\n\n\n@\ntime\n \nfor\n \ntrait\n \nin\n \n1\n:\n13\n\n    \nprintln\n(\nnames\n(\ncg10k_trait\n)[\ntrait\n \n+\n \n2\n])\n\n    \n# form data set for trait j\n\n    \ntraitj_data\n \n=\n \nTwoVarCompVariateRotate\n(\ncg10kdata_rotated\n.\nYrot\n[:,\n \ntrait\n],\n \ncg10kdata_rotated\n.\nXrot\n,\n \n        \ncg10kdata_rotated\n.\neigval\n,\n \ncg10kdata_rotated\n.\nlogdetV2\n)\n\n    \n# initialize model parameters\n\n    \ntraitj_model\n \n=\n \nVarianceComponentModel\n(\ntraitj_data\n)\n\n    \n# estimate variance components\n\n    \n_\n,\n \n_\n,\n \n_\n,\n \n\u03a3cov\n,\n \n_\n,\n \n_\n \n=\n \nmle_fs!\n(\ntraitj_model\n,\n \ntraitj_data\n;\n \nsolver\n=\n:\nIpopt\n,\n \nverbose\n=\nfalse\n)\n\n    \n\u03c32a\n[\ntrait\n]\n \n=\n \ntraitj_model\n.\n\u03a3\n[\n1\n][\n1\n]\n\n    \n\u03c32e\n[\ntrait\n]\n \n=\n \ntraitj_model\n.\n\u03a3\n[\n2\n][\n1\n]\n\n    \n@\nshow\n \n\u03c32a\n[\ntrait\n],\n \n\u03c32e\n[\ntrait\n]\n\n    \nh\n,\n \nhse\n \n=\n \nheritability\n(\ntraitj_model\n.\n\u03a3\n,\n \n\u03a3cov\n)\n\n    \nhST\n[\ntrait\n]\n \n=\n \nh\n[\n1\n]\n\n    \nhST_se\n[\ntrait\n]\n \n=\n \nhse\n[\n1\n]\n\n\nend\n\n\n\n\n\n\nTrait1\n\n******************************************************************************\nThis program contains Ipopt, a library for large-scale nonlinear optimization.\n Ipopt is released as open source code under the Eclipse Public License (EPL).\n         For more information visit http://projects.coin-or.org/Ipopt\n******************************************************************************\n\n(\u03c32a[trait],\u03c32e[trait]) = (0.26104123222538084,0.735688443211474)\nTrait2\n(\u03c32a[trait],\u03c32e[trait]) = (0.18874147373002487,0.8106899992330557)\nTrait3\n(\u03c32a[trait],\u03c32e[trait]) = (0.318571927651206,0.6801458862910434)\nTrait4\n(\u03c32a[trait],\u03c32e[trait]) = (0.26556901335366295,0.730358836480852)\nTrait5\n(\u03c32a[trait],\u03c32e[trait]) = (0.28123321199488277,0.7167989046615363)\nTrait6\n(\u03c32a[trait],\u03c32e[trait]) = (0.2829461159340443,0.7165629525047605)\nTrait7\n(\u03c32a[trait],\u03c32e[trait]) = (0.21543856399750066,0.7816211121996341)\nTrait8\n(\u03c32a[trait],\u03c32e[trait]) = (0.19412648726333176,0.805527765060679)\nTrait9\n(\u03c32a[trait],\u03c32e[trait]) = (0.24789561129713544,0.7504615853385027)\nTrait10\n(\u03c32a[trait],\u03c32e[trait]) = (0.100074557877669,0.8998152776356187)\nTrait11\n(\u03c32a[trait],\u03c32e[trait]) = (0.16486778143457112,0.8338002259854702)\nTrait12\n(\u03c32a[trait],\u03c32e[trait]) = (0.0829866038383105,0.9158035671624248)\nTrait13\n(\u03c32a[trait],\u03c32e[trait]) = (0.056842480167674306,0.9423653389084629)\n  5.952183 seconds (49.17 M allocations: 1.102 GB, 5.89% gc time)\n\n\n\n\n\n# heritability and standard errors\n\n\n[\nhST\n;\n \nhST_se\n]\n\n\n\n\n\n\n2x13 Array{Float64,2}:\n 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n\n\n\n\n\n\n\nPairwise traits\n\n\nFollowing code snippet calculates joint heritability among all pairs of traits, a total of 78 bivariate variane component models.\n\n\n# additive genetic effects (2x2 psd matrices) from bavariate trait analysis;\n\n\n\u03a3a\n \n=\n \nArray\n{\nMatrix\n{\nFloat64\n}}(\n13\n,\n \n13\n)\n\n\n# environmental effects (2x2 psd matrices) from bavariate trait analysis;\n\n\n\u03a3e\n \n=\n \nArray\n{\nMatrix\n{\nFloat64\n}}(\n13\n,\n \n13\n)\n\n\n\n@\ntime\n \nfor\n \ni\n \nin\n \n1\n:\n13\n\n    \nfor\n \nj\n \nin\n \n(\ni\n+\n1\n):\n13\n\n        \nprintln\n(\nnames\n(\ncg10k_trait\n)[\ni\n \n+\n \n2\n],\n \nnames\n(\ncg10k_trait\n)[\nj\n \n+\n \n2\n])\n\n        \n# form data set for (trait1, trait2)\n\n        \ntraitij_data\n \n=\n \nTwoVarCompVariateRotate\n(\ncg10kdata_rotated\n.\nYrot\n[:,\n \n[\ni\n;\nj\n]],\n \ncg10kdata_rotated\n.\nXrot\n,\n \n            \ncg10kdata_rotated\n.\neigval\n,\n \ncg10kdata_rotated\n.\nlogdetV2\n)\n\n        \n# initialize model parameters\n\n        \ntraitij_model\n \n=\n \nVarianceComponentModel\n(\ntraitij_data\n)\n\n        \n# estimate variance components\n\n        \nmle_fs!\n(\ntraitij_model\n,\n \ntraitij_data\n;\n \nsolver\n=\n:\nIpopt\n,\n \nverbose\n=\nfalse\n)\n\n        \n\u03a3a\n[\ni\n,\n \nj\n]\n \n=\n \ntraitij_model\n.\n\u03a3\n[\n1\n]\n\n        \n\u03a3e\n[\ni\n,\n \nj\n]\n \n=\n \ntraitij_model\n.\n\u03a3\n[\n2\n]\n\n        \n@\nshow\n \n\u03a3a\n[\ni\n,\n \nj\n],\n \n\u03a3e\n[\ni\n,\n \nj\n]\n\n    \nend\n\n\nend\n\n\n\n\n\n\nTrait1Trait2\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26011943486815303 0.1762158250641666\n 0.1762158250641666 0.18737615484318682],\n\n[0.7365894055240527 0.5838920954583557\n 0.5838920954583557 0.8120331390255984])\nTrait1Trait3\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2615639935568583 -0.013126818536804538\n -0.013126818536804538 0.3190566225477499],\n\n[0.7351802111593627 -0.12112674834322068\n -0.12112674834322068 0.6796789899239241])\nTrait1Trait4\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26087960315961645 0.2226144055987542\n 0.2226144055987542 0.26558083276300853],\n\n[0.735845998164204 0.5994353345857374\n 0.5994353345857374 0.7303474474479689])\nTrait1Trait5\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26078303770342093 -0.14701178378027208\n -0.14701178378027208 0.2818772454637467],\n\n[0.7359373011280201 -0.2545838905575993\n -0.2545838905575993 0.7161761242026842])\nTrait1Trait6\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26070703552005153 -0.1293564259272152\n -0.1293564259272152 0.28318838486326464],\n\n[0.7360128807191256 -0.23136128330673647\n -0.23136128330673647 0.7163294323420235])\nTrait1Trait7\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26030750074865355 -0.1402575370658552\n -0.1402575370658552 0.2150805562437876],\n\n[0.736405599875614 -0.19780547644886934\n -0.19780547644886934 0.7819851899273343])\nTrait1Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2610345999109415 -0.033529628072184174\n -0.033529628072184174 0.1941430731435061],\n\n[0.7356949687052194 -0.12627246367045894\n -0.12627246367045894 0.8055115370752971])\nTrait1Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26301631599826725 -0.20486492716403212\n -0.20486492716403212 0.24679565235839057],\n\n[0.733794462308188 -0.30745013667457605\n -0.30745013667457605 0.7515442213436087])\nTrait1Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26089807908154783 -0.09981756181315272\n -0.09981756181315272 0.0970232854366607],\n\n[0.7358279769596973 -0.3036087596209461\n -0.3036087596209461 0.902853465186668])\nTrait1Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2607397076720635 -0.1389834153966234\n -0.1389834153966234 0.16306263185657766],\n\n[0.7359820027777678 -0.3591745321509024\n -0.3591745321509024 0.8355950431882248])\nTrait1Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26306860004688026 -0.14553554987243783\n -0.14553554987243783 0.08051358652010815],\n\n[0.7337809604103112 -0.04169750224640395\n -0.04169750224640395 0.9183594400218908])\nTrait1Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26234367608192977 -0.10889551713434968\n -0.10889551713434968 0.0512940383653612],\n\n[0.7344496461752492 -0.11399558207532524\n -0.11399558207532524 0.9479424007586392])\nTrait2Trait3\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18901532602954713 0.14615743011868396\n 0.14615743011868396 0.32052865893932325],\n\n[0.8104184413491479 0.09749923852720849\n 0.09749923852720849 0.6782713240476694])\nTrait2Trait4\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.1883951499036305 0.07521464811301082\n 0.07521464811301082 0.26555848041382424],\n\n[0.8110301028366897 0.22049483157599306\n 0.22049483157599306 0.7303691342557705])\nTrait2Trait5\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18871644002070298 -0.011314018224773681\n -0.011314018224773681 0.2812465335272833],\n\n[0.8107145247899494 -0.03701047017353238\n -0.03701047017353238 0.7167859986683998])\nTrait2Trait6\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.1887737598357356 -0.003106603698693131\n -0.003106603698693131 0.28301251325921034],\n\n[0.8106583657770059 -0.021182656859616053\n -0.021182656859616053 0.7164985874165493])\nTrait2Trait7\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.1883522257152029 -0.02995792853329811\n -0.02995792853329811 0.21518854249006697],\n\n[0.8110719442645782 -0.00136938653417689\n -0.00136938653417689 0.7818678818050632])\nTrait2Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18926168900224644 0.033142298438513934\n 0.033142298438513934 0.19466629556574452],\n\n[0.8101822287413256 -0.03260027070436449\n -0.03260027070436449 0.8050045055360936])\nTrait2Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.1872848956280239 -0.08541458777076169\n -0.08541458777076169 0.24671880340715757],\n\n[0.8121330455990424 -0.08087908481224644\n -0.08087908481224644 0.7516171286963302])\nTrait2Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.1889645629678981 -0.12531880400449946\n -0.12531880400449946 0.10012137188898965],\n\n[0.8104983819152255 -0.2710710218717953\n -0.2710710218717953 0.8998490679544218])\nTrait2Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18776200371995733 -0.11847920330746468\n -0.11847920330746468 0.16627341912957957],\n\n[0.8116528153514335 -0.29554899494751774\n -0.29554899494751774 0.8324372717265173])\nTrait2Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18819063520893153 -0.09053833116231333\n -0.09053833116231333 0.08226341390714831],\n\n[0.8112716597628467 0.04542203421221531\n 0.04542203421221531 0.9165863321400829])\nTrait2Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18826030571365 -0.07070412373503615\n -0.07070412373503615 0.05472389418108183],\n\n[0.8112166105461245 0.07379770159309924\n 0.07379770159309924 0.9445208397201135])\nTrait3Trait4\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.31852039540025556 -0.15433893723722844\n -0.15433893723722844 0.26475409905630554],\n\n[0.6801958865832615 -0.3034399519741299\n -0.3034399519741299 0.731151851539042])\nTrait3Trait5\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.31896997787115844 0.1843544667615588\n 0.1843544667615588 0.2825001772391643],\n\n[0.6797599597904634 0.3364105248325953\n 0.3364105248325953 0.7155665412290728])\nTrait3Trait6\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.3195663644223704 0.16663988772541583\n 0.16663988772541583 0.2850313182313418],\n\n[0.6791832508340369 0.2976976595424014\n 0.2976976595424014 0.7145358499994827])\nTrait3Trait7\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.3185755051463484 0.16685216000557962\n 0.16685216000557962 0.21523224226058452],\n\n[0.6801424314852816 0.3471388423837074\n 0.3471388423837074 0.781823130994699])\nTrait3Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.32049923480743736 0.05753194037721402\n 0.05753194037721402 0.19724489854138733],\n\n[0.6782830498088369 0.04425974188401513\n 0.04425974188401513 0.802473783266528])\nTrait3Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.31871912001262215 0.13729240537832613\n 0.13729240537832613 0.24697586633940616],\n\n[0.6800039145595509 0.2671054378272429\n 0.2671054378272429 0.7513573840671314])\nTrait3Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.3189152132179772 -0.0786338234436915\n -0.0786338234436915 0.10110317193796312],\n\n[0.679814558884657 -0.14078871656902353\n -0.14078871656902353 0.8987982713072635])\nTrait3Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.3178223304600456 -0.01798395917145184\n -0.01798395917145184 0.16474292116632128],\n\n[0.6808712744789884 -0.11416573111718417\n -0.11416573111718417 0.8339228729000641])\nTrait3Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.3208883401716964 0.08452483760009306\n 0.08452483760009306 0.0869867503171365],\n\n[0.6779139477279349 0.0340132717811355\n 0.0340132717811355 0.9118411342532936])\nTrait3Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.32300879330585164 0.11068106826965814\n 0.11068106826965814 0.06117389943402113],\n\n[0.6759011385390731 -0.007296623864558913\n -0.007296623864558913 0.9380722549857157])\nTrait4Trait5\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26566699036169605 -0.2158475608286269\n -0.2158475608286269 0.28291866201101923],\n\n[0.7302544030223196 -0.376675282891704\n -0.376675282891704 0.7151643527045644])\nTrait4Trait6\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26614305300873853 -0.20063378204267554\n -0.20063378204267554 0.2844419499822279],\n\n[0.7297943215353132 -0.3468040727719556\n -0.3468040727719556 0.7151119490174423])\nTrait4Trait7\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2644898029398779 -0.18275157344131776\n -0.18275157344131776 0.2141168002388134],\n\n[0.7314145610167773 -0.3261719955266139\n -0.3261719955266139 0.7829351279927492])\nTrait4Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26669395421675546 -0.09763540115429367\n -0.09763540115429367 0.1961260872033616],\n\n[0.7292655955847159 -0.15036048225408044\n -0.15036048225408044 0.8035709853965969])\nTrait4Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.27003652025292474 -0.22740698731918993\n -0.22740698731918993 0.2480458221785815],\n\n[0.7260245141067312 -0.4156014356566848\n -0.4156014356566848 0.7502976667276586])\nTrait4Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2655429418281044 -0.03381072154126782\n -0.03381072154126782 0.0996098263599129],\n\n[0.7303952879665676 -0.22772490049078267\n -0.22772490049078267 0.9002752447772486])\nTrait4Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2656276022067445 -0.0967400332453423\n -0.0967400332453423 0.16327409086062875],\n\n[0.7303019079378218 -0.2726111957424877\n -0.2726111957424877 0.8353713025165547])\nTrait4Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26816369655143846 -0.14161261171741682\n -0.14161261171741682 0.08039677346947334],\n\n[0.7278825933041443 -0.08284654589719648\n -0.08284654589719648 0.9184455609265872])\nTrait4Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26617123205334886 -0.09807308729740324\n -0.09807308729740324 0.05401019174697443],\n\n[0.7297749332697795 -0.22505950767079727\n -0.22505950767079727 0.9452044744732253])\nTrait5Trait6\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2815916529117581 0.28089837189876277\n 0.28089837189876277 0.2822980504457378],\n\n[0.7164553609388885 0.6603676496624155\n 0.6603676496624155 0.7171950644786848])\nTrait5Trait7\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28081437389685465 0.2320998689028785\n 0.2320998689028785 0.21166204276578496],\n\n[0.7172180317128432 0.6743038172539134\n 0.6743038172539134 0.7853426270933965])\nTrait5Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28134012176547224 0.16394787427644833\n 0.16394787427644833 0.19270331039789454],\n\n[0.716700910916717 0.22103210912788746\n 0.22103210912788746 0.8069220956459742])\nTrait5Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2838778024864278 0.24453172568336923\n 0.24453172568336923 0.24129303734496713],\n\n[0.7142441395374184 0.5084169870279653\n 0.5084169870279653 0.75689423383449])\nTrait5Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2818130149579839 -0.04621141466318818\n -0.04621141466318818 0.10148069053702076],\n\n[0.7162383352810132 -0.05721113478873817\n -0.05721113478873817 0.8984242888549007])\nTrait5Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28042354198276 0.020249545578616107\n 0.020249545578616107 0.16400332024863942],\n\n[0.7175856258522051 -0.03524364742481622\n -0.03524364742481622 0.8346493308274309])\nTrait5Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28142706977067977 0.0616130662199462\n 0.0616130662199462 0.08271662802494333],\n\n[0.7166145561763498 0.05292864493625416\n 0.05292864493625416 0.9160739286144334])\nTrait5Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2822915336770548 0.07042205168959345\n 0.07042205168959345 0.05694630997371182],\n\n[0.7157823114671132 0.05283744551208099\n 0.05283744551208099 0.9422684292501169])\nTrait6Trait7\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28296107605405046 0.22065632106005845\n 0.22065632106005845 0.2138560977045212],\n\n[0.7165486719516274 0.5810829183804748\n 0.5810829183804748 0.7831785715682008])\nTrait6Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2829606227323868 0.18407962647041584\n 0.18407962647041584 0.19237902250043631],\n\n[0.7165491133456647 0.4365973893626811\n 0.4365973893626811 0.8072460050916037])\nTrait6Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2849784406224258 0.23443573773563228\n 0.23443573773563228 0.24320710809890078],\n\n[0.7146005305248684 0.4768263391920377\n 0.4768263391920377 0.7550279957443258])\nTrait6Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28365475689742714 -0.043548481043600644\n -0.043548481043600644 0.10202532158188515],\n\n[0.7158768651026055 -0.05916812562687212\n -0.05916812562687212 0.8978859540367762])\nTrait6Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2815224136591653 0.027999198497497716\n 0.027999198497497716 0.16342991310189497],\n\n[0.7179464769862334 -0.05241060710393953\n -0.05241060710393953 0.8352130875902175])\nTrait6Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28311434441170164 0.05713989944414399\n 0.05713989944414399 0.0826789313035068],\n\n[0.7164030333437527 0.04791987131194029\n 0.04791987131194029 0.9161120298125991])\nTrait6Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2838199671572152 0.06112120329707695\n 0.06112120329707695 0.057081689708499625],\n\n[0.7157217792743793 0.0532698347458057\n 0.0532698347458057 0.9421333545367362])\nTrait7Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2138568636062993 0.08845552117563456\n 0.08845552117563456 0.19237305507185362],\n\n[0.7831777634587772 -0.056833059546840724\n -0.056833059546840724 0.8072518674868492])\nTrait7Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2187556960318311 0.21704186383319593\n 0.21704186383319593 0.24414386504096938],\n\n[0.7784327750408729 0.4629009682465131\n 0.4629009682465131 0.7541229287887962])\nTrait7Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.21627296245459482 -0.042114572555895034\n -0.042114572555895034 0.10209048393905551],\n\n[0.7808073891153632 -0.0859074527248701\n -0.0859074527248701 0.8978220136433211])\nTrait7Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.214068776570261 0.020696687537510253\n 0.020696687537510253 0.16347380945463358],\n\n[0.7829608191256512 -0.04814801124193434\n -0.04814801124193434 0.8351704867201007])\nTrait7Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.21493232507095117 0.07578743223256132\n 0.07578743223256132 0.08087309077615555],\n\n[0.7821316768241421 0.03469555448086824\n 0.03469555448086824 0.9179149818382321])\nTrait7Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.21595864338688792 0.07493726652193226\n 0.07493726652193226 0.054593411293268314],\n\n[0.7811387334966593 0.038905793654869604\n 0.038905793654869604 0.9446215737969718])\nTrait8Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.1945549993508713 0.11281615771703897\n 0.11281615771703897 0.247244151913094],\n\n[0.8051240570328738 0.18477843242872458\n 0.18477843242872458 0.7510982278178284])\nTrait8Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.1944410026133888 -0.015634153645910635\n -0.015634153645910635 0.10042647889553495],\n\n[0.8052215712374999 0.011982589675582881\n 0.011982589675582881 0.8994678453427947])\nTrait8Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.19385316433932662 0.02253246401737779\n 0.02253246401737779 0.16466854383170343],\n\n[0.8057962945707323 -0.027274736865623306\n -0.027274736865623306 0.833996968298484])\nTrait8Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.19395121849388605 -0.00287601218605317\n -0.00287601218605317 0.08285727476214352],\n\n[0.805699796364685 0.03361278792998698\n 0.03361278792998698 0.9159318672850477])\nTrait8Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.19397976155591182 0.004078666572513058\n 0.004078666572513058 0.056907123220398724],\n\n[0.8056716012385241 0.037881707520808355\n 0.037881707520808355 0.9423010776521313])\nTrait9Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.24729383232846244 -0.0023083632339188282\n -0.0023083632339188282 0.09982638783604271],\n\n[0.7510505981827851 0.07407294366362593\n 0.07407294366362593 0.9000613327580784])\nTrait9Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.24782344372399562 0.03182350298547301\n 0.03182350298547301 0.16489046411211802],\n\n[0.7505321390729256 0.15228537870520292\n 0.15228537870520292 0.8337779553469964])\nTrait9Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2503346951480958 0.08457136153453912\n 0.08457136153453912 0.08875872341182169],\n\n[0.7480909649325541 0.1077563215164905\n 0.1077563215164905 0.910108091340272])\nTrait9Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.24944189418695698 0.09348451303646096\n 0.09348451303646096 0.05793201495098822],\n\n[0.7489745640198023 0.09821909823020973\n 0.09821909823020973 0.9413348855377766])\nTrait10Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.09313966828035954 0.10003371877497542\n 0.10003371877497542 0.16495492788508725],\n\n[0.9067034447680414 0.47442665936453843\n 0.47442665936453843 0.8337151519497663])\nTrait10Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.09672471644137419 0.05640434659676373\n 0.05640434659676373 0.07945282707687533],\n\n[0.9031497841187028 0.08532319187509019\n 0.08532319187509019 0.91933434342665])\nTrait10Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.10098492172122948 -0.027991587710857326\n -0.027991587710857326 0.05783694113832583],\n\n[0.8989368215833939 0.16605077488640077\n 0.16605077488640077 0.9413901799217301])\nTrait11Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.16384057742661823 0.05703178017251179\n 0.05703178017251179 0.07921436807844635],\n\n[0.8348140972530623 0.14559650973720015\n 0.14559650973720015 0.9195521322043868])\nTrait11Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.16488293337335094 -0.0015841372093299245\n -0.0015841372093299245 0.05749684375147145],\n\n[0.8337979488908841 0.2006122283482765\n 0.2006122283482765 0.9417152320985648])\nTrait12Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.08314058460338657 -0.30414162669938277\n -0.30414162669938277 6.1516805202088326e7],\n\n[0.9156535422859348 0.20300255194828656\n 0.20300255194828656 7.289623734162273e9])\n 73.287758 seconds (3.33 G allocations: 50.885 GB, 10.69% gc time)\n\n\n\n\n\n\n\n5-trait analysis\n\n\nResearchers want to jointly analyze traits 5-9. Our strategy is to try both Fisher scoring and MM algorithm with different starting point, and choose the best local optimum. We first form the data set and run Fisher scoring, which yields a final objective value 8.6836898e+03.\n\n\ntraitidx\n \n=\n \n5\n:\n9\n\n\n# form data set\n\n\ntrait59_data\n \n=\n \nTwoVarCompVariateRotate\n(\ncg10kdata_rotated\n.\nYrot\n[:,\n \ntraitidx\n],\n \ncg10kdata_rotated\n.\nXrot\n,\n \n    \ncg10kdata_rotated\n.\neigval\n,\n \ncg10kdata_rotated\n.\nlogdetV2\n)\n\n\n# initialize model parameters\n\n\ntrait59_model\n \n=\n \nVarianceComponentModel\n(\ntrait59_data\n)\n\n\n# estimate variance components\n\n\n@\ntime\n \nmle_fs!\n(\ntrait59_model\n,\n \ntrait59_data\n;\n \nsolver\n=\n:\nKnitro\n,\n \nverbose\n=\ntrue\n)\n\n\ntrait59_model\n\n\n\n\n\n\nKnitro\n \n10\n.1.0\n \nSTUDENT\n \nLICENSE\n \n(\nproblem\n \nsize\n \nlimit\n \n=\n \n300\n)\n\n\n\n=======================================\n\n            \nStudent\n \nLicense\n\n       \n(\nNOT\n \nFOR\n \nCOMMERCIAL\n \nUSE\n)\n\n         \nArtelys\n \nKnitro\n \n10\n.1.0\n\n\n=======================================\n\n\n\nKnitro\n \npresolve\n \neliminated\n \n0\n \nvariables\n \nand\n \n0\n \nconstraints\n.\n\n\n\nalgorithm\n:\n            \n1\n\n\nThe\n \nproblem\n \nis\n \nidentified\n \nas\n \nbound\n \nconstrained\n \nonly\n.\n\n\nKnitro\n \nchanging\n \nbar_initpt\n \nfrom\n \nAUTO\n \nto\n \n3\n.\n\n\nKnitro\n \nchanging\n \nbar_murule\n \nfrom\n \nAUTO\n \nto\n \n4\n.\n\n\nKnitro\n \nchanging\n \nbar_penaltycons\n \nfrom\n \nAUTO\n \nto\n \n1\n.\n\n\nKnitro\n \nchanging\n \nbar_penaltyrule\n \nfrom\n \nAUTO\n \nto\n \n2\n.\n\n\nKnitro\n \nchanging\n \nbar_switchrule\n \nfrom\n \nAUTO\n \nto\n \n1\n.\n\n\nKnitro\n \nchanging\n \nlinsolver\n \nfrom\n \nAUTO\n \nto\n \n2\n.\n\n\n\nProblem\n \nCharacteristics\n                    \n(\n \nPresolved\n)\n\n\n-----------------------\n\n\nObjective\n \ngoal\n:\n  \nMaximize\n\n\nNumber\n \nof\n \nvariables\n:\n                    \n30\n \n(\n        \n30\n)\n\n    \nbounded\n \nbelow\n:\n                      \n10\n \n(\n        \n10\n)\n\n    \nbounded\n \nabove\n:\n                       \n0\n \n(\n         \n0\n)\n\n    \nbounded\n \nbelow\n \nand\n \nabove\n:\n             \n0\n \n(\n         \n0\n)\n\n    \nfixed\n:\n                               \n0\n \n(\n         \n0\n)\n\n    \nfree\n:\n                               \n20\n \n(\n        \n20\n)\n\n\nNumber\n \nof\n \nconstraints\n:\n                   \n0\n \n(\n         \n0\n)\n\n    \nlinear\n \nequalities\n:\n                   \n0\n \n(\n         \n0\n)\n\n    \nnonlinear\n \nequalities\n:\n                \n0\n \n(\n         \n0\n)\n\n    \nlinear\n \ninequalities\n:\n                 \n0\n \n(\n         \n0\n)\n\n    \nnonlinear\n \ninequalities\n:\n              \n0\n \n(\n         \n0\n)\n\n    \nrange\n:\n                               \n0\n \n(\n         \n0\n)\n\n\nNumber\n \nof\n \nnonzeros\n \nin\n \nJacobian\n:\n          \n0\n \n(\n         \n0\n)\n\n\nNumber\n \nof\n \nnonzeros\n \nin\n \nHessian\n:\n         \n465\n \n(\n       \n465\n)\n\n\n  \nIter\n      \nObjective\n      \nFeasError\n   \nOptError\n    \n||\nStep\n||\n    \nCGits\n \n\n--------\n  \n--------------\n  \n----------\n  \n----------\n  \n----------\n  \n-------\n\n       \n0\n   \n-5\n.042149e\n+\n04\n   \n0\n.000e\n+\n00\n\n      \n10\n   \n-1\n.677917e\n+\n04\n   \n0\n.000e\n+\n00\n   \n1\n.102e\n+\n03\n   \n8\n.413e-02\n        \n0\n\n      \n20\n   \n-1\n.531001e\n+\n03\n   \n0\n.000e\n+\n00\n   \n1\n.489e\n+\n04\n   \n2\n.670e-03\n        \n0\n\n      \n30\n    \n8\n.342379e\n+\n03\n   \n0\n.000e\n+\n00\n   \n8\n.574e\n+\n03\n   \n4\n.155e-04\n        \n7\n\n      \n40\n    \n8\n.638819e\n+\n03\n   \n0\n.000e\n+\n00\n   \n3\n.597e\n+\n03\n   \n7\n.576e-05\n       \n63\n\n      \n50\n    \n8\n.673858e\n+\n03\n   \n0\n.000e\n+\n00\n   \n3\n.459e\n+\n03\n   \n1\n.426e-04\n        \n5\n\n      \n60\n    \n8\n.683483e\n+\n03\n   \n0\n.000e\n+\n00\n   \n5\n.619e\n+\n02\n   \n4\n.284e-06\n        \n5\n\n      \n70\n    \n8\n.683690e\n+\n03\n   \n0\n.000e\n+\n00\n   \n4\n.927e\n+\n02\n   \n1\n.183e-08\n        \n8\n\n      \n78\n    \n8\n.683690e\n+\n03\n   \n0\n.000e\n+\n00\n   \n4\n.927e\n+\n02\n   \n9\n.036e-17\n       \n12\n\n\n\nEXIT\n:\n \nPrimal\n \nfeasible\n \nsolution\n;\n \nterminate\n \nbecause\n \nthe\n \nrelative\n \nchange\n \nin\n\n      \nsolution\n \nestimate\n \n \nxtol\n.\n\n\n\nFinal\n \nStatistics\n\n\n----------------\n\n\nFinal\n \nobjective\n \nvalue\n               \n=\n   \n8\n.68368980794010e\n+\n03\n\n\nFinal\n \nfeasibility\n \nerror\n \n(\nabs\n \n/\n \nrel\n)\n \n=\n   \n0\n.00e\n+\n00\n \n/\n \n0\n.00e\n+\n00\n\n\nFinal\n \noptimality\n \nerror\n  \n(\nabs\n \n/\n \nrel\n)\n \n=\n   \n4\n.93e\n+\n02\n \n/\n \n1\n.00e\n+\n00\n\n\n#\n \nof\n \niterations\n                     \n=\n         \n78\n \n\n#\n \nof\n \nCG\n \niterations\n                  \n=\n        \n742\n \n\n#\n \nof\n \nfunction\n \nevaluations\n           \n=\n        \n420\n\n\n#\n \nof\n \ngradient\n \nevaluations\n           \n=\n         \n79\n\n\n#\n \nof\n \nHessian\n \nevaluations\n            \n=\n         \n76\n\n\nTotal\n \nprogram\n \ntime\n \n(\nsecs\n)\n           \n=\n       \n8\n.49573\n \n(\n     \n8\n.460\n \nCPU\n \ntime\n)\n\n\nTime\n \nspent\n \nin\n \nevaluations\n \n(\nsecs\n)\n    \n=\n       \n8\n.47474\n\n\n\n===============================================================================\n\n\n  \n8\n.877926\n \nseconds\n \n(\n398\n.54\n \nM\n \nallocations\n:\n \n6\n.096\n \nGB\n,\n \n15\n.25\n%\n \ngc\n \ntime\n)\n\n\n\n\n###\n \nCould\n \nnot\n \nfind\n \na\n \nvalid\n \nlicense\n.\n\n    \nYour\n \nmachine\n \nID\n \nis\n \ne2-9d-cc-64-5f\n.\n\n    \nPlease\n \ncontact\n \nlicensing\n@artelys\n.com\n \nor\n \nyour\n \nlocal\n \ndistributor\n \nto\n \nobtain\n \na\n \nlicense\n.\n\n    \nIf\n \nyou\n \nalready\n \nhave\n \na\n \nlicense\n,\n \nplease\n \nexecute\n \n`\nget_machine_ID\n \n-v\n`\n \nand\n \nsend\n \nthe\n \noutput\n \nto\n \nsupport\n.\n\n\n\n\n\n\n\nVarianceComponentModels\n.VarianceComponentModel\n{\nFloat64\n,\n2\n,\nArray\n{\nFloat64\n,\n2\n}\n,\nArray\n{\nFloat64\n,\n2\n}}\n(\n0x5\n \nArray\n{\nFloat64\n,\n2\n}\n,(\n\n\n5x5\n \nArray\n{\nFloat64\n,\n2\n}\n:\n\n \n0\n.31512\n   \n0\n.319157\n  \n0\n.250341\n  \n0\n.204466\n  \n0\n.24944\n \n \n0\n.319157\n  \n0\n.329653\n  \n0\n.241834\n  \n0\n.233293\n  \n0\n.247452\n\n \n0\n.250341\n  \n0\n.241834\n  \n0\n.221271\n  \n0\n.113265\n  \n0\n.208544\n\n \n0\n.204466\n  \n0\n.233293\n  \n0\n.113265\n  \n0\n.241484\n  \n0\n.139501\n\n \n0\n.24944\n   \n0\n.247452\n  \n0\n.208544\n  \n0\n.139501\n  \n0\n.376927\n,\n\n\n\n5x5\n \nArray\n{\nFloat64\n,\n2\n}\n:\n\n \n0\n.688825\n  \n0\n.632998\n   \n0\n.657586\n    \n0\n.196702\n   \n0\n.528705\n\n \n0\n.632998\n  \n0\n.685078\n   \n0\n.56295\n     \n0\n.408814\n   \n0\n.507746\n\n \n0\n.657586\n  \n0\n.56295\n    \n0\n.775116\n   \n-0\n.0757512\n  \n0\n.501867\n\n \n0\n.196702\n  \n0\n.408814\n  \n-0\n.0757512\n   \n0\n.78627\n    \n0\n.191494\n\n \n0\n.528705\n  \n0\n.507746\n   \n0\n.501867\n    \n0\n.191494\n   \n0\n.756279\n),\n0x0\n \nArray\n{\nFloat64\n,\n2\n}\n,\nChar\n[]\n,\nFloat64\n[]\n,\n-Inf\n,\nInf\n)\n\n\n\n\n\n\nWe then run the MM algorithm, starting from the Fisher scoring answer. MM finds an improved solution with objective value 8.955397e+03.\n\n\n# trait59_model contains the fitted model by Fisher scoring now\n\n\n@\ntime\n \nmle_mm!\n(\ntrait59_model\n,\n \ntrait59_data\n;\n \nverbose\n=\ntrue\n)\n\n\ntrait59_model\n\n\n\n\n\n\n     MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0   8.683690e+03\n       1   8.749335e+03\n       2   8.769373e+03\n       3   8.775609e+03\n       4   8.777713e+03\n       5   8.778568e+03\n       6   8.779034e+03\n       7   8.779373e+03\n       8   8.779666e+03\n       9   8.779940e+03\n      10   8.780204e+03\n      20   8.782575e+03\n      30   8.784706e+03\n      40   8.786833e+03\n      50   8.789198e+03\n      60   8.792077e+03\n      70   8.795815e+03\n      80   8.800822e+03\n      90   8.807545e+03\n     100   8.816372e+03\n     110   8.827478e+03\n     120   8.840646e+03\n     130   8.855183e+03\n     140   8.870054e+03\n     150   8.884191e+03\n     160   8.896801e+03\n     170   8.907505e+03\n     180   8.916279e+03\n     190   8.923318e+03\n     200   8.928908e+03\n     210   8.933336e+03\n     220   8.936854e+03\n     230   8.939668e+03\n     240   8.941938e+03\n     250   8.943788e+03\n     260   8.945309e+03\n     270   8.946573e+03\n     280   8.947632e+03\n     290   8.948528e+03\n     300   8.949292e+03\n     310   8.949948e+03\n     320   8.950516e+03\n     330   8.951009e+03\n     340   8.951441e+03\n     350   8.951820e+03\n     360   8.952155e+03\n     370   8.952453e+03\n     380   8.952717e+03\n     390   8.952954e+03\n     400   8.953165e+03\n     410   8.953356e+03\n     420   8.953527e+03\n     430   8.953682e+03\n     440   8.953823e+03\n     450   8.953950e+03\n     460   8.954066e+03\n     470   8.954171e+03\n     480   8.954267e+03\n     490   8.954355e+03\n     500   8.954435e+03\n     510   8.954509e+03\n     520   8.954576e+03\n     530   8.954638e+03\n     540   8.954695e+03\n     550   8.954748e+03\n     560   8.954796e+03\n     570   8.954841e+03\n     580   8.954882e+03\n     590   8.954920e+03\n     600   8.954955e+03\n     610   8.954987e+03\n     620   8.955017e+03\n     630   8.955045e+03\n     640   8.955071e+03\n     650   8.955094e+03\n     660   8.955117e+03\n     670   8.955137e+03\n     680   8.955156e+03\n     690   8.955174e+03\n     700   8.955190e+03\n     710   8.955205e+03\n     720   8.955219e+03\n     730   8.955233e+03\n     740   8.955245e+03\n     750   8.955256e+03\n     760   8.955267e+03\n     770   8.955276e+03\n     780   8.955286e+03\n     790   8.955294e+03\n     800   8.955302e+03\n     810   8.955309e+03\n     820   8.955316e+03\n     830   8.955323e+03\n     840   8.955329e+03\n     850   8.955334e+03\n     860   8.955339e+03\n     870   8.955344e+03\n     880   8.955349e+03\n     890   8.955353e+03\n     900   8.955357e+03\n     910   8.955360e+03\n     920   8.955364e+03\n     930   8.955367e+03\n     940   8.955370e+03\n     950   8.955372e+03\n     960   8.955375e+03\n     970   8.955377e+03\n     980   8.955380e+03\n     990   8.955382e+03\n    1000   8.955384e+03\n    1010   8.955385e+03\n    1020   8.955387e+03\n    1030   8.955389e+03\n    1040   8.955390e+03\n    1050   8.955391e+03\n    1060   8.955393e+03\n    1070   8.955394e+03\n    1080   8.955395e+03\n    1090   8.955396e+03\n    1100   8.955397e+03\n\n 10.940231 seconds (375.19 M allocations: 9.267 GB, 19.34% gc time)\n\n\n\n\n\nVarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(0x5 Array{Float64,2},(\n5x5 Array{Float64,2}:\n 0.261514  0.273061  0.22074    0.167275   0.216444\n 0.273061  0.290848  0.219592   0.198638   0.218758\n 0.22074   0.219592  0.207146   0.0954691  0.19478 \n 0.167275  0.198638  0.0954691  0.207501   0.110312\n 0.216444  0.218758  0.19478    0.110312   0.216043,\n\n5x5 Array{Float64,2}:\n 0.735836  0.667979   0.685261    0.21787    0.535609\n 0.667979  0.708913   0.582131    0.42248    0.492028\n 0.685261  0.582131   0.789681   -0.0636001  0.484483\n 0.21787   0.42248   -0.0636001   0.792537   0.187238\n 0.535609  0.492028   0.484483    0.187238   0.781172),0x0 Array{Float64,2},Char[],Float64[],-Inf,Inf)\n\n\n\n\n\nDo another run of MM algorithm from default starting point. It leads to a slightly better local optimum 8.957172e+03. Follow up anlaysis should use this result.\n\n\n# default starting point\n\n\ntrait59_model\n \n=\n \nVarianceComponentModel\n(\ntrait59_data\n)\n\n\n@\ntime\n \n_\n,\n \n_\n,\n \n_\n,\n \n\u03a3cov\n,\n \n=\n \nmle_mm!\n(\ntrait59_model\n,\n \ntrait59_data\n;\n \nverbose\n=\ntrue\n)\n\n\ntrait59_model\n\n\n\n\n\n\n     MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0  -5.042149e+04\n       1  -1.699687e+04\n       2  -1.543968e+03\n       3   5.143609e+03\n       4   7.669359e+03\n       5   8.489390e+03\n       6   8.728893e+03\n       7   8.796019e+03\n       8   8.815880e+03\n       9   8.823279e+03\n      10   8.827419e+03\n      20   8.854389e+03\n      30   8.874943e+03\n      40   8.890795e+03\n      50   8.903062e+03\n      60   8.912619e+03\n      70   8.920130e+03\n      80   8.926088e+03\n      90   8.930861e+03\n     100   8.934721e+03\n     110   8.937872e+03\n     120   8.940467e+03\n     130   8.942622e+03\n     140   8.944425e+03\n     150   8.945946e+03\n     160   8.947237e+03\n     170   8.948339e+03\n     180   8.949287e+03\n     190   8.950106e+03\n     200   8.950818e+03\n     210   8.951439e+03\n     220   8.951983e+03\n     230   8.952462e+03\n     240   8.952886e+03\n     250   8.953262e+03\n     260   8.953597e+03\n     270   8.953896e+03\n     280   8.954164e+03\n     290   8.954404e+03\n     300   8.954621e+03\n     310   8.954817e+03\n     320   8.954994e+03\n     330   8.955154e+03\n     340   8.955300e+03\n     350   8.955433e+03\n     360   8.955555e+03\n     370   8.955666e+03\n     380   8.955767e+03\n     390   8.955860e+03\n     400   8.955946e+03\n     410   8.956025e+03\n     420   8.956097e+03\n     430   8.956164e+03\n     440   8.956226e+03\n     450   8.956283e+03\n     460   8.956336e+03\n     470   8.956385e+03\n     480   8.956430e+03\n     490   8.956473e+03\n     500   8.956512e+03\n     510   8.956549e+03\n     520   8.956583e+03\n     530   8.956615e+03\n     540   8.956645e+03\n     550   8.956673e+03\n     560   8.956699e+03\n     570   8.956723e+03\n     580   8.956746e+03\n     590   8.956768e+03\n     600   8.956788e+03\n     610   8.956807e+03\n     620   8.956825e+03\n     630   8.956842e+03\n     640   8.956858e+03\n     650   8.956873e+03\n     660   8.956887e+03\n     670   8.956900e+03\n     680   8.956913e+03\n     690   8.956925e+03\n     700   8.956936e+03\n     710   8.956947e+03\n     720   8.956957e+03\n     730   8.956967e+03\n     740   8.956976e+03\n     750   8.956985e+03\n     760   8.956994e+03\n     770   8.957001e+03\n     780   8.957009e+03\n     790   8.957016e+03\n     800   8.957023e+03\n     810   8.957030e+03\n     820   8.957036e+03\n     830   8.957042e+03\n     840   8.957048e+03\n     850   8.957053e+03\n     860   8.957058e+03\n     870   8.957064e+03\n     880   8.957068e+03\n     890   8.957073e+03\n     900   8.957077e+03\n     910   8.957082e+03\n     920   8.957086e+03\n     930   8.957090e+03\n     940   8.957093e+03\n     950   8.957097e+03\n     960   8.957100e+03\n     970   8.957104e+03\n     980   8.957107e+03\n     990   8.957110e+03\n    1000   8.957113e+03\n    1010   8.957116e+03\n    1020   8.957119e+03\n    1030   8.957121e+03\n    1040   8.957124e+03\n    1050   8.957126e+03\n    1060   8.957129e+03\n    1070   8.957131e+03\n    1080   8.957133e+03\n    1090   8.957135e+03\n    1100   8.957138e+03\n    1110   8.957140e+03\n    1120   8.957141e+03\n    1130   8.957143e+03\n    1140   8.957145e+03\n    1150   8.957147e+03\n    1160   8.957149e+03\n    1170   8.957150e+03\n    1180   8.957152e+03\n    1190   8.957153e+03\n    1200   8.957155e+03\n    1210   8.957156e+03\n    1220   8.957158e+03\n    1230   8.957159e+03\n    1240   8.957160e+03\n    1250   8.957161e+03\n    1260   8.957163e+03\n    1270   8.957164e+03\n    1280   8.957165e+03\n    1290   8.957166e+03\n    1300   8.957167e+03\n    1310   8.957168e+03\n    1320   8.957169e+03\n    1330   8.957170e+03\n    1340   8.957171e+03\n    1350   8.957172e+03\n\n 13.052188 seconds (455.86 M allocations: 11.254 GB, 19.84% gc time)\n\n\n\n\n\nVarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(0x5 Array{Float64,2},(\n5x5 Array{Float64,2}:\n 0.28408   0.282346  0.235651   0.163231   0.243528\n 0.282346  0.287797  0.222888   0.189209   0.231229\n 0.235651  0.222888  0.215833   0.0895747  0.212778\n 0.163231  0.189209  0.0895747  0.199473   0.107541\n 0.243528  0.231229  0.212778   0.107541   0.246379,\n\n5x5 Array{Float64,2}:\n 0.714039  0.65898    0.67085     0.221737   0.509435\n 0.65898   0.711746   0.578905    0.431453   0.480001\n 0.67085   0.578905   0.781276   -0.0579601  0.467102\n 0.221737  0.431453  -0.0579601   0.800138   0.189943\n 0.509435  0.480001   0.467102    0.189943   0.751844),0x0 Array{Float64,2},Char[],Float64[],-Inf,Inf)\n\n\n\n\n\nHeritability from 5-variate estimate and their standard errors.\n\n\nh\n,\n \nhse\n \n=\n \nheritability\n(\ntrait59_model\n.\n\u03a3\n,\n \n\u03a3cov\n)\n\n\n[\nh\n;\n \nhse\n]\n\n\n\n\n\n\n2x5 Array{Float64,2}:\n 0.284615   0.287928   0.216459   0.199551  0.246817 \n 0.0773858  0.0769331  0.0836844  0.085051  0.0809202\n\n\n\n\n\n\n\n13-trait analysis\n\n\nResearchers would like to jointly analyze all 13 traits. Fisher scoring algorithm (with KNITRO backend) ends with objective value of -6.839422e+04.\n\n\n# initialize model parameters\n\n\nalltrait_model\n \n=\n \nVarianceComponentModel\n(\ncg10kdata_rotated\n)\n\n\n# estimate variance components\n\n\n@\ntime\n \nmle_fs!\n(\nalltrait_model\n,\n \ncg10kdata_rotated\n;\n \nsolver\n=\n:\nKnitro\n,\n \nverbose\n=\ntrue\n)\n\n\nalltrait_model\n\n\n\n\n\n\nKnitro\n \n10\n.1.0\n \nSTUDENT\n \nLICENSE\n \n(\nproblem\n \nsize\n \nlimit\n \n=\n \n300\n)\n\n\n\n=======================================\n\n            \nStudent\n \nLicense\n\n       \n(\nNOT\n \nFOR\n \nCOMMERCIAL\n \nUSE\n)\n\n         \nArtelys\n \nKnitro\n \n10\n.1.0\n\n\n=======================================\n\n\n\nKnitro\n \npresolve\n \neliminated\n \n0\n \nvariables\n \nand\n \n0\n \nconstraints\n.\n\n\n\nalgorithm\n:\n            \n1\n\n\nThe\n \nproblem\n \nis\n \nidentified\n \nas\n \nbound\n \nconstrained\n \nonly\n.\n\n\nKnitro\n \nchanging\n \nbar_initpt\n \nfrom\n \nAUTO\n \nto\n \n3\n.\n\n\nKnitro\n \nchanging\n \nbar_murule\n \nfrom\n \nAUTO\n \nto\n \n4\n.\n\n\nKnitro\n \nchanging\n \nbar_penaltycons\n \nfrom\n \nAUTO\n \nto\n \n1\n.\n\n\nKnitro\n \nchanging\n \nbar_penaltyrule\n \nfrom\n \nAUTO\n \nto\n \n2\n.\n\n\nKnitro\n \nchanging\n \nbar_switchrule\n \nfrom\n \nAUTO\n \nto\n \n1\n.\n\n\nKnitro\n \nchanging\n \nlinsolver\n \nfrom\n \nAUTO\n \nto\n \n2\n.\n\n\n\nProblem\n \nCharacteristics\n                    \n(\n \nPresolved\n)\n\n\n-----------------------\n\n\nObjective\n \ngoal\n:\n  \nMaximize\n\n\nNumber\n \nof\n \nvariables\n:\n                   \n182\n \n(\n       \n182\n)\n\n    \nbounded\n \nbelow\n:\n                      \n26\n \n(\n        \n26\n)\n\n    \nbounded\n \nabove\n:\n                       \n0\n \n(\n         \n0\n)\n\n    \nbounded\n \nbelow\n \nand\n \nabove\n:\n             \n0\n \n(\n         \n0\n)\n\n    \nfixed\n:\n                               \n0\n \n(\n         \n0\n)\n\n    \nfree\n:\n                              \n156\n \n(\n       \n156\n)\n\n\nNumber\n \nof\n \nconstraints\n:\n                   \n0\n \n(\n         \n0\n)\n\n    \nlinear\n \nequalities\n:\n                   \n0\n \n(\n         \n0\n)\n\n    \nnonlinear\n \nequalities\n:\n                \n0\n \n(\n         \n0\n)\n\n    \nlinear\n \ninequalities\n:\n                 \n0\n \n(\n         \n0\n)\n\n    \nnonlinear\n \ninequalities\n:\n              \n0\n \n(\n         \n0\n)\n\n    \nrange\n:\n                               \n0\n \n(\n         \n0\n)\n\n\nNumber\n \nof\n \nnonzeros\n \nin\n \nJacobian\n:\n          \n0\n \n(\n         \n0\n)\n\n\nNumber\n \nof\n \nnonzeros\n \nin\n \nHessian\n:\n       \n16653\n \n(\n     \n16653\n)\n\n\n  \nIter\n      \nObjective\n      \nFeasError\n   \nOptError\n    \n||\nStep\n||\n    \nCGits\n \n\n--------\n  \n--------------\n  \n----------\n  \n----------\n  \n----------\n  \n-------\n\n       \n0\n   \n-1\n.311337e\n+\n05\n   \n0\n.000e\n+\n00\n\n      \n10\n   \n-7\n.616310e\n+\n04\n   \n0\n.000e\n+\n00\n   \n8\n.995e\n+\n02\n   \n4\n.820e-01\n        \n0\n\n      \n20\n   \n-6\n.839422e\n+\n04\n   \n0\n.000e\n+\n00\n   \n2\n.109e\n+\n03\n   \n0\n.000e\n+\n00\n       \n38\n\n\n\nEXIT\n:\n \nPrimal\n \nfeasible\n \nsolution\n;\n \nterminate\n \nbecause\n \nthe\n \nrelative\n \nchange\n \nin\n\n      \nsolution\n \nestimate\n \n \nxtol\n.\n\n\n\nFinal\n \nStatistics\n\n\n----------------\n\n\nFinal\n \nobjective\n \nvalue\n               \n=\n  \n-6\n.83942246370272e\n+\n04\n\n\nFinal\n \nfeasibility\n \nerror\n \n(\nabs\n \n/\n \nrel\n)\n \n=\n   \n0\n.00e\n+\n00\n \n/\n \n0\n.00e\n+\n00\n\n\nFinal\n \noptimality\n \nerror\n  \n(\nabs\n \n/\n \nrel\n)\n \n=\n   \n2\n.11e\n+\n03\n \n/\n \n1\n.00e\n+\n00\n\n\n#\n \nof\n \niterations\n                     \n=\n         \n21\n \n\n#\n \nof\n \nCG\n \niterations\n                  \n=\n        \n358\n \n\n#\n \nof\n \nfunction\n \nevaluations\n           \n=\n        \n114\n\n\n#\n \nof\n \ngradient\n \nevaluations\n           \n=\n         \n22\n\n\n#\n \nof\n \nHessian\n \nevaluations\n            \n=\n         \n20\n\n\nTotal\n \nprogram\n \ntime\n \n(\nsecs\n)\n           \n=\n      \n15\n.45499\n \n(\n    \n28\n.004\n \nCPU\n \ntime\n)\n\n\nTime\n \nspent\n \nin\n \nevaluations\n \n(\nsecs\n)\n    \n=\n      \n15\n.41301\n\n\n\n===============================================================================\n\n\n \n16\n.196635\n \nseconds\n \n(\n734\n.69\n \nM\n \nallocations\n:\n \n11\n.184\n \nGB\n,\n \n18\n.44\n%\n \ngc\n \ntime\n)\n\n\n\n\n###\n \nCould\n \nnot\n \nfind\n \na\n \nvalid\n \nlicense\n.\n\n    \nYour\n \nmachine\n \nID\n \nis\n \ne2-9d-cc-64-5f\n.\n\n    \nPlease\n \ncontact\n \nlicensing\n@artelys\n.com\n \nor\n \nyour\n \nlocal\n \ndistributor\n \nto\n \nobtain\n \na\n \nlicense\n.\n\n    \nIf\n \nyou\n \nalready\n \nhave\n \na\n \nlicense\n,\n \nplease\n \nexecute\n \n`\nget_machine_ID\n \n-v\n`\n \nand\n \nsend\n \nthe\n \noutput\n \nto\n \nsupport\n.\n\n\n\n\n\n\n\nVarianceComponentModels\n.VarianceComponentModel\n{\nFloat64\n,\n2\n,\nArray\n{\nFloat64\n,\n2\n}\n,\nArray\n{\nFloat64\n,\n2\n}}\n(\n0x13\n \nArray\n{\nFloat64\n,\n2\n}\n,(\n\n\n13x13\n \nArray\n{\nFloat64\n,\n2\n}\n:\n\n  \n0\n.314331\n    \n0\n.132105\n     \n-0\n.0353743\n   \n\u2026\n  \n-0\n.136065\n    \n-0\n.105679\n  \n  \n0\n.132105\n    \n0\n.139835\n      \n0\n.140532\n       \n-0\n.0173756\n   \n-0\n.00454843\n\n \n-0\n.0353743\n   \n0\n.140532\n      \n0\n.356882\n        \n0\n.0759456\n    \n0\n.0921647\n \n  \n0\n.343477\n    \n0\n.054447\n     \n-0\n.20584\n        \n-0\n.178914\n    \n-0\n.150596\n  \n \n-0\n.129413\n    \n0\n.0162518\n     \n0\n.189194\n        \n0\n.074017\n     \n0\n.0695955\n \n \n-0\n.113535\n    \n0\n.00983593\n    \n0\n.160915\n    \n\u2026\n   \n0\n.0670008\n    \n0\n.0576629\n \n \n-0\n.103928\n    \n0\n.012809\n      \n0\n.16756\n         \n0\n.0753421\n    \n0\n.0715201\n \n \n-0\n.0549071\n   \n0\n.000400283\n   \n0\n.0502762\n       \n0\n.00854523\n   \n0\n.00326281\n\n \n-0\n.205264\n   \n-0\n.0387588\n     \n0\n.153961\n        \n0\n.0858418\n    \n0\n.0789957\n \n \n-0\n.147011\n   \n-0\n.0856788\n    \n-0\n.064831\n        \n0\n.12759\n      \n0\n.0730245\n \n \n-0\n.155356\n   \n-0\n.0717934\n    \n-0\n.00878633\n  \n\u2026\n   \n0\n.0945906\n    \n0\n.0510817\n \n \n-0\n.136065\n   \n-0\n.0173756\n     \n0\n.0759456\n       \n0\n.357044\n     \n0\n.236415\n  \n \n-0\n.105679\n   \n-0\n.00454843\n    \n0\n.0921647\n       \n0\n.236415\n     \n0\n.24394\n   \n,\n\n\n\n13x13\n \nArray\n{\nFloat64\n,\n2\n}\n:\n\n  \n0\n.701526\n    \n0\n.640432\n    \n-0\n.0964342\n  \n\u2026\n  \n-0\n.352486\n   \n-0\n.0542532\n  \n-0\n.125562\n \n  \n0\n.640432\n    \n0\n.884372\n     \n0\n.107444\n      \n-0\n.340323\n   \n-0\n.0140205\n   \n0\n.0218768\n\n \n-0\n.0964342\n   \n0\n.107444\n     \n0\n.649201\n      \n-0\n.127019\n    \n0\n.0354407\n   \n0\n.0121441\n\n  \n0\n.496518\n    \n0\n.241287\n    \n-0\n.254125\n      \n-0\n.219282\n   \n-0\n.0580118\n  \n-0\n.19055\n  \n \n-0\n.282266\n   \n-0\n.0653499\n    \n0\n.327741\n      \n-0\n.0412117\n   \n0\n.0425152\n   \n0\n.0545268\n\n \n-0\n.259093\n   \n-0\n.0348929\n    \n0\n.297623\n   \n\u2026\n  \n-0\n.0583661\n   \n0\n.0376783\n   \n0\n.0533446\n\n \n-0\n.249\n      \n-0\n.0489288\n    \n0\n.349755\n      \n-0\n.0283019\n   \n0\n.0338332\n   \n0\n.0434008\n\n \n-0\n.105542\n    \n0\n.00459972\n   \n0\n.0387758\n     \n-0\n.0633714\n   \n0\n.0178299\n   \n0\n.0319088\n\n \n-0\n.32499\n    \n-0\n.126343\n     \n0\n.252081\n       \n0\n.13956\n     \n0\n.0987083\n   \n0\n.102378\n \n \n-0\n.266693\n   \n-0\n.308904\n    \n-0\n.160801\n       \n0\n.422532\n    \n0\n.0144221\n   \n0\n.0601095\n\n \n-0\n.352486\n   \n-0\n.340323\n    \n-0\n.127019\n   \n\u2026\n   \n0\n.788049\n    \n0\n.107235\n    \n0\n.146221\n \n \n-0\n.0542532\n  \n-0\n.0140205\n    \n0\n.0354407\n      \n0\n.107235\n    \n0\n.645093\n    \n0\n.405515\n \n \n-0\n.125562\n    \n0\n.0218768\n    \n0\n.0121441\n      \n0\n.146221\n    \n0\n.405515\n    \n0\n.755077\n \n),\n0x0\n \nArray\n{\nFloat64\n,\n2\n}\n,\nChar\n[]\n,\nFloat64\n[]\n,\n-Inf\n,\nInf\n)\n\n\n\n\n\n\nRe-run using MM algorithm, which locates a better mode with objective value -4.435632e+04. Follow up anlaysis should use this result.\n\n\n# initialize model parameters\n\n\nalltrait_model\n \n=\n \nVarianceComponentModel\n(\ncg10kdata_rotated\n)\n\n\n# estimate variance components\n\n\n@\ntime\n \n_\n,\n \n_\n,\n \n_\n,\n \n\u03a3cov\n,\n \n=\n \nmle_mm!\n(\nalltrait_model\n,\n \ncg10kdata_rotated\n;\n \nverbose\n=\ntrue\n)\n\n\nalltrait_model\n\n\n\n\n\n\n     MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0  -1.311337e+05\n       1  -8.002195e+04\n       2  -5.807051e+04\n       3  -4.926234e+04\n       4  -4.611182e+04\n       5  -4.511727e+04\n       6  -4.482798e+04\n       7  -4.474410e+04\n       8  -4.471610e+04\n       9  -4.470285e+04\n      10  -4.469355e+04\n      20  -4.462331e+04\n      30  -4.456960e+04\n      40  -4.452834e+04\n      50  -4.449652e+04\n      60  -4.447178e+04\n      70  -4.445237e+04\n      80  -4.443699e+04\n      90  -4.442467e+04\n     100  -4.441470e+04\n     110  -4.440656e+04\n     120  -4.439985e+04\n     130  -4.439427e+04\n     140  -4.438959e+04\n     150  -4.438564e+04\n     160  -4.438229e+04\n     170  -4.437941e+04\n     180  -4.437694e+04\n     190  -4.437480e+04\n     200  -4.437294e+04\n     210  -4.437131e+04\n     220  -4.436989e+04\n     230  -4.436863e+04\n     240  -4.436751e+04\n     250  -4.436652e+04\n     260  -4.436564e+04\n     270  -4.436485e+04\n     280  -4.436414e+04\n     290  -4.436351e+04\n     300  -4.436293e+04\n     310  -4.436242e+04\n     320  -4.436195e+04\n     330  -4.436152e+04\n     340  -4.436113e+04\n     350  -4.436078e+04\n     360  -4.436046e+04\n     370  -4.436016e+04\n     380  -4.435989e+04\n     390  -4.435965e+04\n     400  -4.435942e+04\n     410  -4.435921e+04\n     420  -4.435902e+04\n     430  -4.435884e+04\n     440  -4.435867e+04\n     450  -4.435852e+04\n     460  -4.435838e+04\n     470  -4.435825e+04\n     480  -4.435813e+04\n     490  -4.435802e+04\n     500  -4.435791e+04\n     510  -4.435781e+04\n     520  -4.435772e+04\n     530  -4.435764e+04\n     540  -4.435756e+04\n     550  -4.435748e+04\n     560  -4.435741e+04\n     570  -4.435735e+04\n     580  -4.435729e+04\n     590  -4.435723e+04\n     600  -4.435718e+04\n     610  -4.435713e+04\n     620  -4.435708e+04\n     630  -4.435704e+04\n     640  -4.435700e+04\n     650  -4.435696e+04\n     660  -4.435692e+04\n     670  -4.435688e+04\n     680  -4.435685e+04\n     690  -4.435682e+04\n     700  -4.435679e+04\n     710  -4.435676e+04\n     720  -4.435674e+04\n     730  -4.435671e+04\n     740  -4.435669e+04\n     750  -4.435667e+04\n     760  -4.435665e+04\n     770  -4.435663e+04\n     780  -4.435661e+04\n     790  -4.435659e+04\n     800  -4.435657e+04\n     810  -4.435656e+04\n     820  -4.435654e+04\n     830  -4.435653e+04\n     840  -4.435651e+04\n     850  -4.435650e+04\n     860  -4.435649e+04\n     870  -4.435648e+04\n     880  -4.435647e+04\n     890  -4.435646e+04\n     900  -4.435645e+04\n     910  -4.435644e+04\n     920  -4.435643e+04\n     930  -4.435642e+04\n     940  -4.435641e+04\n     950  -4.435640e+04\n     960  -4.435639e+04\n     970  -4.435639e+04\n     980  -4.435638e+04\n     990  -4.435637e+04\n    1000  -4.435637e+04\n    1010  -4.435636e+04\n    1020  -4.435635e+04\n    1030  -4.435635e+04\n    1040  -4.435634e+04\n    1050  -4.435634e+04\n    1060  -4.435633e+04\n    1070  -4.435633e+04\n    1080  -4.435632e+04\n\n 27.474548 seconds (976.37 M allocations: 23.795 GB, 18.43% gc time)\n\n\n\n\n\nVarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(0x13 Array{Float64,2},(\n13x13 Array{Float64,2}:\n  0.273498    0.192141    -0.0207392   0.231615   \u2026  -0.128643   -0.098307  \n  0.192141    0.219573     0.134389    0.0800317     -0.0687355  -0.0433724 \n -0.0207392   0.134389     0.329149   -0.158086       0.0717258   0.097381  \n  0.231615    0.0800317   -0.158086    0.277921      -0.129316   -0.104571  \n -0.149294   -0.0130248    0.186275   -0.219746       0.0673901   0.0798606 \n -0.131878   -0.00396265   0.169037   -0.204038   \u2026   0.0539454   0.0662375 \n -0.14514    -0.0332988    0.168384   -0.190066       0.0778299   0.0867255 \n -0.0299641   0.0372326    0.0617453  -0.0918129     -0.0120473  -0.00309877\n -0.205216   -0.0839698    0.137149   -0.232933       0.0895106   0.0971193 \n -0.100475   -0.114933    -0.088079   -0.0435633      0.046928   -0.0048387 \n -0.133733   -0.109897    -0.0247458  -0.0985453  \u2026   0.0587572   0.0114353 \n -0.128643   -0.0687355    0.0717258  -0.129316       0.117185    0.0899824 \n -0.098307   -0.0433724    0.097381   -0.104571       0.0899824   0.106354  ,\n\n13x13 Array{Float64,2}:\n  0.723441    0.568135    -0.113563     0.590598   \u2026  -0.0586259  -0.12469   \n  0.568135    0.77999      0.109287     0.215784       0.0236098   0.0464835 \n -0.113563    0.109287     0.669754    -0.299757       0.0467158   0.00601682\n  0.590598    0.215784    -0.299757     0.718142      -0.0951686  -0.218709  \n -0.252371   -0.0353068    0.334628    -0.372904       0.0472511   0.0435499 \n -0.228865   -0.0203083    0.295345    -0.343471   \u2026   0.0511838   0.0482913 \n -0.193033    0.00191887   0.345731    -0.319          0.0327529   0.0272593 \n -0.129704   -0.0365696    0.0400358   -0.156082       0.0427586   0.0451036 \n -0.30716    -0.0823855    0.2673      -0.410123       0.102842    0.0946414 \n -0.303001   -0.28147     -0.13149     -0.218          0.0947723   0.142937  \n -0.364401   -0.30413     -0.107477    -0.270766   \u2026   0.143809    0.187604  \n -0.0586259   0.0236098    0.0467158   -0.0951686      0.881707    0.551818  \n -0.12469     0.0464835    0.00601682  -0.218709       0.551818    0.893023  ),0x0 Array{Float64,2},Char[],Float64[],-Inf,Inf)\n\n\n\n\n\nHeritability estimate from 13-variate analysis.\n\n\nh\n,\n \nhse\n \n=\n \nheritability\n(\nalltrait_model\n.\n\u03a3\n,\n \n\u03a3cov\n)\n\n\n[\nh\n;\n \nhse\n]\n\n\n\n\n\n\n2x13 Array{Float64,2}:\n 0.274338   0.219669   0.329511  0.279019   \u2026  0.172946  0.117315   0.10642  \n 0.0778364  0.0818365  0.072716  0.0775316     0.087259  0.0902115  0.0903969\n\n\n\n\n\n\n\nSave analysis results\n\n\nusing\n \nJLD\n\n\n@\nsave\n \ncopd.jld\n\n\nwhos\n()\n\n\n\n\n\n\nINFO\n:\n \nRecompiling\n \nstale\n \ncache\n \nfile\n \n/Users/huazhou/.julia/lib/v0.4/\nJLD\n.\nji\n \nfor\n \nmodule\n \nJLD\n.\n\n\n\n                 \n#\n334\n#\nwsession\n    \n280\n \nbytes\n  \nJLD\n.\nJldWriteSession\n\n                    \nArrayViews\n    \n188\n \nKB\n     \nModule\n\n                          \nBase\n  \n38129\n \nKB\n     \nModule\n\n                       \nBinDeps\n    \n208\n \nKB\n     \nModule\n\n                         \nBlosc\n     \n37\n \nKB\n     \nModule\n\n                    \nColorTypes\n    \n313\n \nKB\n     \nModule\n\n                        \nColors\n    \n747\n \nKB\n     \nModule\n\n                        \nCompat\n    \n344\n \nKB\n     \nModule\n\n                         \nConda\n     \n65\n \nKB\n     \nModule\n\n                          \nCore\n   \n7200\n \nKB\n     \nModule\n\n                    \nDataArrays\n    \n762\n \nKB\n     \nModule\n\n                    \nDataFrames\n   \n1807\n \nKB\n     \nModule\n\n                        \nDocile\n    \n415\n \nKB\n     \nModule\n\n                        \nFileIO\n    \n536\n \nKB\n     \nModule\n\n             \nFixedPointNumbers\n     \n33\n \nKB\n     \nModule\n\n               \nFixedSizeArrays\n    \n157\n \nKB\n     \nModule\n\n\n\n\nWARNING\n:\n \nboth\n \nDataArrays\n \nand\n \nStatsBase\n \nexport\n \nautocor\n;\n \nuses\n \nof\n \nit\n \nin\n \nmodule\n \nDataFrames\n \nmust\n \nbe\n \nqualified\n\n\nWARNING\n:\n \nboth\n \nDataArrays\n \nand\n \nStatsBase\n \nexport\n \ninverse_rle\n;\n \nuses\n \nof\n \nit\n \nin\n \nmodule\n \nDataFrames\n \nmust\n \nbe\n \nqualified\n\n\nWARNING\n:\n \nboth\n \nDataArrays\n \nand\n \nStatsBase\n \nexport\n \nrle\n;\n \nuses\n \nof\n \nit\n \nin\n \nmodule\n \nDataFrames\n \nmust\n \nbe\n \nqualified\n\n\n\n                          \nGZip\n    \n791\n \nKB\n     \nModule\n\n                          \nHDF5\n   \n3336\n \nKB\n     \nModule\n\n                        \nIJulia\n \n3468156\n \nKB\n     \nModule\n\n                \nIPythonDisplay\n     \n35\n \nKB\n     \nModule\n\n                         \nIpopt\n     \n50\n \nKB\n     \nModule\n\n              \nIterativeSolvers\n    \n486\n \nKB\n     \nModule\n\n                           \nJLD\n   \n1364\n \nKB\n     \nModule\n\n                          \nJSON\n    \n240\n \nKB\n     \nModule\n\n                        \nKNITRO\n    \n320\n \nKB\n     \nModule\n\n                  \nLaTeXStrings\n   \n3115\n \nbytes\n  \nModule\n\n                    \nMacroTools\n    \n124\n \nKB\n     \nModule\n\n                          \nMain\n \n3527139\n \nKB\n     \nModule\n\n                  \nMathProgBase\n   \n1393\n \nKB\n     \nModule\n\n                      \nMeasures\n     \n15\n \nKB\n     \nModule\n\n                        \nNettle\n     \n58\n \nKB\n     \nModule\n\n                         \nPlots\n   \n2975\n \nKB\n     \nModule\n\n                        \nPyCall\n   \n1002\n \nKB\n     \nModule\n\n                        \nPyPlot\n   \n1278\n \nKB\n     \nModule\n\n                   \nRecipesBase\n    \n193\n \nKB\n     \nModule\n\n                      \nReexport\n   \n3658\n \nbytes\n  \nModule\n\n                           \nSHA\n     \n50\n \nKB\n     \nModule\n\n                     \nSnpArrays\n    \n437\n \nKB\n     \nModule\n\n             \nSortingAlgorithms\n     \n40\n \nKB\n     \nModule\n\n                     \nStatsBase\n    \n783\n \nKB\n     \nModule\n\n                     \nStatsFuns\n    \n286\n \nKB\n     \nModule\n\n                     \nURIParser\n    \n103\n \nKB\n     \nModule\n\n       \nVarianceComponentModels\n    \n642\n \nKB\n     \nModule\n\n                             \nY\n    \n677\n \nKB\n     \n6670\nx13\n \nArray\n{\nFloat64\n,\n2\n}\n\n                           \nZMQ\n     \n81\n \nKB\n     \nModule\n\n                             \n_\n   \n2720\n \nbytes\n  \nTuple\n{\nArray\n{\nFloat64\n,\n2\n},\nArray\n{\nFloat\n\u2026\n\n                \nalltrait_model\n   \n2792\n \nbytes\n  \nVarianceComponentModels\n.\nVarianceCo\n\u2026\n\n                         \ncg10k\n \n1027303\n \nKB\n     \n6670\nx630860\n \nSnpArrays\n.\nSnpArray\n{\n2\n}\n\n                   \ncg10k_trait\n    \n978\n \nKB\n     \n6670\n\u00d7\n15\n \nDataFrames\n.\nDataFrame\n\n                     \ncg10kdata\n \n695816\n \nKB\n     \nVarianceComponentModels\n.\nVarianceCo\n\u2026\n\n             \ncg10kdata_rotated\n    \n729\n \nKB\n     \nVarianceComponentModels\n.\nTwoVarComp\n\u2026\n\n                             \nh\n    \n104\n \nbytes\n  \n13\n-\nelement\n \nArray\n{\nFloat64\n,\n1\n}\n\n                           \nhST\n    \n104\n \nbytes\n  \n13\n-\nelement\n \nArray\n{\nFloat64\n,\n1\n}\n\n                        \nhST_se\n    \n104\n \nbytes\n  \n13\n-\nelement\n \nArray\n{\nFloat64\n,\n1\n}\n\n                           \nhse\n    \n104\n \nbytes\n  \n13\n-\nelement\n \nArray\n{\nFloat64\n,\n1\n}\n\n                           \nmaf\n   \n4928\n \nKB\n     \n630860\n-\nelement\n \nArray\n{\nFloat64\n,\n1\n}\n\n                  \nminor_allele\n     \n77\n \nKB\n     \n630860\n-\nelement\n \nBitArray\n{\n1\n}\n\n            \nmissings_by_person\n     \n52\n \nKB\n     \n6670\n-\nelement\n \nArray\n{\nInt64\n,\n1\n}\n\n               \nmissings_by_snp\n   \n4928\n \nKB\n     \n630860\n-\nelement\n \nArray\n{\nInt64\n,\n1\n}\n\n                        \npeople\n      \n8\n \nbytes\n  \nInt64\n\n                          \nsnps\n      \n8\n \nbytes\n  \nInt64\n\n                  \ntrait59_data\n    \n312\n \nKB\n     \nVarianceComponentModels\n.\nTwoVarComp\n\u2026\n\n                 \ntrait59_model\n    \n488\n \nbytes\n  \nVarianceComponentModels\n.\nVarianceCo\n\u2026\n\n                      \ntraitidx\n     \n16\n \nbytes\n  \n5\n-\nelement\n \nUnitRange\n{\nInt64\n}\n\n                            \n\u03a3\na\n   \n3848\n \nbytes\n  \n13\nx13\n \nArray\n{\nArray\n{\nFloat64\n,\n2\n},\n2\n}\n\n                          \n\u03a3\ncov\n    \n892\n \nKB\n     \n338\nx338\n \nArray\n{\nFloat64\n,\n2\n}\n\n                            \n\u03a3\ne\n   \n3848\n \nbytes\n  \n13\nx13\n \nArray\n{\nArray\n{\nFloat64\n,\n2\n},\n2\n}\n\n                          \n\u03a6\ngrm\n \n347569\n \nKB\n     \n6670\nx6670\n \nArray\n{\nFloat64\n,\n2\n}\n\n                           \n\u03c3\n2\na\n    \n104\n \nbytes\n  \n13\n-\nelement\n \nArray\n{\nFloat64\n,\n1\n}\n\n                           \n\u03c3\n2\ne\n    \n104\n \nbytes\n  \n13\n-\nelement\n \nArray\n{\nFloat64\n,\n1\n}", 
            "title": "Heritability"
        }, 
        {
            "location": "/man/heritability/#heritability-analysis", 
            "text": "This note demonstrates the workflow for a typical heritability analysis in genetics, using a sample data set  cg10k  with  6,670  individuals and  630,860  SNPs. Person IDs and phenotype names are masked for privacy. Here  cg10k.bed ,  cg10k.bim , and  cg10k.fam  is a set of Plink files in binary format.  cg10k_traits.txt  contains the phenotype data of 6,670 individuals.  ; ls   cg10k *.*   cg10k.bed\ncg10k.bim\ncg10k.fam\ncg10k.ipynb\ncg10k.jld\ncg10k_traits.txt  Machine information:  versioninfo ()   Julia Version 0.4.6\nCommit 2e358ce (2016-06-19 17:16 UTC)\nPlatform Info:\n  System: Darwin (x86_64-apple-darwin13.4.0)\n  CPU: Intel(R) Core(TM) i7-4790K CPU @ 4.00GHz\n  WORD_SIZE: 64\n  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Haswell)\n  LAPACK: libopenblas64_\n  LIBM: libopenlibm\n  LLVM: libLLVM-3.3", 
            "title": "Heritability Analysis"
        }, 
        {
            "location": "/man/heritability/#read-in-binary-snp-data", 
            "text": "We will use the  SnpArrays  package to read in binary SNP data and compute the empirical kinship matrix. Issue  Pkg.clone(\"git@github.com:Hua-Zhou/SnpArrays.jl.git\")  within  Julia  to install the  SnpArrays  package.  #Pkg.clone( git@github.com:OpenMendel/SnpArrays.jl.git )  using   SnpArrays   # read in genotype data from Plink binary file (~50 secs on my laptop)  @ time   cg10k   =   SnpArray ( cg10k )    33.409278 seconds (4.58 k allocations: 1003.520 MB, 0.07% gc time)\n\n\n\n\n\n6670x630860 SnpArrays.SnpArray{2}:\n (false,true)   (false,true)   (true,true)   \u2026  (true,true)    (true,true) \n (true,true)    (true,true)    (false,true)     (false,true)   (true,false)\n (true,true)    (true,true)    (false,true)     (true,true)    (true,true) \n (true,true)    (true,true)    (true,true)      (false,true)   (true,true) \n (true,true)    (true,true)    (true,true)      (true,true)    (false,true)\n (false,true)   (false,true)   (true,true)   \u2026  (true,true)    (true,true) \n (false,false)  (false,false)  (true,true)      (true,true)    (true,true) \n (true,true)    (true,true)    (true,true)      (true,true)    (false,true)\n (true,true)    (true,true)    (false,true)     (true,true)    (true,true) \n (true,true)    (true,true)    (true,true)      (false,true)   (true,true) \n (true,true)    (true,true)    (false,true)  \u2026  (true,true)    (true,true) \n (false,true)   (false,true)   (true,true)      (true,true)    (false,true)\n (true,true)    (true,true)    (true,true)      (true,true)    (false,true)\n \u22ee                                           \u22f1                             \n (false,true)   (false,true)   (true,true)      (false,true)   (false,true)\n (false,true)   (false,true)   (false,true)     (false,true)   (true,true) \n (true,true)    (true,true)    (false,true)  \u2026  (false,true)   (true,true) \n (false,true)   (false,true)   (true,true)      (true,true)    (false,true)\n (true,true)    (true,true)    (true,true)      (false,true)   (true,true) \n (true,true)    (true,true)    (true,false)     (false,false)  (false,true)\n (true,true)    (true,true)    (true,true)      (true,true)    (false,true)\n (true,true)    (true,true)    (false,true)  \u2026  (true,true)    (true,true) \n (true,true)    (true,true)    (true,true)      (false,true)   (true,true) \n (true,true)    (true,true)    (true,true)      (true,true)    (false,true)\n (false,true)   (false,true)   (true,true)      (true,true)    (true,true) \n (true,true)    (true,true)    (true,true)      (true,true)    (true,true)", 
            "title": "Read in binary SNP data"
        }, 
        {
            "location": "/man/heritability/#summary-statistics-of-snp-data", 
            "text": "people ,   snps   =   size ( cg10k )   (6670,630860)  # summary statistics (~50 secs on my laptop)  @ time   maf ,   minor_allele ,   missings_by_snp ,   missings_by_person   =   summarize ( cg10k )    28.517763 seconds (20 allocations: 9.753 MB)\n\n\n\n\n\n([0.169916,0.17099,0.114026,0.268694,0.219265,0.23935,0.190612,0.20201,0.0271609,0.299714  \u2026  0.207996,0.448012,0.295465,0.142654,0.170915,0.281428,0.0611354,0.0524738,0.13931,0.132413],Bool[true,true,true,true,true,true,true,true,true,true  \u2026  true,true,true,true,true,true,true,true,true,true],[2,0,132,77,0,27,2,2,6,27  \u2026  4,5,11,0,0,4,29,0,5,43],[364,1087,1846,1724,1540,248,215,273,273,224  \u2026  1353,692,901,1039,685,304,223,1578,2059,1029])  # 5 number summary and average MAF (minor allele frequencies)  quantile ( maf ,   [ 0.0   . 25   . 5   . 75   1.0 ]),   mean ( maf )   (\n1x5 Array{Float64,2}:\n 0.00841726  0.124063  0.236953  0.364253  0.5,\n\n0.24536516625042462)  using   Plots  pyplot ()  #gr()  histogram ( maf ,   xlab   =   Minor Allele Frequency (MAF) ,   label   =   MAF )    # proportion of missing genotypes  sum ( missings_by_snp )   /   length ( cg10k )   0.0013128198764010824  # proportion of rare SNPs with maf   0.05  countnz ( maf   .   0.05 )   /   length ( maf )   0.07228069619249913", 
            "title": "Summary statistics of SNP data"
        }, 
        {
            "location": "/man/heritability/#empirical-kinship-matrix", 
            "text": "We estimate empirical kinship based on all SNPs by the genetic relation matrix (GRM). Missing genotypes are imputed on the fly by drawing according to the minor allele frequencies.  # GRM using all SNPs (~10 mins on my laptop)  srand ( 123 )  @ time   \u03a6grm   =   grm ( cg10k ;   method   =   : GRM )   343.981385 seconds (4.21 G allocations: 64.468 GB, 2.25% gc time)\n\n\n\n\n\n6670x6670 Array{Float64,2}:\n  0.502916      0.00329978   -0.000116213  \u2026  -6.46286e-5   -0.00281229 \n  0.00329978    0.49892      -0.00201992       0.000909871   0.00345573 \n -0.000116213  -0.00201992    0.493632         0.000294565  -0.000349854\n  0.000933977  -0.00320391   -0.0018611       -0.00241682   -0.00127078 \n -7.75429e-5   -0.0036075     0.00181442       0.00213976   -0.00158382 \n  0.00200371    0.000577386   0.0025455    \u2026   0.000943753  -1.82994e-6 \n  0.000558503   0.00241421   -0.0018782        0.001217     -0.00123924 \n -0.000659495   0.00319987   -0.00101496       0.00353646   -0.00024093 \n -0.00102619   -0.00120448   -0.00055462       0.00175586    0.00181899 \n -0.00136838    0.00211996    0.000119128     -0.00147305   -0.00105239 \n -0.00206144    0.000148818  -0.000475177  \u2026  -0.000265522  -0.00106123 \n  0.000951016   0.00167042    0.00183545      -0.000703658  -0.00313334 \n  0.000330442  -0.000904147   0.00301478       0.000754772  -0.00127413 \n  \u22ee                                        \u22f1                            \n  0.00301137    0.00116042    0.00100426       6.67254e-6    0.00307069 \n -0.00214008    0.00270925   -0.00185054      -0.00109935    0.00366816 \n  0.000546739  -0.00242646   -0.00305264   \u2026  -0.000629014   0.00210779 \n -0.00422553   -0.0020713    -0.00109052      -0.000705804  -0.000508055\n -0.00318405   -0.00075385    0.00312377       0.00052883   -3.60969e-5 \n  0.000430196  -0.00197163    0.00268545      -0.00633175   -0.00520337 \n  0.00221429    0.000849792  -0.00101111      -0.000943129  -0.000624419\n -0.00229025   -0.000130598   0.000101853  \u2026   0.000840136  -0.00230224 \n -0.00202917    0.00233007   -0.00131006       0.00197798   -0.000513771\n -0.000964907  -0.000872326  -7.06722e-5       0.00124702   -0.00295844 \n -6.46286e-5    0.000909871   0.000294565      0.500983      0.000525615\n -0.00281229    0.00345573   -0.000349854      0.000525615   0.500792", 
            "title": "Empirical kinship matrix"
        }, 
        {
            "location": "/man/heritability/#phenotypes", 
            "text": "Read in the phenotype data and compute descriptive statistics.  using   DataFrames  cg10k_trait   =   readtable ( cg10k_traits.txt ;  \n     separator   =     , \n     names   =   [: FID ;   : IID ;   : Trait1 ;   : Trait2 ;   : Trait3 ;   : Trait4 ;   : Trait5 ;   : Trait6 ;  \n              : Trait7 ;   : Trait8 ;   : Trait9 ;   : Trait10 ;   : Trait11 ;   : Trait12 ;   : Trait13 ],   \n     eltypes   =   [ UTF8String ;   UTF8String ;   Float64 ;   Float64 ;   Float64 ;   Float64 ;   Float64 ;  \n                Float64 ;   Float64 ;   Float64 ;   Float64 ;   Float64 ;   Float64 ;   Float64 ;   Float64 ])   FID IID Trait1 Trait2 Trait3 Trait4 Trait5 Trait6 Trait7 Trait8 Trait9 Trait10 Trait11 Trait12 Trait13 1 10002K 10002K -1.81573145026234 -0.94615046147283 1.11363077580442 -2.09867121119159 0.744416614111748 0.00139171884080131 0.934732480409667 -1.22677315418103 1.1160784277875 -0.4436280335029 0.824465656443384 -1.02852542216546 -0.394049201727681 2 10004O 10004O -1.24440094378729 0.109659992547179 0.467119394241789 -1.62131304097589 1.0566758355683 0.978946979419181 1.00014633946047 0.32487427140228 1.16232175219696 2.6922706948705 3.08263672461047 1.09064954786013 0.0256616415357438 3 10005Q 10005Q 1.45566914502305 1.53866932923243 1.09402959376555 0.586655272226893 -0.32796454430367 -0.30337709778827 -0.0334354881314741 -0.464463064285437 -0.3319396273436 -0.486839089635991 -1.10648681564373 -1.42015780427231 -0.687463456644413 4 10006S 10006S -0.768809276698548 0.513490885514249 0.244263028382142 -1.31740254475691 1.19393774326845 1.17344127734288 1.08737426675232 0.536022583732261 0.802759240762068 0.234159411749815 0.394174866891074 -0.767365892476029 0.0635385761884935 5 10009Y 10009Y -0.264415132547719 -0.348240421825694 -0.0239065083413606 0.00473915802244948 1.25619191712193 1.2038883667631 1.29800739042627 0.310113660247311 0.626159861059352 0.899289129831224 0.54996783350812 0.540687809542048 0.179675416046033 6 10010J 10010J -1.37617270917293 -1.47191967744564 0.291179894254146 -0.803110740704731 -0.264239977442213 -0.260573027836772 -0.165372266287781 -0.219257294118362 1.04702422290318 -0.0985815534616482 0.947393438068448 0.594014812031438 0.245407436348479 7 10011L 10011L 0.1009416296374 -0.191615722103455 -0.567421321596677 0.378571487240382 -0.246656179817904 -0.608810750053858 0.189081058215596 -1.27077787326519 -0.452476199143965 0.702562877297724 0.332636218957179 0.0026916503626181 0.317117176705358 8 10013P 10013P -0.319818276367464 1.35774480657283 0.818689545938528 -1.15565531644352 0.63448368102259 0.291461908634679 0.933323714954726 -0.741083289682492 0.647477683507572 -0.970877627077966 0.220861165411304 0.852512250237764 -0.225904624283945 9 10014R 10014R -0.288334173342032 0.566082538090752 0.254958336116175 -0.652578302869714 0.668921559277347 0.978309199170558 0.122862966041938 1.4790926378214 0.0672132424173449 0.0795903917527827 0.167532455243232 0.246915579442139 0.539932616458363 10 10015T 10015T -1.15759732583991 -0.781198583545165 -0.595807759833517 -1.00554980260402 0.789828885933321 0.571058413379044 0.951304176233755 -0.295962982984816 0.99042002479707 0.561309366988983 0.733100030623233 -1.73467772245684 -1.35278484330654 11 10017X 10017X 0.740569150459031 1.40873846755415 0.734689999440088 0.0208322841295094 -0.337440968561619 -0.458304040611395 -0.142582512772326 -0.580392297464107 -0.684684998101516 -0.00785381461893456 -0.712244337518008 -0.313345561230878 -0.345419463162219 12 10020M 10020M -0.675892486454995 0.279892613829682 0.267915996308248 -1.04103665392985 0.910741715645888 0.866027618513171 1.07414431702005 0.0381751003538302 0.766355377018601 -0.340118016143495 -0.809013958505059 0.548521663785885 -0.0201828675962336 13 10022Q 10022Q -0.795410435603455 -0.699989939762738 0.3991295030063 -0.510476261900736 1.51552245416844 1.28743032939467 1.53772393250903 0.133989160117702 1.02025736886037 0.499018733899186 -0.36948273277931 -1.10153460436318 -0.598132438886619 14 10023S 10023S -0.193483122930324 -0.286021160323518 -0.691494225262995 0.0131581678700699 1.52337470686782 1.4010638072262 1.53114620451896 0.333066483478075 1.04372480381099 0.163206783570466 -0.422883765001728 -0.383527976713573 -0.489221907788158 15 10028C 10028C 0.151246203379718 2.09185108993614 2.03800472474384 -1.12474717143531 1.66557024390713 1.62535675109576 1.58751070483655 0.635852186043776 0.842577784605979 0.450761870778952 -1.39479033623028 -0.560984107567768 0.289349776549287 16 10031R 10031R -0.464608740812712 0.36127694772303 1.2327673928287 -0.826033731086383 1.43475224709983 1.74451823818846 0.211096887484638 2.64816425140548 1.02511433146096 0.11975731603184 0.0596832073448267 -0.631231612661616 -0.207878671782927 17 10032T 10032T -0.732977488012215 -0.526223425889779 0.61657871336593 -0.55447974332593 0.947484859025104 0.936833214138173 0.972516806335524 0.290251013865227 1.01285359725723 0.516207422283291 -0.0300689171988194 0.8787322524583 0.450254629309513 18 10034X 10034X -0.167326459622119 0.175327165487237 0.287467725892572 -0.402652532084246 0.551181509418056 0.522204743290975 0.436837660094653 0.299564933845579 0.583109520896067 -0.704415820005353 -0.730810367994577 -1.95140580379896 -0.933504665700164 19 10035Z 10035Z 1.41159485787418 1.78722407901017 0.84397639585364 0.481278083772991 -0.0887673728508268 -0.49957757426858 0.304195897924847 -1.23884208383369 -0.153475724036624 -0.870486102788329 0.0955473331150403 -0.983708050882817 -0.3563445644514 20 10041U 10041U -1.42997091652825 -0.490147045034213 0.272730237607695 -1.61029992954153 0.990787817197748 0.711687532608184 1.1885836012715 -0.371229188075638 1.24703459239952 -0.0389162332271516 0.883495749072872 2.58988026321017 3.33539552370368 21 10047G 10047G -0.147247288176765 0.12328430415652 0.617549051912237 -0.18713077178262 0.256438107586694 0.17794983735083 0.412611806463263 -0.244809124559737 0.0947624806136492 0.723017223849532 -0.683948354633436 0.0873751276309269 -0.262209652750371 22 10051X 10051X -0.187112676773894 -0.270777264595619 -1.01556818551606 0.0602850568600233 0.272419757757978 0.869133161879197 -0.657519461414234 2.32388522018189 -0.999936011525034 1.44671844178306 0.971157886040772 -0.358747904241515 -0.439657942096136 23 10052Z 10052Z -1.82434047163768 -0.933480446068067 1.29474003766977 -1.94545221151036 0.33584651189654 0.359201654302844 0.513652924365886 -0.073197696696958 1.57139042812005 1.53329371326728 1.82076821859528 2.22740301867829 1.50063347195857 24 10056H 10056H -2.29344084351335 -2.49161842344418 0.40383988742336 -2.36488074752948 1.4105254831956 1.42244117147792 1.17024166272172 0.84476650176855 1.79026875432495 0.648181858970515 -0.0857231057403538 -1.02789535292617 0.491288088952859 25 10057J 10057J -0.434135932888305 0.740881989034652 0.699576357578518 -1.02405543187775 0.759529223983713 0.956656110895288 0.633299568656589 0.770733932268516 0.824988511714526 1.84287437634769 1.91045942063443 -0.502317207869366 0.132670133448219 26 10058L 10058L -2.1920969546557 -2.49465664272271 0.354854763893431 -1.93155848635714 0.941979400289938 0.978917101414106 0.894860097289736 0.463239402831873 1.12537133317163 1.70528446191955 0.717792714479123 0.645888049108261 0.783968250169388 27 10060Y 10060Y -1.46602269088422 -1.24921677101897 0.307977693653039 -1.55097364660989 0.618908494474798 0.662508171662042 0.475957173906078 0.484718674597707 0.401564892028249 0.55987973254026 -0.376938143754217 -0.933982629228218 0.390013151672955 28 10062C 10062C -1.83317744236881 -1.53268787828701 2.55674262685865 -1.51827745783835 0.789409601746455 0.908747799728588 0.649971922941479 0.668373649931667 1.20058303519903 0.277963256075637 1.2504953198275 3.31370445071638 2.22035828885342 29 10064G 10064G -0.784546628243178 0.276582579543931 3.01104958800057 -1.11978843206758 0.920823858422707 0.750217689886151 1.26153730009639 -0.403363882922417 0.400667296857811 -0.217597941303479 -0.724669537565068 -0.391945338467193 -0.650023936358253 30 10065I 10065I 0.464455916345135 1.3326356122229 -1.23059563374303 -0.357975958937414 1.18249746977104 1.54315938069757 -0.60339041154062 3.38308845958422 0.823740765148641 -0.129951318508883 -0.657979878422938 -0.499534924074273 -0.414476569095651  #describe(cg10k_trait)   Y   =   convert ( Matrix { Float64 },   cg10k_trait [:,   3 : 15 ])  histogram ( Y ,   layout   =   13 )", 
            "title": "Phenotypes"
        }, 
        {
            "location": "/man/heritability/#pre-processing-data-for-heritability-analysis", 
            "text": "To prepare variance component model fitting, we form an instance of  VarianceComponentVariate . The two variance components are $(2\\Phi, I)$.  using   VarianceComponentModels  # form data as VarianceComponentVariate  cg10kdata   =   VarianceComponentVariate ( Y ,   ( 2 \u03a6grm ,   eye ( size ( Y ,   1 ))))  fieldnames ( cg10kdata )   3-element Array{Symbol,1}:\n :Y\n :X\n :V  cg10kdata   VarianceComponentModels.VarianceComponentVariate{Float64,2,Array{Float64,2},Array{Float64,2},Array{Float64,2}}(6670x13 Array{Float64,2}:\n -1.81573   -0.94615     1.11363    \u2026   0.824466  -1.02853     -0.394049 \n -1.2444     0.10966     0.467119       3.08264    1.09065      0.0256616\n  1.45567    1.53867     1.09403       -1.10649   -1.42016     -0.687463 \n -0.768809   0.513491    0.244263       0.394175  -0.767366     0.0635386\n -0.264415  -0.34824    -0.0239065      0.549968   0.540688     0.179675 \n -1.37617   -1.47192     0.29118    \u2026   0.947393   0.594015     0.245407 \n  0.100942  -0.191616   -0.567421       0.332636   0.00269165   0.317117 \n -0.319818   1.35774     0.81869        0.220861   0.852512    -0.225905 \n -0.288334   0.566083    0.254958       0.167532   0.246916     0.539933 \n -1.1576    -0.781199   -0.595808       0.7331    -1.73468     -1.35278  \n  0.740569   1.40874     0.73469    \u2026  -0.712244  -0.313346    -0.345419 \n -0.675892   0.279893    0.267916      -0.809014   0.548522    -0.0201829\n -0.79541   -0.69999     0.39913       -0.369483  -1.10153     -0.598132 \n  \u22ee                                 \u22f1   \u22ee                                \n -0.131005   0.425378   -1.09015        0.35674    0.456428     0.882577 \n -0.52427    1.04173     1.13749        0.366737   1.78286      1.90764  \n  1.32516    0.905899    0.84261    \u2026  -0.418756  -0.275519    -0.912778 \n -1.44368   -2.55708    -0.868193       1.31914   -1.44981     -1.77373  \n -1.8518    -1.25726     1.81724        0.770329  -0.0470789    1.50496  \n -0.810034   0.0896703   0.530939       0.757479   1.10001      1.29115  \n -1.22395   -1.48953    -2.95847        1.29209    0.697478     0.228819 \n -0.282847  -1.54129    -1.38819    \u2026   1.00973   -0.362158    -1.55022  \n  0.475008   1.46697     0.497403       0.141684   0.183218     0.122664 \n -0.408154  -0.325323    0.0850869     -0.2214    -0.575183     0.399583 \n  0.886626   0.487408   -0.0977307     -0.985545  -0.636874    -0.439825 \n -1.24394    0.213697    2.74965        1.39201    0.299931     0.392809 ,6670x0 Array{Float64,2},(\n6670x6670 Array{Float64,2}:\n  1.00583       0.00659955   -0.000232427  \u2026  -0.000129257  -0.00562459 \n  0.00659955    0.99784      -0.00403985       0.00181974    0.00691145 \n -0.000232427  -0.00403985    0.987264         0.00058913   -0.000699707\n  0.00186795   -0.00640781   -0.00372219      -0.00483365   -0.00254155 \n -0.000155086  -0.00721501    0.00362883       0.00427952   -0.00316764 \n  0.00400741    0.00115477    0.005091     \u2026   0.00188751   -3.65987e-6 \n  0.00111701    0.00482842   -0.00375641       0.00243399   -0.00247849 \n -0.00131899    0.00639975   -0.00202991       0.00707293   -0.00048186 \n -0.00205238   -0.00240896   -0.00110924       0.00351173    0.00363799 \n -0.00273677    0.00423992    0.000238256     -0.0029461    -0.00210478 \n -0.00412287    0.000297635  -0.000950353  \u2026  -0.000531045  -0.00212246 \n  0.00190203    0.00334083    0.0036709       -0.00140732   -0.00626668 \n  0.000660883  -0.00180829    0.00602955       0.00150954   -0.00254826 \n  \u22ee                                        \u22f1                            \n  0.00602273    0.00232083    0.00200852       1.33451e-5    0.00614137 \n -0.00428016    0.0054185    -0.00370108      -0.00219871    0.00733631 \n  0.00109348   -0.00485292   -0.00610528   \u2026  -0.00125803    0.00421559 \n -0.00845106   -0.00414261   -0.00218104      -0.00141161   -0.00101611 \n -0.00636811   -0.0015077     0.00624753       0.00105766   -7.21938e-5 \n  0.000860393  -0.00394326    0.0053709       -0.0126635    -0.0104067  \n  0.00442858    0.00169958   -0.00202223      -0.00188626   -0.00124884 \n -0.0045805    -0.000261196   0.000203706  \u2026   0.00168027   -0.00460447 \n -0.00405834    0.00466013   -0.00262013       0.00395595   -0.00102754 \n -0.00192981   -0.00174465   -0.000141344      0.00249404   -0.00591688 \n -0.000129257   0.00181974    0.00058913       1.00197       0.00105123 \n -0.00562459    0.00691145   -0.000699707      0.00105123    1.00158    ,\n\n6670x6670 Array{Float64,2}:\n 1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \u2026  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \u2026  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \u2026  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n \u22ee                        \u22ee              \u22f1            \u22ee                      \n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \u2026  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0  0.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  1.0  0.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \u2026  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  1.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  1.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  1.0  0.0\n 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  1.0))  Before fitting the variance component model, we pre-compute the eigen-decomposition of $2\\Phi_{\\text{GRM}}$, the rotated responses, and the constant part in log-likelihood, and store them as a  TwoVarCompVariateRotate  instance, which is re-used in various variane component estimation procedures.  # pre-compute eigen-decomposition (~50 secs on my laptop)  @ time   cg10kdata_rotated   =   TwoVarCompVariateRotate ( cg10kdata )  fieldnames ( cg10kdata_rotated )    51.297311 seconds (957.07 k allocations: 1.038 GB, 0.32% gc time)\n\n\n\n\n\n4-element Array{Symbol,1}:\n :Yrot    \n :Xrot    \n :eigval  \n :logdetV2", 
            "title": "Pre-processing data for heritability analysis"
        }, 
        {
            "location": "/man/heritability/#save-intermediate-results", 
            "text": "We don't want to re-compute SnpArray and empirical kinship matrices again and again for heritibility analysis.  #using JLD  #@save  cg10k.jld  #whos()   To load workspace  #using SnpArrays, JLD, DataFrames, VarianceComponentModels, Plots  #gr()  #@load  cg10k.jld  #whos()", 
            "title": "Save intermediate results"
        }, 
        {
            "location": "/man/heritability/#heritability-of-single-traits", 
            "text": "We use Fisher scoring algorithm to fit variance component model for each single trait.  # heritability from single trait analysis  hST   =   zeros ( 13 )  # standard errors of estimated heritability  hST_se   =   zeros ( 13 )  # additive genetic effects  \u03c32a   =   zeros ( 13 )  # enviromental effects  \u03c32e   =   zeros ( 13 )  @ time   for   trait   in   1 : 13 \n     println ( names ( cg10k_trait )[ trait   +   2 ]) \n     # form data set for trait j \n     traitj_data   =   TwoVarCompVariateRotate ( cg10kdata_rotated . Yrot [:,   trait ],   cg10kdata_rotated . Xrot ,  \n         cg10kdata_rotated . eigval ,   cg10kdata_rotated . logdetV2 ) \n     # initialize model parameters \n     traitj_model   =   VarianceComponentModel ( traitj_data ) \n     # estimate variance components \n     _ ,   _ ,   _ ,   \u03a3cov ,   _ ,   _   =   mle_fs! ( traitj_model ,   traitj_data ;   solver = : Ipopt ,   verbose = false ) \n     \u03c32a [ trait ]   =   traitj_model . \u03a3 [ 1 ][ 1 ] \n     \u03c32e [ trait ]   =   traitj_model . \u03a3 [ 2 ][ 1 ] \n     @ show   \u03c32a [ trait ],   \u03c32e [ trait ] \n     h ,   hse   =   heritability ( traitj_model . \u03a3 ,   \u03a3cov ) \n     hST [ trait ]   =   h [ 1 ] \n     hST_se [ trait ]   =   hse [ 1 ]  end   Trait1\n\n******************************************************************************\nThis program contains Ipopt, a library for large-scale nonlinear optimization.\n Ipopt is released as open source code under the Eclipse Public License (EPL).\n         For more information visit http://projects.coin-or.org/Ipopt\n******************************************************************************\n\n(\u03c32a[trait],\u03c32e[trait]) = (0.26104123222538084,0.735688443211474)\nTrait2\n(\u03c32a[trait],\u03c32e[trait]) = (0.18874147373002487,0.8106899992330557)\nTrait3\n(\u03c32a[trait],\u03c32e[trait]) = (0.318571927651206,0.6801458862910434)\nTrait4\n(\u03c32a[trait],\u03c32e[trait]) = (0.26556901335366295,0.730358836480852)\nTrait5\n(\u03c32a[trait],\u03c32e[trait]) = (0.28123321199488277,0.7167989046615363)\nTrait6\n(\u03c32a[trait],\u03c32e[trait]) = (0.2829461159340443,0.7165629525047605)\nTrait7\n(\u03c32a[trait],\u03c32e[trait]) = (0.21543856399750066,0.7816211121996341)\nTrait8\n(\u03c32a[trait],\u03c32e[trait]) = (0.19412648726333176,0.805527765060679)\nTrait9\n(\u03c32a[trait],\u03c32e[trait]) = (0.24789561129713544,0.7504615853385027)\nTrait10\n(\u03c32a[trait],\u03c32e[trait]) = (0.100074557877669,0.8998152776356187)\nTrait11\n(\u03c32a[trait],\u03c32e[trait]) = (0.16486778143457112,0.8338002259854702)\nTrait12\n(\u03c32a[trait],\u03c32e[trait]) = (0.0829866038383105,0.9158035671624248)\nTrait13\n(\u03c32a[trait],\u03c32e[trait]) = (0.056842480167674306,0.9423653389084629)\n  5.952183 seconds (49.17 M allocations: 1.102 GB, 5.89% gc time)  # heritability and standard errors  [ hST ;   hST_se ]   2x13 Array{Float64,2}:\n 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0", 
            "title": "Heritability of single traits"
        }, 
        {
            "location": "/man/heritability/#pairwise-traits", 
            "text": "Following code snippet calculates joint heritability among all pairs of traits, a total of 78 bivariate variane component models.  # additive genetic effects (2x2 psd matrices) from bavariate trait analysis;  \u03a3a   =   Array { Matrix { Float64 }}( 13 ,   13 )  # environmental effects (2x2 psd matrices) from bavariate trait analysis;  \u03a3e   =   Array { Matrix { Float64 }}( 13 ,   13 )  @ time   for   i   in   1 : 13 \n     for   j   in   ( i + 1 ): 13 \n         println ( names ( cg10k_trait )[ i   +   2 ],   names ( cg10k_trait )[ j   +   2 ]) \n         # form data set for (trait1, trait2) \n         traitij_data   =   TwoVarCompVariateRotate ( cg10kdata_rotated . Yrot [:,   [ i ; j ]],   cg10kdata_rotated . Xrot ,  \n             cg10kdata_rotated . eigval ,   cg10kdata_rotated . logdetV2 ) \n         # initialize model parameters \n         traitij_model   =   VarianceComponentModel ( traitij_data ) \n         # estimate variance components \n         mle_fs! ( traitij_model ,   traitij_data ;   solver = : Ipopt ,   verbose = false ) \n         \u03a3a [ i ,   j ]   =   traitij_model . \u03a3 [ 1 ] \n         \u03a3e [ i ,   j ]   =   traitij_model . \u03a3 [ 2 ] \n         @ show   \u03a3a [ i ,   j ],   \u03a3e [ i ,   j ] \n     end  end   Trait1Trait2\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26011943486815303 0.1762158250641666\n 0.1762158250641666 0.18737615484318682],\n\n[0.7365894055240527 0.5838920954583557\n 0.5838920954583557 0.8120331390255984])\nTrait1Trait3\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2615639935568583 -0.013126818536804538\n -0.013126818536804538 0.3190566225477499],\n\n[0.7351802111593627 -0.12112674834322068\n -0.12112674834322068 0.6796789899239241])\nTrait1Trait4\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26087960315961645 0.2226144055987542\n 0.2226144055987542 0.26558083276300853],\n\n[0.735845998164204 0.5994353345857374\n 0.5994353345857374 0.7303474474479689])\nTrait1Trait5\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26078303770342093 -0.14701178378027208\n -0.14701178378027208 0.2818772454637467],\n\n[0.7359373011280201 -0.2545838905575993\n -0.2545838905575993 0.7161761242026842])\nTrait1Trait6\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26070703552005153 -0.1293564259272152\n -0.1293564259272152 0.28318838486326464],\n\n[0.7360128807191256 -0.23136128330673647\n -0.23136128330673647 0.7163294323420235])\nTrait1Trait7\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26030750074865355 -0.1402575370658552\n -0.1402575370658552 0.2150805562437876],\n\n[0.736405599875614 -0.19780547644886934\n -0.19780547644886934 0.7819851899273343])\nTrait1Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2610345999109415 -0.033529628072184174\n -0.033529628072184174 0.1941430731435061],\n\n[0.7356949687052194 -0.12627246367045894\n -0.12627246367045894 0.8055115370752971])\nTrait1Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26301631599826725 -0.20486492716403212\n -0.20486492716403212 0.24679565235839057],\n\n[0.733794462308188 -0.30745013667457605\n -0.30745013667457605 0.7515442213436087])\nTrait1Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26089807908154783 -0.09981756181315272\n -0.09981756181315272 0.0970232854366607],\n\n[0.7358279769596973 -0.3036087596209461\n -0.3036087596209461 0.902853465186668])\nTrait1Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2607397076720635 -0.1389834153966234\n -0.1389834153966234 0.16306263185657766],\n\n[0.7359820027777678 -0.3591745321509024\n -0.3591745321509024 0.8355950431882248])\nTrait1Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26306860004688026 -0.14553554987243783\n -0.14553554987243783 0.08051358652010815],\n\n[0.7337809604103112 -0.04169750224640395\n -0.04169750224640395 0.9183594400218908])\nTrait1Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26234367608192977 -0.10889551713434968\n -0.10889551713434968 0.0512940383653612],\n\n[0.7344496461752492 -0.11399558207532524\n -0.11399558207532524 0.9479424007586392])\nTrait2Trait3\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18901532602954713 0.14615743011868396\n 0.14615743011868396 0.32052865893932325],\n\n[0.8104184413491479 0.09749923852720849\n 0.09749923852720849 0.6782713240476694])\nTrait2Trait4\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.1883951499036305 0.07521464811301082\n 0.07521464811301082 0.26555848041382424],\n\n[0.8110301028366897 0.22049483157599306\n 0.22049483157599306 0.7303691342557705])\nTrait2Trait5\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18871644002070298 -0.011314018224773681\n -0.011314018224773681 0.2812465335272833],\n\n[0.8107145247899494 -0.03701047017353238\n -0.03701047017353238 0.7167859986683998])\nTrait2Trait6\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.1887737598357356 -0.003106603698693131\n -0.003106603698693131 0.28301251325921034],\n\n[0.8106583657770059 -0.021182656859616053\n -0.021182656859616053 0.7164985874165493])\nTrait2Trait7\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.1883522257152029 -0.02995792853329811\n -0.02995792853329811 0.21518854249006697],\n\n[0.8110719442645782 -0.00136938653417689\n -0.00136938653417689 0.7818678818050632])\nTrait2Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18926168900224644 0.033142298438513934\n 0.033142298438513934 0.19466629556574452],\n\n[0.8101822287413256 -0.03260027070436449\n -0.03260027070436449 0.8050045055360936])\nTrait2Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.1872848956280239 -0.08541458777076169\n -0.08541458777076169 0.24671880340715757],\n\n[0.8121330455990424 -0.08087908481224644\n -0.08087908481224644 0.7516171286963302])\nTrait2Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.1889645629678981 -0.12531880400449946\n -0.12531880400449946 0.10012137188898965],\n\n[0.8104983819152255 -0.2710710218717953\n -0.2710710218717953 0.8998490679544218])\nTrait2Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18776200371995733 -0.11847920330746468\n -0.11847920330746468 0.16627341912957957],\n\n[0.8116528153514335 -0.29554899494751774\n -0.29554899494751774 0.8324372717265173])\nTrait2Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18819063520893153 -0.09053833116231333\n -0.09053833116231333 0.08226341390714831],\n\n[0.8112716597628467 0.04542203421221531\n 0.04542203421221531 0.9165863321400829])\nTrait2Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.18826030571365 -0.07070412373503615\n -0.07070412373503615 0.05472389418108183],\n\n[0.8112166105461245 0.07379770159309924\n 0.07379770159309924 0.9445208397201135])\nTrait3Trait4\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.31852039540025556 -0.15433893723722844\n -0.15433893723722844 0.26475409905630554],\n\n[0.6801958865832615 -0.3034399519741299\n -0.3034399519741299 0.731151851539042])\nTrait3Trait5\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.31896997787115844 0.1843544667615588\n 0.1843544667615588 0.2825001772391643],\n\n[0.6797599597904634 0.3364105248325953\n 0.3364105248325953 0.7155665412290728])\nTrait3Trait6\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.3195663644223704 0.16663988772541583\n 0.16663988772541583 0.2850313182313418],\n\n[0.6791832508340369 0.2976976595424014\n 0.2976976595424014 0.7145358499994827])\nTrait3Trait7\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.3185755051463484 0.16685216000557962\n 0.16685216000557962 0.21523224226058452],\n\n[0.6801424314852816 0.3471388423837074\n 0.3471388423837074 0.781823130994699])\nTrait3Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.32049923480743736 0.05753194037721402\n 0.05753194037721402 0.19724489854138733],\n\n[0.6782830498088369 0.04425974188401513\n 0.04425974188401513 0.802473783266528])\nTrait3Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.31871912001262215 0.13729240537832613\n 0.13729240537832613 0.24697586633940616],\n\n[0.6800039145595509 0.2671054378272429\n 0.2671054378272429 0.7513573840671314])\nTrait3Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.3189152132179772 -0.0786338234436915\n -0.0786338234436915 0.10110317193796312],\n\n[0.679814558884657 -0.14078871656902353\n -0.14078871656902353 0.8987982713072635])\nTrait3Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.3178223304600456 -0.01798395917145184\n -0.01798395917145184 0.16474292116632128],\n\n[0.6808712744789884 -0.11416573111718417\n -0.11416573111718417 0.8339228729000641])\nTrait3Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.3208883401716964 0.08452483760009306\n 0.08452483760009306 0.0869867503171365],\n\n[0.6779139477279349 0.0340132717811355\n 0.0340132717811355 0.9118411342532936])\nTrait3Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.32300879330585164 0.11068106826965814\n 0.11068106826965814 0.06117389943402113],\n\n[0.6759011385390731 -0.007296623864558913\n -0.007296623864558913 0.9380722549857157])\nTrait4Trait5\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26566699036169605 -0.2158475608286269\n -0.2158475608286269 0.28291866201101923],\n\n[0.7302544030223196 -0.376675282891704\n -0.376675282891704 0.7151643527045644])\nTrait4Trait6\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26614305300873853 -0.20063378204267554\n -0.20063378204267554 0.2844419499822279],\n\n[0.7297943215353132 -0.3468040727719556\n -0.3468040727719556 0.7151119490174423])\nTrait4Trait7\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2644898029398779 -0.18275157344131776\n -0.18275157344131776 0.2141168002388134],\n\n[0.7314145610167773 -0.3261719955266139\n -0.3261719955266139 0.7829351279927492])\nTrait4Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26669395421675546 -0.09763540115429367\n -0.09763540115429367 0.1961260872033616],\n\n[0.7292655955847159 -0.15036048225408044\n -0.15036048225408044 0.8035709853965969])\nTrait4Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.27003652025292474 -0.22740698731918993\n -0.22740698731918993 0.2480458221785815],\n\n[0.7260245141067312 -0.4156014356566848\n -0.4156014356566848 0.7502976667276586])\nTrait4Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2655429418281044 -0.03381072154126782\n -0.03381072154126782 0.0996098263599129],\n\n[0.7303952879665676 -0.22772490049078267\n -0.22772490049078267 0.9002752447772486])\nTrait4Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2656276022067445 -0.0967400332453423\n -0.0967400332453423 0.16327409086062875],\n\n[0.7303019079378218 -0.2726111957424877\n -0.2726111957424877 0.8353713025165547])\nTrait4Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26816369655143846 -0.14161261171741682\n -0.14161261171741682 0.08039677346947334],\n\n[0.7278825933041443 -0.08284654589719648\n -0.08284654589719648 0.9184455609265872])\nTrait4Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.26617123205334886 -0.09807308729740324\n -0.09807308729740324 0.05401019174697443],\n\n[0.7297749332697795 -0.22505950767079727\n -0.22505950767079727 0.9452044744732253])\nTrait5Trait6\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2815916529117581 0.28089837189876277\n 0.28089837189876277 0.2822980504457378],\n\n[0.7164553609388885 0.6603676496624155\n 0.6603676496624155 0.7171950644786848])\nTrait5Trait7\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28081437389685465 0.2320998689028785\n 0.2320998689028785 0.21166204276578496],\n\n[0.7172180317128432 0.6743038172539134\n 0.6743038172539134 0.7853426270933965])\nTrait5Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28134012176547224 0.16394787427644833\n 0.16394787427644833 0.19270331039789454],\n\n[0.716700910916717 0.22103210912788746\n 0.22103210912788746 0.8069220956459742])\nTrait5Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2838778024864278 0.24453172568336923\n 0.24453172568336923 0.24129303734496713],\n\n[0.7142441395374184 0.5084169870279653\n 0.5084169870279653 0.75689423383449])\nTrait5Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2818130149579839 -0.04621141466318818\n -0.04621141466318818 0.10148069053702076],\n\n[0.7162383352810132 -0.05721113478873817\n -0.05721113478873817 0.8984242888549007])\nTrait5Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28042354198276 0.020249545578616107\n 0.020249545578616107 0.16400332024863942],\n\n[0.7175856258522051 -0.03524364742481622\n -0.03524364742481622 0.8346493308274309])\nTrait5Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28142706977067977 0.0616130662199462\n 0.0616130662199462 0.08271662802494333],\n\n[0.7166145561763498 0.05292864493625416\n 0.05292864493625416 0.9160739286144334])\nTrait5Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2822915336770548 0.07042205168959345\n 0.07042205168959345 0.05694630997371182],\n\n[0.7157823114671132 0.05283744551208099\n 0.05283744551208099 0.9422684292501169])\nTrait6Trait7\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28296107605405046 0.22065632106005845\n 0.22065632106005845 0.2138560977045212],\n\n[0.7165486719516274 0.5810829183804748\n 0.5810829183804748 0.7831785715682008])\nTrait6Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2829606227323868 0.18407962647041584\n 0.18407962647041584 0.19237902250043631],\n\n[0.7165491133456647 0.4365973893626811\n 0.4365973893626811 0.8072460050916037])\nTrait6Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2849784406224258 0.23443573773563228\n 0.23443573773563228 0.24320710809890078],\n\n[0.7146005305248684 0.4768263391920377\n 0.4768263391920377 0.7550279957443258])\nTrait6Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28365475689742714 -0.043548481043600644\n -0.043548481043600644 0.10202532158188515],\n\n[0.7158768651026055 -0.05916812562687212\n -0.05916812562687212 0.8978859540367762])\nTrait6Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2815224136591653 0.027999198497497716\n 0.027999198497497716 0.16342991310189497],\n\n[0.7179464769862334 -0.05241060710393953\n -0.05241060710393953 0.8352130875902175])\nTrait6Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.28311434441170164 0.05713989944414399\n 0.05713989944414399 0.0826789313035068],\n\n[0.7164030333437527 0.04791987131194029\n 0.04791987131194029 0.9161120298125991])\nTrait6Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2838199671572152 0.06112120329707695\n 0.06112120329707695 0.057081689708499625],\n\n[0.7157217792743793 0.0532698347458057\n 0.0532698347458057 0.9421333545367362])\nTrait7Trait8\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2138568636062993 0.08845552117563456\n 0.08845552117563456 0.19237305507185362],\n\n[0.7831777634587772 -0.056833059546840724\n -0.056833059546840724 0.8072518674868492])\nTrait7Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2187556960318311 0.21704186383319593\n 0.21704186383319593 0.24414386504096938],\n\n[0.7784327750408729 0.4629009682465131\n 0.4629009682465131 0.7541229287887962])\nTrait7Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.21627296245459482 -0.042114572555895034\n -0.042114572555895034 0.10209048393905551],\n\n[0.7808073891153632 -0.0859074527248701\n -0.0859074527248701 0.8978220136433211])\nTrait7Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.214068776570261 0.020696687537510253\n 0.020696687537510253 0.16347380945463358],\n\n[0.7829608191256512 -0.04814801124193434\n -0.04814801124193434 0.8351704867201007])\nTrait7Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.21493232507095117 0.07578743223256132\n 0.07578743223256132 0.08087309077615555],\n\n[0.7821316768241421 0.03469555448086824\n 0.03469555448086824 0.9179149818382321])\nTrait7Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.21595864338688792 0.07493726652193226\n 0.07493726652193226 0.054593411293268314],\n\n[0.7811387334966593 0.038905793654869604\n 0.038905793654869604 0.9446215737969718])\nTrait8Trait9\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.1945549993508713 0.11281615771703897\n 0.11281615771703897 0.247244151913094],\n\n[0.8051240570328738 0.18477843242872458\n 0.18477843242872458 0.7510982278178284])\nTrait8Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.1944410026133888 -0.015634153645910635\n -0.015634153645910635 0.10042647889553495],\n\n[0.8052215712374999 0.011982589675582881\n 0.011982589675582881 0.8994678453427947])\nTrait8Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.19385316433932662 0.02253246401737779\n 0.02253246401737779 0.16466854383170343],\n\n[0.8057962945707323 -0.027274736865623306\n -0.027274736865623306 0.833996968298484])\nTrait8Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.19395121849388605 -0.00287601218605317\n -0.00287601218605317 0.08285727476214352],\n\n[0.805699796364685 0.03361278792998698\n 0.03361278792998698 0.9159318672850477])\nTrait8Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.19397976155591182 0.004078666572513058\n 0.004078666572513058 0.056907123220398724],\n\n[0.8056716012385241 0.037881707520808355\n 0.037881707520808355 0.9423010776521313])\nTrait9Trait10\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.24729383232846244 -0.0023083632339188282\n -0.0023083632339188282 0.09982638783604271],\n\n[0.7510505981827851 0.07407294366362593\n 0.07407294366362593 0.9000613327580784])\nTrait9Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.24782344372399562 0.03182350298547301\n 0.03182350298547301 0.16489046411211802],\n\n[0.7505321390729256 0.15228537870520292\n 0.15228537870520292 0.8337779553469964])\nTrait9Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.2503346951480958 0.08457136153453912\n 0.08457136153453912 0.08875872341182169],\n\n[0.7480909649325541 0.1077563215164905\n 0.1077563215164905 0.910108091340272])\nTrait9Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.24944189418695698 0.09348451303646096\n 0.09348451303646096 0.05793201495098822],\n\n[0.7489745640198023 0.09821909823020973\n 0.09821909823020973 0.9413348855377766])\nTrait10Trait11\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.09313966828035954 0.10003371877497542\n 0.10003371877497542 0.16495492788508725],\n\n[0.9067034447680414 0.47442665936453843\n 0.47442665936453843 0.8337151519497663])\nTrait10Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.09672471644137419 0.05640434659676373\n 0.05640434659676373 0.07945282707687533],\n\n[0.9031497841187028 0.08532319187509019\n 0.08532319187509019 0.91933434342665])\nTrait10Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.10098492172122948 -0.027991587710857326\n -0.027991587710857326 0.05783694113832583],\n\n[0.8989368215833939 0.16605077488640077\n 0.16605077488640077 0.9413901799217301])\nTrait11Trait12\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.16384057742661823 0.05703178017251179\n 0.05703178017251179 0.07921436807844635],\n\n[0.8348140972530623 0.14559650973720015\n 0.14559650973720015 0.9195521322043868])\nTrait11Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.16488293337335094 -0.0015841372093299245\n -0.0015841372093299245 0.05749684375147145],\n\n[0.8337979488908841 0.2006122283482765\n 0.2006122283482765 0.9417152320985648])\nTrait12Trait13\n(\u03a3a[i,j],\u03a3e[i,j]) = (\n[0.08314058460338657 -0.30414162669938277\n -0.30414162669938277 6.1516805202088326e7],\n\n[0.9156535422859348 0.20300255194828656\n 0.20300255194828656 7.289623734162273e9])\n 73.287758 seconds (3.33 G allocations: 50.885 GB, 10.69% gc time)", 
            "title": "Pairwise traits"
        }, 
        {
            "location": "/man/heritability/#5-trait-analysis", 
            "text": "Researchers want to jointly analyze traits 5-9. Our strategy is to try both Fisher scoring and MM algorithm with different starting point, and choose the best local optimum. We first form the data set and run Fisher scoring, which yields a final objective value 8.6836898e+03.  traitidx   =   5 : 9  # form data set  trait59_data   =   TwoVarCompVariateRotate ( cg10kdata_rotated . Yrot [:,   traitidx ],   cg10kdata_rotated . Xrot ,  \n     cg10kdata_rotated . eigval ,   cg10kdata_rotated . logdetV2 )  # initialize model parameters  trait59_model   =   VarianceComponentModel ( trait59_data )  # estimate variance components  @ time   mle_fs! ( trait59_model ,   trait59_data ;   solver = : Knitro ,   verbose = true )  trait59_model   Knitro   10 .1.0   STUDENT   LICENSE   ( problem   size   limit   =   300 )  ======================================= \n             Student   License \n        ( NOT   FOR   COMMERCIAL   USE ) \n          Artelys   Knitro   10 .1.0  =======================================  Knitro   presolve   eliminated   0   variables   and   0   constraints .  algorithm :              1  The   problem   is   identified   as   bound   constrained   only .  Knitro   changing   bar_initpt   from   AUTO   to   3 .  Knitro   changing   bar_murule   from   AUTO   to   4 .  Knitro   changing   bar_penaltycons   from   AUTO   to   1 .  Knitro   changing   bar_penaltyrule   from   AUTO   to   2 .  Knitro   changing   bar_switchrule   from   AUTO   to   1 .  Knitro   changing   linsolver   from   AUTO   to   2 .  Problem   Characteristics                      (   Presolved )  -----------------------  Objective   goal :    Maximize  Number   of   variables :                      30   (          30 ) \n     bounded   below :                        10   (          10 ) \n     bounded   above :                         0   (           0 ) \n     bounded   below   and   above :               0   (           0 ) \n     fixed :                                 0   (           0 ) \n     free :                                 20   (          20 )  Number   of   constraints :                     0   (           0 ) \n     linear   equalities :                     0   (           0 ) \n     nonlinear   equalities :                  0   (           0 ) \n     linear   inequalities :                   0   (           0 ) \n     nonlinear   inequalities :                0   (           0 ) \n     range :                                 0   (           0 )  Number   of   nonzeros   in   Jacobian :            0   (           0 )  Number   of   nonzeros   in   Hessian :           465   (         465 ) \n\n   Iter        Objective        FeasError     OptError      || Step ||      CGits   --------    --------------    ----------    ----------    ----------    ------- \n        0     -5 .042149e + 04     0 .000e + 00 \n       10     -1 .677917e + 04     0 .000e + 00     1 .102e + 03     8 .413e-02          0 \n       20     -1 .531001e + 03     0 .000e + 00     1 .489e + 04     2 .670e-03          0 \n       30      8 .342379e + 03     0 .000e + 00     8 .574e + 03     4 .155e-04          7 \n       40      8 .638819e + 03     0 .000e + 00     3 .597e + 03     7 .576e-05         63 \n       50      8 .673858e + 03     0 .000e + 00     3 .459e + 03     1 .426e-04          5 \n       60      8 .683483e + 03     0 .000e + 00     5 .619e + 02     4 .284e-06          5 \n       70      8 .683690e + 03     0 .000e + 00     4 .927e + 02     1 .183e-08          8 \n       78      8 .683690e + 03     0 .000e + 00     4 .927e + 02     9 .036e-17         12  EXIT :   Primal   feasible   solution ;   terminate   because   the   relative   change   in \n       solution   estimate     xtol .  Final   Statistics  ----------------  Final   objective   value                 =     8 .68368980794010e + 03  Final   feasibility   error   ( abs   /   rel )   =     0 .00e + 00   /   0 .00e + 00  Final   optimality   error    ( abs   /   rel )   =     4 .93e + 02   /   1 .00e + 00  #   of   iterations                       =           78   #   of   CG   iterations                    =          742   #   of   function   evaluations             =          420  #   of   gradient   evaluations             =           79  #   of   Hessian   evaluations              =           76  Total   program   time   ( secs )             =         8 .49573   (       8 .460   CPU   time )  Time   spent   in   evaluations   ( secs )      =         8 .47474  =============================================================================== \n\n   8 .877926   seconds   ( 398 .54   M   allocations :   6 .096   GB ,   15 .25 %   gc   time )  ###   Could   not   find   a   valid   license . \n     Your   machine   ID   is   e2-9d-cc-64-5f . \n     Please   contact   licensing @artelys .com   or   your   local   distributor   to   obtain   a   license . \n     If   you   already   have   a   license ,   please   execute   ` get_machine_ID   -v `   and   send   the   output   to   support .  VarianceComponentModels .VarianceComponentModel { Float64 , 2 , Array { Float64 , 2 } , Array { Float64 , 2 }} ( 0x5   Array { Float64 , 2 } ,(  5x5   Array { Float64 , 2 } : \n  0 .31512     0 .319157    0 .250341    0 .204466    0 .24944  \n  0 .319157    0 .329653    0 .241834    0 .233293    0 .247452 \n  0 .250341    0 .241834    0 .221271    0 .113265    0 .208544 \n  0 .204466    0 .233293    0 .113265    0 .241484    0 .139501 \n  0 .24944     0 .247452    0 .208544    0 .139501    0 .376927 ,  5x5   Array { Float64 , 2 } : \n  0 .688825    0 .632998     0 .657586      0 .196702     0 .528705 \n  0 .632998    0 .685078     0 .56295       0 .408814     0 .507746 \n  0 .657586    0 .56295      0 .775116     -0 .0757512    0 .501867 \n  0 .196702    0 .408814    -0 .0757512     0 .78627      0 .191494 \n  0 .528705    0 .507746     0 .501867      0 .191494     0 .756279 ), 0x0   Array { Float64 , 2 } , Char [] , Float64 [] , -Inf , Inf )   We then run the MM algorithm, starting from the Fisher scoring answer. MM finds an improved solution with objective value 8.955397e+03.  # trait59_model contains the fitted model by Fisher scoring now  @ time   mle_mm! ( trait59_model ,   trait59_data ;   verbose = true )  trait59_model        MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0   8.683690e+03\n       1   8.749335e+03\n       2   8.769373e+03\n       3   8.775609e+03\n       4   8.777713e+03\n       5   8.778568e+03\n       6   8.779034e+03\n       7   8.779373e+03\n       8   8.779666e+03\n       9   8.779940e+03\n      10   8.780204e+03\n      20   8.782575e+03\n      30   8.784706e+03\n      40   8.786833e+03\n      50   8.789198e+03\n      60   8.792077e+03\n      70   8.795815e+03\n      80   8.800822e+03\n      90   8.807545e+03\n     100   8.816372e+03\n     110   8.827478e+03\n     120   8.840646e+03\n     130   8.855183e+03\n     140   8.870054e+03\n     150   8.884191e+03\n     160   8.896801e+03\n     170   8.907505e+03\n     180   8.916279e+03\n     190   8.923318e+03\n     200   8.928908e+03\n     210   8.933336e+03\n     220   8.936854e+03\n     230   8.939668e+03\n     240   8.941938e+03\n     250   8.943788e+03\n     260   8.945309e+03\n     270   8.946573e+03\n     280   8.947632e+03\n     290   8.948528e+03\n     300   8.949292e+03\n     310   8.949948e+03\n     320   8.950516e+03\n     330   8.951009e+03\n     340   8.951441e+03\n     350   8.951820e+03\n     360   8.952155e+03\n     370   8.952453e+03\n     380   8.952717e+03\n     390   8.952954e+03\n     400   8.953165e+03\n     410   8.953356e+03\n     420   8.953527e+03\n     430   8.953682e+03\n     440   8.953823e+03\n     450   8.953950e+03\n     460   8.954066e+03\n     470   8.954171e+03\n     480   8.954267e+03\n     490   8.954355e+03\n     500   8.954435e+03\n     510   8.954509e+03\n     520   8.954576e+03\n     530   8.954638e+03\n     540   8.954695e+03\n     550   8.954748e+03\n     560   8.954796e+03\n     570   8.954841e+03\n     580   8.954882e+03\n     590   8.954920e+03\n     600   8.954955e+03\n     610   8.954987e+03\n     620   8.955017e+03\n     630   8.955045e+03\n     640   8.955071e+03\n     650   8.955094e+03\n     660   8.955117e+03\n     670   8.955137e+03\n     680   8.955156e+03\n     690   8.955174e+03\n     700   8.955190e+03\n     710   8.955205e+03\n     720   8.955219e+03\n     730   8.955233e+03\n     740   8.955245e+03\n     750   8.955256e+03\n     760   8.955267e+03\n     770   8.955276e+03\n     780   8.955286e+03\n     790   8.955294e+03\n     800   8.955302e+03\n     810   8.955309e+03\n     820   8.955316e+03\n     830   8.955323e+03\n     840   8.955329e+03\n     850   8.955334e+03\n     860   8.955339e+03\n     870   8.955344e+03\n     880   8.955349e+03\n     890   8.955353e+03\n     900   8.955357e+03\n     910   8.955360e+03\n     920   8.955364e+03\n     930   8.955367e+03\n     940   8.955370e+03\n     950   8.955372e+03\n     960   8.955375e+03\n     970   8.955377e+03\n     980   8.955380e+03\n     990   8.955382e+03\n    1000   8.955384e+03\n    1010   8.955385e+03\n    1020   8.955387e+03\n    1030   8.955389e+03\n    1040   8.955390e+03\n    1050   8.955391e+03\n    1060   8.955393e+03\n    1070   8.955394e+03\n    1080   8.955395e+03\n    1090   8.955396e+03\n    1100   8.955397e+03\n\n 10.940231 seconds (375.19 M allocations: 9.267 GB, 19.34% gc time)\n\n\n\n\n\nVarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(0x5 Array{Float64,2},(\n5x5 Array{Float64,2}:\n 0.261514  0.273061  0.22074    0.167275   0.216444\n 0.273061  0.290848  0.219592   0.198638   0.218758\n 0.22074   0.219592  0.207146   0.0954691  0.19478 \n 0.167275  0.198638  0.0954691  0.207501   0.110312\n 0.216444  0.218758  0.19478    0.110312   0.216043,\n\n5x5 Array{Float64,2}:\n 0.735836  0.667979   0.685261    0.21787    0.535609\n 0.667979  0.708913   0.582131    0.42248    0.492028\n 0.685261  0.582131   0.789681   -0.0636001  0.484483\n 0.21787   0.42248   -0.0636001   0.792537   0.187238\n 0.535609  0.492028   0.484483    0.187238   0.781172),0x0 Array{Float64,2},Char[],Float64[],-Inf,Inf)  Do another run of MM algorithm from default starting point. It leads to a slightly better local optimum 8.957172e+03. Follow up anlaysis should use this result.  # default starting point  trait59_model   =   VarianceComponentModel ( trait59_data )  @ time   _ ,   _ ,   _ ,   \u03a3cov ,   =   mle_mm! ( trait59_model ,   trait59_data ;   verbose = true )  trait59_model        MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0  -5.042149e+04\n       1  -1.699687e+04\n       2  -1.543968e+03\n       3   5.143609e+03\n       4   7.669359e+03\n       5   8.489390e+03\n       6   8.728893e+03\n       7   8.796019e+03\n       8   8.815880e+03\n       9   8.823279e+03\n      10   8.827419e+03\n      20   8.854389e+03\n      30   8.874943e+03\n      40   8.890795e+03\n      50   8.903062e+03\n      60   8.912619e+03\n      70   8.920130e+03\n      80   8.926088e+03\n      90   8.930861e+03\n     100   8.934721e+03\n     110   8.937872e+03\n     120   8.940467e+03\n     130   8.942622e+03\n     140   8.944425e+03\n     150   8.945946e+03\n     160   8.947237e+03\n     170   8.948339e+03\n     180   8.949287e+03\n     190   8.950106e+03\n     200   8.950818e+03\n     210   8.951439e+03\n     220   8.951983e+03\n     230   8.952462e+03\n     240   8.952886e+03\n     250   8.953262e+03\n     260   8.953597e+03\n     270   8.953896e+03\n     280   8.954164e+03\n     290   8.954404e+03\n     300   8.954621e+03\n     310   8.954817e+03\n     320   8.954994e+03\n     330   8.955154e+03\n     340   8.955300e+03\n     350   8.955433e+03\n     360   8.955555e+03\n     370   8.955666e+03\n     380   8.955767e+03\n     390   8.955860e+03\n     400   8.955946e+03\n     410   8.956025e+03\n     420   8.956097e+03\n     430   8.956164e+03\n     440   8.956226e+03\n     450   8.956283e+03\n     460   8.956336e+03\n     470   8.956385e+03\n     480   8.956430e+03\n     490   8.956473e+03\n     500   8.956512e+03\n     510   8.956549e+03\n     520   8.956583e+03\n     530   8.956615e+03\n     540   8.956645e+03\n     550   8.956673e+03\n     560   8.956699e+03\n     570   8.956723e+03\n     580   8.956746e+03\n     590   8.956768e+03\n     600   8.956788e+03\n     610   8.956807e+03\n     620   8.956825e+03\n     630   8.956842e+03\n     640   8.956858e+03\n     650   8.956873e+03\n     660   8.956887e+03\n     670   8.956900e+03\n     680   8.956913e+03\n     690   8.956925e+03\n     700   8.956936e+03\n     710   8.956947e+03\n     720   8.956957e+03\n     730   8.956967e+03\n     740   8.956976e+03\n     750   8.956985e+03\n     760   8.956994e+03\n     770   8.957001e+03\n     780   8.957009e+03\n     790   8.957016e+03\n     800   8.957023e+03\n     810   8.957030e+03\n     820   8.957036e+03\n     830   8.957042e+03\n     840   8.957048e+03\n     850   8.957053e+03\n     860   8.957058e+03\n     870   8.957064e+03\n     880   8.957068e+03\n     890   8.957073e+03\n     900   8.957077e+03\n     910   8.957082e+03\n     920   8.957086e+03\n     930   8.957090e+03\n     940   8.957093e+03\n     950   8.957097e+03\n     960   8.957100e+03\n     970   8.957104e+03\n     980   8.957107e+03\n     990   8.957110e+03\n    1000   8.957113e+03\n    1010   8.957116e+03\n    1020   8.957119e+03\n    1030   8.957121e+03\n    1040   8.957124e+03\n    1050   8.957126e+03\n    1060   8.957129e+03\n    1070   8.957131e+03\n    1080   8.957133e+03\n    1090   8.957135e+03\n    1100   8.957138e+03\n    1110   8.957140e+03\n    1120   8.957141e+03\n    1130   8.957143e+03\n    1140   8.957145e+03\n    1150   8.957147e+03\n    1160   8.957149e+03\n    1170   8.957150e+03\n    1180   8.957152e+03\n    1190   8.957153e+03\n    1200   8.957155e+03\n    1210   8.957156e+03\n    1220   8.957158e+03\n    1230   8.957159e+03\n    1240   8.957160e+03\n    1250   8.957161e+03\n    1260   8.957163e+03\n    1270   8.957164e+03\n    1280   8.957165e+03\n    1290   8.957166e+03\n    1300   8.957167e+03\n    1310   8.957168e+03\n    1320   8.957169e+03\n    1330   8.957170e+03\n    1340   8.957171e+03\n    1350   8.957172e+03\n\n 13.052188 seconds (455.86 M allocations: 11.254 GB, 19.84% gc time)\n\n\n\n\n\nVarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(0x5 Array{Float64,2},(\n5x5 Array{Float64,2}:\n 0.28408   0.282346  0.235651   0.163231   0.243528\n 0.282346  0.287797  0.222888   0.189209   0.231229\n 0.235651  0.222888  0.215833   0.0895747  0.212778\n 0.163231  0.189209  0.0895747  0.199473   0.107541\n 0.243528  0.231229  0.212778   0.107541   0.246379,\n\n5x5 Array{Float64,2}:\n 0.714039  0.65898    0.67085     0.221737   0.509435\n 0.65898   0.711746   0.578905    0.431453   0.480001\n 0.67085   0.578905   0.781276   -0.0579601  0.467102\n 0.221737  0.431453  -0.0579601   0.800138   0.189943\n 0.509435  0.480001   0.467102    0.189943   0.751844),0x0 Array{Float64,2},Char[],Float64[],-Inf,Inf)  Heritability from 5-variate estimate and their standard errors.  h ,   hse   =   heritability ( trait59_model . \u03a3 ,   \u03a3cov )  [ h ;   hse ]   2x5 Array{Float64,2}:\n 0.284615   0.287928   0.216459   0.199551  0.246817 \n 0.0773858  0.0769331  0.0836844  0.085051  0.0809202", 
            "title": "5-trait analysis"
        }, 
        {
            "location": "/man/heritability/#13-trait-analysis", 
            "text": "Researchers would like to jointly analyze all 13 traits. Fisher scoring algorithm (with KNITRO backend) ends with objective value of -6.839422e+04.  # initialize model parameters  alltrait_model   =   VarianceComponentModel ( cg10kdata_rotated )  # estimate variance components  @ time   mle_fs! ( alltrait_model ,   cg10kdata_rotated ;   solver = : Knitro ,   verbose = true )  alltrait_model   Knitro   10 .1.0   STUDENT   LICENSE   ( problem   size   limit   =   300 )  ======================================= \n             Student   License \n        ( NOT   FOR   COMMERCIAL   USE ) \n          Artelys   Knitro   10 .1.0  =======================================  Knitro   presolve   eliminated   0   variables   and   0   constraints .  algorithm :              1  The   problem   is   identified   as   bound   constrained   only .  Knitro   changing   bar_initpt   from   AUTO   to   3 .  Knitro   changing   bar_murule   from   AUTO   to   4 .  Knitro   changing   bar_penaltycons   from   AUTO   to   1 .  Knitro   changing   bar_penaltyrule   from   AUTO   to   2 .  Knitro   changing   bar_switchrule   from   AUTO   to   1 .  Knitro   changing   linsolver   from   AUTO   to   2 .  Problem   Characteristics                      (   Presolved )  -----------------------  Objective   goal :    Maximize  Number   of   variables :                     182   (         182 ) \n     bounded   below :                        26   (          26 ) \n     bounded   above :                         0   (           0 ) \n     bounded   below   and   above :               0   (           0 ) \n     fixed :                                 0   (           0 ) \n     free :                                156   (         156 )  Number   of   constraints :                     0   (           0 ) \n     linear   equalities :                     0   (           0 ) \n     nonlinear   equalities :                  0   (           0 ) \n     linear   inequalities :                   0   (           0 ) \n     nonlinear   inequalities :                0   (           0 ) \n     range :                                 0   (           0 )  Number   of   nonzeros   in   Jacobian :            0   (           0 )  Number   of   nonzeros   in   Hessian :         16653   (       16653 ) \n\n   Iter        Objective        FeasError     OptError      || Step ||      CGits   --------    --------------    ----------    ----------    ----------    ------- \n        0     -1 .311337e + 05     0 .000e + 00 \n       10     -7 .616310e + 04     0 .000e + 00     8 .995e + 02     4 .820e-01          0 \n       20     -6 .839422e + 04     0 .000e + 00     2 .109e + 03     0 .000e + 00         38  EXIT :   Primal   feasible   solution ;   terminate   because   the   relative   change   in \n       solution   estimate     xtol .  Final   Statistics  ----------------  Final   objective   value                 =    -6 .83942246370272e + 04  Final   feasibility   error   ( abs   /   rel )   =     0 .00e + 00   /   0 .00e + 00  Final   optimality   error    ( abs   /   rel )   =     2 .11e + 03   /   1 .00e + 00  #   of   iterations                       =           21   #   of   CG   iterations                    =          358   #   of   function   evaluations             =          114  #   of   gradient   evaluations             =           22  #   of   Hessian   evaluations              =           20  Total   program   time   ( secs )             =        15 .45499   (      28 .004   CPU   time )  Time   spent   in   evaluations   ( secs )      =        15 .41301  =============================================================================== \n\n  16 .196635   seconds   ( 734 .69   M   allocations :   11 .184   GB ,   18 .44 %   gc   time )  ###   Could   not   find   a   valid   license . \n     Your   machine   ID   is   e2-9d-cc-64-5f . \n     Please   contact   licensing @artelys .com   or   your   local   distributor   to   obtain   a   license . \n     If   you   already   have   a   license ,   please   execute   ` get_machine_ID   -v `   and   send   the   output   to   support .  VarianceComponentModels .VarianceComponentModel { Float64 , 2 , Array { Float64 , 2 } , Array { Float64 , 2 }} ( 0x13   Array { Float64 , 2 } ,(  13x13   Array { Float64 , 2 } : \n   0 .314331      0 .132105       -0 .0353743     \u2026    -0 .136065      -0 .105679   \n   0 .132105      0 .139835        0 .140532         -0 .0173756     -0 .00454843 \n  -0 .0353743     0 .140532        0 .356882          0 .0759456      0 .0921647  \n   0 .343477      0 .054447       -0 .20584          -0 .178914      -0 .150596   \n  -0 .129413      0 .0162518       0 .189194          0 .074017       0 .0695955  \n  -0 .113535      0 .00983593      0 .160915      \u2026     0 .0670008      0 .0576629  \n  -0 .103928      0 .012809        0 .16756           0 .0753421      0 .0715201  \n  -0 .0549071     0 .000400283     0 .0502762         0 .00854523     0 .00326281 \n  -0 .205264     -0 .0387588       0 .153961          0 .0858418      0 .0789957  \n  -0 .147011     -0 .0856788      -0 .064831          0 .12759        0 .0730245  \n  -0 .155356     -0 .0717934      -0 .00878633    \u2026     0 .0945906      0 .0510817  \n  -0 .136065     -0 .0173756       0 .0759456         0 .357044       0 .236415   \n  -0 .105679     -0 .00454843      0 .0921647         0 .236415       0 .24394     ,  13x13   Array { Float64 , 2 } : \n   0 .701526      0 .640432      -0 .0964342    \u2026    -0 .352486     -0 .0542532    -0 .125562  \n   0 .640432      0 .884372       0 .107444        -0 .340323     -0 .0140205     0 .0218768 \n  -0 .0964342     0 .107444       0 .649201        -0 .127019      0 .0354407     0 .0121441 \n   0 .496518      0 .241287      -0 .254125        -0 .219282     -0 .0580118    -0 .19055   \n  -0 .282266     -0 .0653499      0 .327741        -0 .0412117     0 .0425152     0 .0545268 \n  -0 .259093     -0 .0348929      0 .297623     \u2026    -0 .0583661     0 .0376783     0 .0533446 \n  -0 .249        -0 .0489288      0 .349755        -0 .0283019     0 .0338332     0 .0434008 \n  -0 .105542      0 .00459972     0 .0387758       -0 .0633714     0 .0178299     0 .0319088 \n  -0 .32499      -0 .126343       0 .252081         0 .13956       0 .0987083     0 .102378  \n  -0 .266693     -0 .308904      -0 .160801         0 .422532      0 .0144221     0 .0601095 \n  -0 .352486     -0 .340323      -0 .127019     \u2026     0 .788049      0 .107235      0 .146221  \n  -0 .0542532    -0 .0140205      0 .0354407        0 .107235      0 .645093      0 .405515  \n  -0 .125562      0 .0218768      0 .0121441        0 .146221      0 .405515      0 .755077   ), 0x0   Array { Float64 , 2 } , Char [] , Float64 [] , -Inf , Inf )   Re-run using MM algorithm, which locates a better mode with objective value -4.435632e+04. Follow up anlaysis should use this result.  # initialize model parameters  alltrait_model   =   VarianceComponentModel ( cg10kdata_rotated )  # estimate variance components  @ time   _ ,   _ ,   _ ,   \u03a3cov ,   =   mle_mm! ( alltrait_model ,   cg10kdata_rotated ;   verbose = true )  alltrait_model        MM Algorithm\n  Iter      Objective  \n--------  -------------\n       0  -1.311337e+05\n       1  -8.002195e+04\n       2  -5.807051e+04\n       3  -4.926234e+04\n       4  -4.611182e+04\n       5  -4.511727e+04\n       6  -4.482798e+04\n       7  -4.474410e+04\n       8  -4.471610e+04\n       9  -4.470285e+04\n      10  -4.469355e+04\n      20  -4.462331e+04\n      30  -4.456960e+04\n      40  -4.452834e+04\n      50  -4.449652e+04\n      60  -4.447178e+04\n      70  -4.445237e+04\n      80  -4.443699e+04\n      90  -4.442467e+04\n     100  -4.441470e+04\n     110  -4.440656e+04\n     120  -4.439985e+04\n     130  -4.439427e+04\n     140  -4.438959e+04\n     150  -4.438564e+04\n     160  -4.438229e+04\n     170  -4.437941e+04\n     180  -4.437694e+04\n     190  -4.437480e+04\n     200  -4.437294e+04\n     210  -4.437131e+04\n     220  -4.436989e+04\n     230  -4.436863e+04\n     240  -4.436751e+04\n     250  -4.436652e+04\n     260  -4.436564e+04\n     270  -4.436485e+04\n     280  -4.436414e+04\n     290  -4.436351e+04\n     300  -4.436293e+04\n     310  -4.436242e+04\n     320  -4.436195e+04\n     330  -4.436152e+04\n     340  -4.436113e+04\n     350  -4.436078e+04\n     360  -4.436046e+04\n     370  -4.436016e+04\n     380  -4.435989e+04\n     390  -4.435965e+04\n     400  -4.435942e+04\n     410  -4.435921e+04\n     420  -4.435902e+04\n     430  -4.435884e+04\n     440  -4.435867e+04\n     450  -4.435852e+04\n     460  -4.435838e+04\n     470  -4.435825e+04\n     480  -4.435813e+04\n     490  -4.435802e+04\n     500  -4.435791e+04\n     510  -4.435781e+04\n     520  -4.435772e+04\n     530  -4.435764e+04\n     540  -4.435756e+04\n     550  -4.435748e+04\n     560  -4.435741e+04\n     570  -4.435735e+04\n     580  -4.435729e+04\n     590  -4.435723e+04\n     600  -4.435718e+04\n     610  -4.435713e+04\n     620  -4.435708e+04\n     630  -4.435704e+04\n     640  -4.435700e+04\n     650  -4.435696e+04\n     660  -4.435692e+04\n     670  -4.435688e+04\n     680  -4.435685e+04\n     690  -4.435682e+04\n     700  -4.435679e+04\n     710  -4.435676e+04\n     720  -4.435674e+04\n     730  -4.435671e+04\n     740  -4.435669e+04\n     750  -4.435667e+04\n     760  -4.435665e+04\n     770  -4.435663e+04\n     780  -4.435661e+04\n     790  -4.435659e+04\n     800  -4.435657e+04\n     810  -4.435656e+04\n     820  -4.435654e+04\n     830  -4.435653e+04\n     840  -4.435651e+04\n     850  -4.435650e+04\n     860  -4.435649e+04\n     870  -4.435648e+04\n     880  -4.435647e+04\n     890  -4.435646e+04\n     900  -4.435645e+04\n     910  -4.435644e+04\n     920  -4.435643e+04\n     930  -4.435642e+04\n     940  -4.435641e+04\n     950  -4.435640e+04\n     960  -4.435639e+04\n     970  -4.435639e+04\n     980  -4.435638e+04\n     990  -4.435637e+04\n    1000  -4.435637e+04\n    1010  -4.435636e+04\n    1020  -4.435635e+04\n    1030  -4.435635e+04\n    1040  -4.435634e+04\n    1050  -4.435634e+04\n    1060  -4.435633e+04\n    1070  -4.435633e+04\n    1080  -4.435632e+04\n\n 27.474548 seconds (976.37 M allocations: 23.795 GB, 18.43% gc time)\n\n\n\n\n\nVarianceComponentModels.VarianceComponentModel{Float64,2,Array{Float64,2},Array{Float64,2}}(0x13 Array{Float64,2},(\n13x13 Array{Float64,2}:\n  0.273498    0.192141    -0.0207392   0.231615   \u2026  -0.128643   -0.098307  \n  0.192141    0.219573     0.134389    0.0800317     -0.0687355  -0.0433724 \n -0.0207392   0.134389     0.329149   -0.158086       0.0717258   0.097381  \n  0.231615    0.0800317   -0.158086    0.277921      -0.129316   -0.104571  \n -0.149294   -0.0130248    0.186275   -0.219746       0.0673901   0.0798606 \n -0.131878   -0.00396265   0.169037   -0.204038   \u2026   0.0539454   0.0662375 \n -0.14514    -0.0332988    0.168384   -0.190066       0.0778299   0.0867255 \n -0.0299641   0.0372326    0.0617453  -0.0918129     -0.0120473  -0.00309877\n -0.205216   -0.0839698    0.137149   -0.232933       0.0895106   0.0971193 \n -0.100475   -0.114933    -0.088079   -0.0435633      0.046928   -0.0048387 \n -0.133733   -0.109897    -0.0247458  -0.0985453  \u2026   0.0587572   0.0114353 \n -0.128643   -0.0687355    0.0717258  -0.129316       0.117185    0.0899824 \n -0.098307   -0.0433724    0.097381   -0.104571       0.0899824   0.106354  ,\n\n13x13 Array{Float64,2}:\n  0.723441    0.568135    -0.113563     0.590598   \u2026  -0.0586259  -0.12469   \n  0.568135    0.77999      0.109287     0.215784       0.0236098   0.0464835 \n -0.113563    0.109287     0.669754    -0.299757       0.0467158   0.00601682\n  0.590598    0.215784    -0.299757     0.718142      -0.0951686  -0.218709  \n -0.252371   -0.0353068    0.334628    -0.372904       0.0472511   0.0435499 \n -0.228865   -0.0203083    0.295345    -0.343471   \u2026   0.0511838   0.0482913 \n -0.193033    0.00191887   0.345731    -0.319          0.0327529   0.0272593 \n -0.129704   -0.0365696    0.0400358   -0.156082       0.0427586   0.0451036 \n -0.30716    -0.0823855    0.2673      -0.410123       0.102842    0.0946414 \n -0.303001   -0.28147     -0.13149     -0.218          0.0947723   0.142937  \n -0.364401   -0.30413     -0.107477    -0.270766   \u2026   0.143809    0.187604  \n -0.0586259   0.0236098    0.0467158   -0.0951686      0.881707    0.551818  \n -0.12469     0.0464835    0.00601682  -0.218709       0.551818    0.893023  ),0x0 Array{Float64,2},Char[],Float64[],-Inf,Inf)  Heritability estimate from 13-variate analysis.  h ,   hse   =   heritability ( alltrait_model . \u03a3 ,   \u03a3cov )  [ h ;   hse ]   2x13 Array{Float64,2}:\n 0.274338   0.219669   0.329511  0.279019   \u2026  0.172946  0.117315   0.10642  \n 0.0778364  0.0818365  0.072716  0.0775316     0.087259  0.0902115  0.0903969", 
            "title": "13-trait analysis"
        }, 
        {
            "location": "/man/heritability/#save-analysis-results", 
            "text": "using   JLD  @ save   copd.jld  whos ()   INFO :   Recompiling   stale   cache   file   /Users/huazhou/.julia/lib/v0.4/ JLD . ji   for   module   JLD . \n\n\n                  # 334 # wsession      280   bytes    JLD . JldWriteSession \n                     ArrayViews      188   KB       Module \n                           Base    38129   KB       Module \n                        BinDeps      208   KB       Module \n                          Blosc       37   KB       Module \n                     ColorTypes      313   KB       Module \n                         Colors      747   KB       Module \n                         Compat      344   KB       Module \n                          Conda       65   KB       Module \n                           Core     7200   KB       Module \n                     DataArrays      762   KB       Module \n                     DataFrames     1807   KB       Module \n                         Docile      415   KB       Module \n                         FileIO      536   KB       Module \n              FixedPointNumbers       33   KB       Module \n                FixedSizeArrays      157   KB       Module  WARNING :   both   DataArrays   and   StatsBase   export   autocor ;   uses   of   it   in   module   DataFrames   must   be   qualified  WARNING :   both   DataArrays   and   StatsBase   export   inverse_rle ;   uses   of   it   in   module   DataFrames   must   be   qualified  WARNING :   both   DataArrays   and   StatsBase   export   rle ;   uses   of   it   in   module   DataFrames   must   be   qualified \n\n\n                           GZip      791   KB       Module \n                           HDF5     3336   KB       Module \n                         IJulia   3468156   KB       Module \n                 IPythonDisplay       35   KB       Module \n                          Ipopt       50   KB       Module \n               IterativeSolvers      486   KB       Module \n                            JLD     1364   KB       Module \n                           JSON      240   KB       Module \n                         KNITRO      320   KB       Module \n                   LaTeXStrings     3115   bytes    Module \n                     MacroTools      124   KB       Module \n                           Main   3527139   KB       Module \n                   MathProgBase     1393   KB       Module \n                       Measures       15   KB       Module \n                         Nettle       58   KB       Module \n                          Plots     2975   KB       Module \n                         PyCall     1002   KB       Module \n                         PyPlot     1278   KB       Module \n                    RecipesBase      193   KB       Module \n                       Reexport     3658   bytes    Module \n                            SHA       50   KB       Module \n                      SnpArrays      437   KB       Module \n              SortingAlgorithms       40   KB       Module \n                      StatsBase      783   KB       Module \n                      StatsFuns      286   KB       Module \n                      URIParser      103   KB       Module \n        VarianceComponentModels      642   KB       Module \n                              Y      677   KB       6670 x13   Array { Float64 , 2 } \n                            ZMQ       81   KB       Module \n                              _     2720   bytes    Tuple { Array { Float64 , 2 }, Array { Float \u2026 \n                 alltrait_model     2792   bytes    VarianceComponentModels . VarianceCo \u2026 \n                          cg10k   1027303   KB       6670 x630860   SnpArrays . SnpArray { 2 } \n                    cg10k_trait      978   KB       6670 \u00d7 15   DataFrames . DataFrame \n                      cg10kdata   695816   KB       VarianceComponentModels . VarianceCo \u2026 \n              cg10kdata_rotated      729   KB       VarianceComponentModels . TwoVarComp \u2026 \n                              h      104   bytes    13 - element   Array { Float64 , 1 } \n                            hST      104   bytes    13 - element   Array { Float64 , 1 } \n                         hST_se      104   bytes    13 - element   Array { Float64 , 1 } \n                            hse      104   bytes    13 - element   Array { Float64 , 1 } \n                            maf     4928   KB       630860 - element   Array { Float64 , 1 } \n                   minor_allele       77   KB       630860 - element   BitArray { 1 } \n             missings_by_person       52   KB       6670 - element   Array { Int64 , 1 } \n                missings_by_snp     4928   KB       630860 - element   Array { Int64 , 1 } \n                         people        8   bytes    Int64 \n                           snps        8   bytes    Int64 \n                   trait59_data      312   KB       VarianceComponentModels . TwoVarComp \u2026 \n                  trait59_model      488   bytes    VarianceComponentModels . VarianceCo \u2026 \n                       traitidx       16   bytes    5 - element   UnitRange { Int64 } \n                             \u03a3 a     3848   bytes    13 x13   Array { Array { Float64 , 2 }, 2 } \n                           \u03a3 cov      892   KB       338 x338   Array { Float64 , 2 } \n                             \u03a3 e     3848   bytes    13 x13   Array { Array { Float64 , 2 }, 2 } \n                           \u03a6 grm   347569   KB       6670 x6670   Array { Float64 , 2 } \n                            \u03c3 2 a      104   bytes    13 - element   Array { Float64 , 1 } \n                            \u03c3 2 e      104   bytes    13 - element   Array { Float64 , 1 }", 
            "title": "Save analysis results"
        }
    ]
}